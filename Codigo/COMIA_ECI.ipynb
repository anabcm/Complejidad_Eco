{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<h2>Congreso COMIA-Taller-ECI </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Librerias\n",
    "# Tratamiento de datos\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Gr√°ficos\n",
    "# ==============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocesado y modelado\n",
    "# ==============================================================================\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics import euclidean_distances\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "\n",
    "import multiprocessing\n",
    "import random\n",
    "\n",
    "from fitter import Fitter, get_common_distributions\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargo datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ECI=pd.read_csv(\"COMIA-datos - eci_2015_2020_denue.csv\")\n",
    "ECI=ECI.rename(columns={'cvegeo':'Code_INEGI'})\n",
    "ECI=ECI.drop(columns=['nombre'])\n",
    "ECI[\"Code_INEGI\"]=ECI[\"Code_INEGI\"].astype(str).str.zfill(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>eci_2015</th>\n",
       "      <td>2457.0</td>\n",
       "      <td>-1.417823e-12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.821059</td>\n",
       "      <td>-0.720657</td>\n",
       "      <td>-0.192549</td>\n",
       "      <td>0.454768</td>\n",
       "      <td>3.774324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eci_2016</th>\n",
       "      <td>2458.0</td>\n",
       "      <td>-1.500361e-12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.921988</td>\n",
       "      <td>-0.712890</td>\n",
       "      <td>-0.191520</td>\n",
       "      <td>0.452802</td>\n",
       "      <td>3.700553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eci_2017</th>\n",
       "      <td>2458.0</td>\n",
       "      <td>1.550822e-12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.926144</td>\n",
       "      <td>-0.713013</td>\n",
       "      <td>-0.187858</td>\n",
       "      <td>0.452022</td>\n",
       "      <td>3.683763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eci_2018</th>\n",
       "      <td>2460.0</td>\n",
       "      <td>-1.642391e-11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.918949</td>\n",
       "      <td>-0.709210</td>\n",
       "      <td>-0.189288</td>\n",
       "      <td>0.451650</td>\n",
       "      <td>3.710049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eci_2019</th>\n",
       "      <td>2465.0</td>\n",
       "      <td>5.570424e-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.919250</td>\n",
       "      <td>-0.719523</td>\n",
       "      <td>-0.187980</td>\n",
       "      <td>0.484398</td>\n",
       "      <td>3.525857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eci_2020</th>\n",
       "      <td>2465.0</td>\n",
       "      <td>5.149668e-12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.856838</td>\n",
       "      <td>-0.720006</td>\n",
       "      <td>-0.196564</td>\n",
       "      <td>0.461175</td>\n",
       "      <td>3.610880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count          mean  std       min       25%       50%       75%  \\\n",
       "eci_2015  2457.0 -1.417823e-12  1.0 -1.821059 -0.720657 -0.192549  0.454768   \n",
       "eci_2016  2458.0 -1.500361e-12  1.0 -1.921988 -0.712890 -0.191520  0.452802   \n",
       "eci_2017  2458.0  1.550822e-12  1.0 -1.926144 -0.713013 -0.187858  0.452022   \n",
       "eci_2018  2460.0 -1.642391e-11  1.0 -1.918949 -0.709210 -0.189288  0.451650   \n",
       "eci_2019  2465.0  5.570424e-13  1.0 -1.919250 -0.719523 -0.187980  0.484398   \n",
       "eci_2020  2465.0  5.149668e-12  1.0 -1.856838 -0.720006 -0.196564  0.461175   \n",
       "\n",
       "               max  \n",
       "eci_2015  3.774324  \n",
       "eci_2016  3.700553  \n",
       "eci_2017  3.683763  \n",
       "eci_2018  3.710049  \n",
       "eci_2019  3.525857  \n",
       "eci_2020  3.610880  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ECI. describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Code_INEGI    0\n",
       "eci_2015      8\n",
       "eci_2016      7\n",
       "eci_2017      7\n",
       "eci_2018      5\n",
       "eci_2019      0\n",
       "eci_2020      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_nan=ECI.isnull().sum(axis = 0)\n",
    "total_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ECI=ECI.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(15,10))\n",
    "axes = axes.flat\n",
    "columnas_numeric = ECI.select_dtypes(include=['float64', 'int']).columns\n",
    "#quito las variables respuesta\n",
    "\n",
    "\n",
    "for i, colum in enumerate(columnas_numeric):\n",
    "    sns.histplot(\n",
    "        data    = ECI,\n",
    "        x       = colum,\n",
    "        stat    = \"count\",\n",
    "        kde     = True,\n",
    "        #color   = (list(plt.rcParams['axes.prop_cycle'])*2)[i][\"color\"],\n",
    "        line_kws= {'linewidth': 2},\n",
    "        alpha   = 0.3,\n",
    "        ax      = axes[i]\n",
    "    )\n",
    "    axes[i].set_title(colum, fontsize = 7, fontweight = \"bold\")\n",
    "    axes[i].tick_params(labelsize = 6)\n",
    "    axes[i].set_xlabel(\"\")\n",
    "    \n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.subplots_adjust(top = 0.9)\n",
    "fig.suptitle('Distribuci√≥n variables num√©ricas ECI', fontsize = 10, fontweight = \"bold\")\n",
    "\n",
    "plt.savefig('distribucion_variables_ECI.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 8 is out of bounds for axis 0 with size 6",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-25c199db1849>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Se eliminan los axes vac√≠os\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtight_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 8 is out of bounds for axis 0 with size 6"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#La variable a predecir es ECI_2020\n",
    "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(20,20))\n",
    "axes = axes.flat\n",
    "columnas_numeric = ECI.select_dtypes(include=['float64', 'int']).columns\n",
    "columnas_numeric = columnas_numeric.drop([\"eci_2020\"])\n",
    "\n",
    "for i, colum in enumerate(columnas_numeric):\n",
    "    sns.regplot(\n",
    "        x           = ECI[colum],\n",
    "        y           = ECI[\"eci_2020\"],\n",
    "        color       = \"gray\",\n",
    "        marker      = '.',\n",
    "        scatter_kws = {\"alpha\":0.4},\n",
    "        line_kws    = {\"color\":\"r\",\"alpha\":0.7},\n",
    "        ax          = axes[i]\n",
    "    )\n",
    "    axes[i].set_title(\"ECI 2019 vs {colum}\", fontsize = 7, fontweight = \"bold\")\n",
    "    #axes[i].ticklabel_format(style='sci', scilimits=(-4,4), axis='both')\n",
    "    axes[i].yaxis.set_major_formatter(ticker.EngFormatter())\n",
    "    axes[i].xaxis.set_major_formatter(ticker.EngFormatter())\n",
    "    axes[i].tick_params(labelsize = 6)\n",
    "    axes[i].set_xlabel(\"\")\n",
    "    axes[i].set_ylabel(\"\")\n",
    "\n",
    "# Se eliminan los axes vac√≠os\n",
    "for i in [8]:\n",
    "    fig.delaxes(axes[i])\n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.subplots_adjust(top=0.9)\n",
    "fig.suptitle('Correlaci√≥n con ECI 2020', fontsize = 10, fontweight = \"bold\")\n",
    "plt.savefig('correlacion_de_variables_ECI_con_ECI2020.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable_1</th>\n",
       "      <th>variable_2</th>\n",
       "      <th>r</th>\n",
       "      <th>abs_r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>eci_2018</td>\n",
       "      <td>eci_2017</td>\n",
       "      <td>0.999826</td>\n",
       "      <td>0.999826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>eci_2017</td>\n",
       "      <td>eci_2018</td>\n",
       "      <td>0.999826</td>\n",
       "      <td>0.999826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>eci_2017</td>\n",
       "      <td>eci_2016</td>\n",
       "      <td>0.999679</td>\n",
       "      <td>0.999679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>eci_2016</td>\n",
       "      <td>eci_2017</td>\n",
       "      <td>0.999679</td>\n",
       "      <td>0.999679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>eci_2018</td>\n",
       "      <td>eci_2016</td>\n",
       "      <td>0.999518</td>\n",
       "      <td>0.999518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>eci_2016</td>\n",
       "      <td>eci_2018</td>\n",
       "      <td>0.999518</td>\n",
       "      <td>0.999518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>eci_2020</td>\n",
       "      <td>eci_2019</td>\n",
       "      <td>0.997411</td>\n",
       "      <td>0.997411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>eci_2019</td>\n",
       "      <td>eci_2020</td>\n",
       "      <td>0.997411</td>\n",
       "      <td>0.997411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eci_2015</td>\n",
       "      <td>eci_2016</td>\n",
       "      <td>0.996817</td>\n",
       "      <td>0.996817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>eci_2016</td>\n",
       "      <td>eci_2015</td>\n",
       "      <td>0.996817</td>\n",
       "      <td>0.996817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   variable_1 variable_2         r     abs_r\n",
       "20   eci_2018   eci_2017  0.999826  0.999826\n",
       "15   eci_2017   eci_2018  0.999826  0.999826\n",
       "13   eci_2017   eci_2016  0.999679  0.999679\n",
       "8    eci_2016   eci_2017  0.999679  0.999679\n",
       "19   eci_2018   eci_2016  0.999518  0.999518\n",
       "9    eci_2016   eci_2018  0.999518  0.999518\n",
       "34   eci_2020   eci_2019  0.997411  0.997411\n",
       "29   eci_2019   eci_2020  0.997411  0.997411\n",
       "1    eci_2015   eci_2016  0.996817  0.996817\n",
       "6    eci_2016   eci_2015  0.996817  0.996817"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tidy_corr_matrix(corr_mat):\n",
    "    '''\n",
    "    Funci√≥n para convertir una matrix de correlaci√≥n de pandas en formato tidy\n",
    "    '''\n",
    "    corr_mat = corr_mat.stack().reset_index()\n",
    "    corr_mat.columns = ['variable_1','variable_2','r']\n",
    "    corr_mat = corr_mat.loc[corr_mat['variable_1'] != corr_mat['variable_2'], :]\n",
    "    corr_mat['abs_r'] = np.abs(corr_mat['r'])\n",
    "    corr_mat = corr_mat.sort_values('abs_r', ascending=False)\n",
    "    \n",
    "    return(corr_mat)\n",
    "\n",
    "\n",
    "\n",
    "corr_matrix = ECI.select_dtypes(include=['float64', 'int']).corr(method='pearson')\n",
    "tidy_corr_matrix(corr_matrix).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 20))\n",
    "\n",
    "sns.heatmap(\n",
    "    corr_matrix,\n",
    "    annot     = True,\n",
    "    cbar      = False,\n",
    "    annot_kws = {\"size\": 6},\n",
    "    vmin      = -1,\n",
    "    vmax      = 1,\n",
    "    center    = 0,\n",
    "    cmap      = sns.diverging_palette(20, 220, n=200),\n",
    "    square    = True,\n",
    "    ax        = ax\n",
    ")\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation = 45,\n",
    "    horizontalalignment = 'right',\n",
    ")\n",
    "\n",
    "ax.tick_params(labelsize = 8)\n",
    "plt.savefig('Matriz_de_correlaciones_ECI.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1>PCA</H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ECI=ECI.fillna(0)\n",
    "prediccion=ECI['eci_2020']\n",
    "datos= ECI[['eci_2015','eci_2016','eci_2017','eci_2018','eci_2019']]\n",
    "#etiquetando las clases\n",
    "prediccion_percentiles = pd.qcut(prediccion,3, labels=[1,2,3]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a dos componentes\n",
    "#dividimos el conjunto en 2 sets(entrenamiento y prueba)\n",
    "\n",
    "entrenamiento, validacion, entrenamiento_lbl, validacion_lbl = train_test_split(\n",
    "    datos, prediccion_percentiles, test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(493,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entrenamiento.shape\n",
    "validacion.shape\n",
    "entrenamiento_lbl.shape\n",
    "validacion_lbl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training set only.\n",
    "scaler.fit(entrenamiento)\n",
    "\n",
    "# Apply transform to both the training set and the test set.\n",
    "entrenamiento = scaler.transform(entrenamiento)\n",
    "validacion = scaler.transform(validacion)\n",
    "#PCA con regresion logistica\n",
    "from sklearn.decomposition import PCA\n",
    "#queremos un nivel de confianza del .95\n",
    "\n",
    "pca = PCA(.9)\n",
    "pca.fit(entrenamiento)\n",
    "pca.n_components_\n",
    "###############NO HAY SUFICIENTE VARIANZA PARA EJECUTAR UN PCA###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9046653144016227\n"
     ]
    }
   ],
   "source": [
    "#los datos son continuos y necesitamos codificarlos\n",
    "from sklearn import preprocessing\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "\n",
    "entrenamiento_lbl_encoded = lab_enc.fit_transform(entrenamiento_lbl)\n",
    "validacion_lbl_encoded = lab_enc.fit_transform(validacion_lbl)\n",
    "\n",
    "entrenamiento = pca.transform(entrenamiento)\n",
    "validacion = pca.transform(validacion)\n",
    "\n",
    "\n",
    "#Ahora usaremos regresion logistica\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# solver = 'lbfgs' m√©todos de optimizaci√≥n quasi-Newton \n",
    "logisticRegr = LogisticRegression(solver = 'lbfgs', max_iter=1000)\n",
    "\n",
    "#Entrenando el modelo\n",
    "logisticRegr.fit(entrenamiento, entrenamiento_lbl_encoded)\n",
    "predic=logisticRegr.predict(validacion)\n",
    "#ahora el performance\n",
    "score = logisticRegr.score(validacion, validacion_lbl_encoded)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99470182])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explained_variance = pca.explained_variance_ratio_\n",
    "np.cumsum(explained_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PC0</td>\n",
       "      <td>eci_2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         1\n",
       "0  PC0  eci_2017"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of components\n",
    "n_pcs= pca.components_.shape[0]\n",
    "\n",
    "# get the index of the most important feature on EACH component\n",
    "# LIST COMPREHENSION HERE\n",
    "mas_importantes= [np.abs(pca.components_[i]).argmax() for i in range(n_pcs)]\n",
    "descriptivas=datos\n",
    "#quitamos las target\n",
    "\n",
    "nombres_iniciales =descriptivas.columns\n",
    "# get the names\n",
    "nombres_mas_importantes = [nombres_iniciales[mas_importantes[i]] for i in range(n_pcs)]\n",
    "\n",
    "# LIST COMPREHENSION HERE AGAIN\n",
    "dic = {'PC{}'.format(i): nombres_mas_importantes[i] for i in range(n_pcs)}\n",
    "\n",
    "# build the dataframe\n",
    "df = pd.DataFrame(dic.items())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1>K-MEANS</H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#el codo dice que 3 clusters\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "K = range(1,8)\n",
    "sum_squared_distances = []\n",
    "for k in K:\n",
    "  model = KMeans(n_clusters=k).fit(ECI)\n",
    "  sum_squared_distances.append(model.inertia_)\n",
    "plt.plot(K, sum_squared_distances, \"bx-\")\n",
    "plt.xlabel(\"K Values\")\n",
    "plt.ylabel(\"Sum Squared Distances\")\n",
    "plt.title(\"Elbow Method\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code_INEGI</th>\n",
       "      <th>eci_2015</th>\n",
       "      <th>eci_2016</th>\n",
       "      <th>eci_2017</th>\n",
       "      <th>eci_2018</th>\n",
       "      <th>eci_2019</th>\n",
       "      <th>eci_2020</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>09014</td>\n",
       "      <td>3.740938</td>\n",
       "      <td>3.652317</td>\n",
       "      <td>3.639344</td>\n",
       "      <td>3.661518</td>\n",
       "      <td>3.525857</td>\n",
       "      <td>3.610880</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>09016</td>\n",
       "      <td>3.774324</td>\n",
       "      <td>3.653583</td>\n",
       "      <td>3.644736</td>\n",
       "      <td>3.653135</td>\n",
       "      <td>3.460074</td>\n",
       "      <td>3.586565</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>09015</td>\n",
       "      <td>3.743856</td>\n",
       "      <td>3.700553</td>\n",
       "      <td>3.683763</td>\n",
       "      <td>3.710049</td>\n",
       "      <td>3.477146</td>\n",
       "      <td>3.555680</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19039</td>\n",
       "      <td>3.602128</td>\n",
       "      <td>3.545856</td>\n",
       "      <td>3.538237</td>\n",
       "      <td>3.545084</td>\n",
       "      <td>3.460336</td>\n",
       "      <td>3.539288</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14039</td>\n",
       "      <td>3.574441</td>\n",
       "      <td>3.534361</td>\n",
       "      <td>3.522737</td>\n",
       "      <td>3.530704</td>\n",
       "      <td>3.351222</td>\n",
       "      <td>3.423257</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>02004</td>\n",
       "      <td>3.551830</td>\n",
       "      <td>3.542853</td>\n",
       "      <td>3.517225</td>\n",
       "      <td>3.518143</td>\n",
       "      <td>3.286124</td>\n",
       "      <td>3.399274</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>09010</td>\n",
       "      <td>3.361522</td>\n",
       "      <td>3.368395</td>\n",
       "      <td>3.319955</td>\n",
       "      <td>3.373163</td>\n",
       "      <td>3.250641</td>\n",
       "      <td>3.377251</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>19019</td>\n",
       "      <td>3.204351</td>\n",
       "      <td>3.245857</td>\n",
       "      <td>3.269134</td>\n",
       "      <td>3.286065</td>\n",
       "      <td>3.183386</td>\n",
       "      <td>3.372227</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>22014</td>\n",
       "      <td>3.443794</td>\n",
       "      <td>3.469615</td>\n",
       "      <td>3.442376</td>\n",
       "      <td>3.452814</td>\n",
       "      <td>3.314162</td>\n",
       "      <td>3.353358</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15104</td>\n",
       "      <td>3.310086</td>\n",
       "      <td>3.337249</td>\n",
       "      <td>3.364130</td>\n",
       "      <td>3.383370</td>\n",
       "      <td>3.213771</td>\n",
       "      <td>3.339978</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Code_INEGI  eci_2015  eci_2016  eci_2017  eci_2018  eci_2019  eci_2020  \\\n",
       "0      09014  3.740938  3.652317  3.639344  3.661518  3.525857  3.610880   \n",
       "1      09016  3.774324  3.653583  3.644736  3.653135  3.460074  3.586565   \n",
       "2      09015  3.743856  3.700553  3.683763  3.710049  3.477146  3.555680   \n",
       "3      19039  3.602128  3.545856  3.538237  3.545084  3.460336  3.539288   \n",
       "4      14039  3.574441  3.534361  3.522737  3.530704  3.351222  3.423257   \n",
       "5      02004  3.551830  3.542853  3.517225  3.518143  3.286124  3.399274   \n",
       "6      09010  3.361522  3.368395  3.319955  3.373163  3.250641  3.377251   \n",
       "7      19019  3.204351  3.245857  3.269134  3.286065  3.183386  3.372227   \n",
       "8      22014  3.443794  3.469615  3.442376  3.452814  3.314162  3.353358   \n",
       "9      15104  3.310086  3.337249  3.364130  3.383370  3.213771  3.339978   \n",
       "\n",
       "   Cluster  \n",
       "0        1  \n",
       "1        1  \n",
       "2        1  \n",
       "3        0  \n",
       "4        1  \n",
       "5        1  \n",
       "6        1  \n",
       "7        0  \n",
       "8        0  \n",
       "9        1  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#etiquetando datos\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "ECI_clusters = kmeans.fit(ECI)\n",
    "preds = ECI_clusters.fit_predict(ECI)\n",
    "\n",
    "ECI['Cluster']=preds\n",
    "ECI.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1093\n",
       "1     786\n",
       "2     586\n",
       "Name: Cluster, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Los clusters estan desbalanceados\n",
    "ECI.Cluster.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Ahora que ya sabes cuantos clusters hay le echamos una RNA con Tensor flow</H1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1> RNA </H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       0\n",
       "4       1\n",
       "       ..\n",
       "2460    0\n",
       "2461    0\n",
       "2462    0\n",
       "2463    0\n",
       "2464    0\n",
       "Name: Cluster, Length: 2465, dtype: int32"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TFlearn is a modular and transparent deep learning library built on top of Tensorflow. It was designed to provide a higher-level\n",
    "#API to TensorFlow in order to facilitate and speed-up experimentations, while remaining fully transparent and compatible with it.\n",
    "import tensorflow.compat.v1  as tf\n",
    "import tflearn\n",
    "datos= ECI[['eci_2015','eci_2016','eci_2017','eci_2018','eci_2019','eci_2020']]\n",
    "datos=np.array(datos.fillna(0))\n",
    "clases=ECI[\"Cluster\"]\n",
    "clases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "entrenamiento, validacion, entrenamiento_lbl, validacion_lbl = train_test_split(\n",
    "    datos, clases , test_size=0.2, random_state=45)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training set only.\n",
    "scaler.fit(entrenamiento)\n",
    "scaler.fit(validacion)\n",
    "# Apply transform to both the training set and the test set.\n",
    "entrenamiento= scaler.transform(entrenamiento)\n",
    "validacion= scaler.transform(validacion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "entrenamiento_lbl =[i for i in entrenamiento_lbl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "validacion_lbl =[i for i in validacion_lbl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "entrenamiento_lbl = np.reshape(entrenamiento_lbl , (-1, 1))\n",
    "validacion_lbl= np.reshape(validacion_lbl , (-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNA a dos capas ocultas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaDelta\n",
      "relu\n",
      "1000\n",
      "---------------------------------\n",
      "Run id: DOBYST\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.734s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.089s\n",
      "| AdaDelta | epoch: 002 | loss: nan - binary_acc: 0.3555 | val_loss: nan - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.090s\n",
      "| AdaDelta | epoch: 003 | loss: nan - binary_acc: 0.4148 | val_loss: nan - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.087s\n",
      "| AdaDelta | epoch: 004 | loss: nan - binary_acc: 0.4247 | val_loss: nan - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.088s\n",
      "| AdaDelta | epoch: 005 | loss: nan - binary_acc: 0.4270 | val_loss: nan - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.092s\n",
      "| AdaDelta | epoch: 006 | loss: nan - binary_acc: 0.4277 | val_loss: nan - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.088s\n",
      "| AdaDelta | epoch: 007 | loss: nan - binary_acc: 0.4279 | val_loss: nan - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.085s\n",
      "| AdaDelta | epoch: 008 | loss: nan - binary_acc: 0.4280 | val_loss: nan - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.087s\n",
      "| AdaDelta | epoch: 009 | loss: nan - binary_acc: 0.4280 | val_loss: nan - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.095s\n",
      "| AdaDelta | epoch: 010 | loss: nan - binary_acc: 0.4280 | val_loss: nan - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.088s\n",
      "| AdaDelta | epoch: 011 | loss: nan - binary_acc: 0.4280 | val_loss: nan - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.088s\n",
      "| AdaDelta | epoch: 012 | loss: nan - binary_acc: 0.4280 | val_loss: nan - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.087s\n",
      "| AdaDelta | epoch: 013 | loss: nan - binary_acc: 0.4280 | val_loss: nan - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.091s\n",
      "| AdaDelta | epoch: 014 | loss: nan - binary_acc: 0.4280 | val_loss: nan - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.088s\n",
      "| AdaDelta | epoch: 015 | loss: nan - binary_acc: 0.4280 | val_loss: nan - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.085s\n",
      "| AdaDelta | epoch: 016 | loss: nan - binary_acc: 0.4280 | val_loss: nan - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.088s\n",
      "| AdaDelta | epoch: 017 | loss: nan - binary_acc: 0.4280 | val_loss: nan - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.089s\n",
      "| AdaDelta | epoch: 018 | loss: nan - binary_acc: 0.4280 | val_loss: nan - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.088s\n",
      "| AdaDelta | epoch: 019 | loss: nan - binary_acc: 0.4280 | val_loss: nan - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.088s\n",
      "| AdaDelta | epoch: 020 | loss: nan - binary_acc: 0.4280 | val_loss: nan - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.087s\n",
      "| AdaDelta | epoch: 021 | loss: nan - binary_acc: 0.4280 | val_loss: nan - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.092s\n",
      "| AdaDelta | epoch: 022 | loss: nan - binary_acc: 0.4280 | val_loss: nan - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.088s\n",
      "| AdaDelta | epoch: 023 | loss: nan - binary_acc: 0.4280 | val_loss: nan - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.093s\n",
      "| AdaDelta | epoch: 024 | loss: nan - binary_acc: 0.4280 | val_loss: nan - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.088s\n",
      "| AdaDelta | epoch: 025 | loss: nan - binary_acc: 0.4280 | val_loss: nan - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.089s\n",
      "| AdaDelta | epoch: 026 | loss: nan - binary_acc: 0.4280 | val_loss: nan - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.090s\n",
      "| AdaDelta | epoch: 027 | loss: nan - binary_acc: 0.4280 | val_loss: nan - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.089s\n",
      "| AdaDelta | epoch: 028 | loss: nan - binary_acc: 0.4280 | val_loss: nan - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.087s\n",
      "| AdaDelta | epoch: 029 | loss: nan - binary_acc: 0.4280 | val_loss: nan - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.091s\n",
      "| AdaDelta | epoch: 030 | loss: nan - binary_acc: 0.4280 | val_loss: nan - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'relu', 1000, [0.45436105404132276]]\n",
      "AdaDelta\n",
      "relu\n",
      "100\n",
      "---------------------------------\n",
      "Run id: MZQLEQ\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.113s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 002 | loss: nan - binary_acc: 0.3384 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 003 | loss: nan - binary_acc: 0.4216 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaDelta | epoch: 004 | loss: nan - binary_acc: 0.4355 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| AdaDelta | epoch: 005 | loss: nan - binary_acc: 0.4387 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| AdaDelta | epoch: 006 | loss: nan - binary_acc: 0.4396 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 007 | loss: nan - binary_acc: 0.4399 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 008 | loss: nan - binary_acc: 0.4400 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaDelta | epoch: 009 | loss: nan - binary_acc: 0.4400 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaDelta | epoch: 010 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaDelta | epoch: 011 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaDelta | epoch: 012 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaDelta | epoch: 013 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaDelta | epoch: 014 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaDelta | epoch: 015 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| AdaDelta | epoch: 016 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaDelta | epoch: 017 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaDelta | epoch: 018 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaDelta | epoch: 019 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaDelta | epoch: 020 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaDelta | epoch: 021 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaDelta | epoch: 022 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaDelta | epoch: 023 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaDelta | epoch: 024 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaDelta | epoch: 025 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaDelta | epoch: 026 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaDelta | epoch: 027 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaDelta | epoch: 028 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaDelta | epoch: 029 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 030 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'relu', 100, [0.45436105404132276]]\n",
      "AdaDelta\n",
      "relu\n",
      "35\n",
      "---------------------------------\n",
      "Run id: H1HFVP\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.123s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.006s\n",
      "| AdaDelta | epoch: 002 | loss: nan - binary_acc: 0.3521 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 003 | loss: nan - binary_acc: 0.4303 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.006s\n",
      "| AdaDelta | epoch: 004 | loss: nan - binary_acc: 0.4433 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 005 | loss: nan - binary_acc: 0.4463 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 006 | loss: nan - binary_acc: 0.4472 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 007 | loss: nan - binary_acc: 0.4475 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 008 | loss: nan - binary_acc: 0.4476 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 009 | loss: nan - binary_acc: 0.4476 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 010 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 011 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 012 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 013 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 014 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaDelta | epoch: 015 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 016 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 017 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 018 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 019 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 020 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 021 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 022 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 023 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 024 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 025 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 026 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 027 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 028 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 029 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 030 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'relu', 35, [0.45436105404132276]]\n",
      "AdaDelta\n",
      "linear\n",
      "1000\n",
      "---------------------------------\n",
      "Run id: XZG78Q\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.203s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.095s\n",
      "| AdaDelta | epoch: 002 | loss: 0.00000 - binary_acc: 0.3356 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.092s\n",
      "| AdaDelta | epoch: 003 | loss: 0.00000 - binary_acc: 0.2758 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.109s\n",
      "| AdaDelta | epoch: 004 | loss: 0.00000 - binary_acc: 0.3443 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.100s\n",
      "| AdaDelta | epoch: 005 | loss: 0.00000 - binary_acc: 0.2877 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.089s\n",
      "| AdaDelta | epoch: 006 | loss: 0.00000 - binary_acc: 0.3494 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.089s\n",
      "| AdaDelta | epoch: 007 | loss: 0.00000 - binary_acc: 0.2973 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.109s\n",
      "| AdaDelta | epoch: 008 | loss: 0.00000 - binary_acc: 0.2777 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.099s\n",
      "| AdaDelta | epoch: 009 | loss: 0.00000 - binary_acc: 0.2697 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.097s\n",
      "| AdaDelta | epoch: 010 | loss: 0.00000 - binary_acc: 0.3099 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.086s\n",
      "| AdaDelta | epoch: 011 | loss: 0.00000 - binary_acc: 0.2874 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.095s\n",
      "| AdaDelta | epoch: 012 | loss: 0.00000 - binary_acc: 0.3165 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.093s\n",
      "| AdaDelta | epoch: 013 | loss: 0.00000 - binary_acc: 0.2933 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.093s\n",
      "| AdaDelta | epoch: 014 | loss: 0.00000 - binary_acc: 0.3264 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.091s\n",
      "| AdaDelta | epoch: 015 | loss: 0.00000 - binary_acc: 0.3014 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.089s\n",
      "| AdaDelta | epoch: 016 | loss: 0.00000 - binary_acc: 0.3344 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.087s\n",
      "| AdaDelta | epoch: 017 | loss: 0.00000 - binary_acc: 0.3085 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.086s\n",
      "| AdaDelta | epoch: 018 | loss: 0.00000 - binary_acc: 0.3257 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.093s\n",
      "| AdaDelta | epoch: 019 | loss: 0.00000 - binary_acc: 0.3047 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.088s\n",
      "| AdaDelta | epoch: 020 | loss: 0.00000 - binary_acc: 0.3250 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.088s\n",
      "| AdaDelta | epoch: 021 | loss: 0.00000 - binary_acc: 0.3056 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.094s\n",
      "| AdaDelta | epoch: 022 | loss: 0.00000 - binary_acc: 0.3197 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.095s\n",
      "| AdaDelta | epoch: 023 | loss: 0.00000 - binary_acc: 0.3031 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.091s\n",
      "| AdaDelta | epoch: 024 | loss: 0.00000 - binary_acc: 0.3172 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.089s\n",
      "| AdaDelta | epoch: 025 | loss: 0.00000 - binary_acc: 0.3023 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.093s\n",
      "| AdaDelta | epoch: 026 | loss: 0.00000 - binary_acc: 0.3142 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.088s\n",
      "| AdaDelta | epoch: 027 | loss: 0.00000 - binary_acc: 0.3009 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.088s\n",
      "| AdaDelta | epoch: 028 | loss: 0.00000 - binary_acc: 0.3146 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.090s\n",
      "| AdaDelta | epoch: 029 | loss: 0.00000 - binary_acc: 0.3020 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.089s\n",
      "| AdaDelta | epoch: 030 | loss: 0.00000 - binary_acc: 0.3126 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'linear', 1000, [0.2555780959661302]]\n",
      "AdaDelta\n",
      "linear\n",
      "100\n",
      "---------------------------------\n",
      "Run id: 03WTQ6\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.119s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.2354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.010s\n",
      "| AdaDelta | epoch: 002 | loss: 0.00000 - binary_acc: 0.3407 | val_loss: 0.00000 - val_binary_acc: 0.2354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.011s\n",
      "| AdaDelta | epoch: 003 | loss: 0.00000 - binary_acc: 0.2799 | val_loss: 0.00000 - val_binary_acc: 0.2354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.011s\n",
      "| AdaDelta | epoch: 004 | loss: 0.00000 - binary_acc: 0.3477 | val_loss: 0.00000 - val_binary_acc: 0.2354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.010s\n",
      "| AdaDelta | epoch: 005 | loss: 0.00000 - binary_acc: 0.2914 | val_loss: 0.00000 - val_binary_acc: 0.2354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.011s\n",
      "| AdaDelta | epoch: 006 | loss: 0.00000 - binary_acc: 0.3405 | val_loss: 0.00000 - val_binary_acc: 0.2354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.010s\n",
      "| AdaDelta | epoch: 007 | loss: 0.00000 - binary_acc: 0.2960 | val_loss: 0.00000 - val_binary_acc: 0.2354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.011s\n",
      "| AdaDelta | epoch: 008 | loss: 0.00000 - binary_acc: 0.3435 | val_loss: 0.00000 - val_binary_acc: 0.2354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.010s\n",
      "| AdaDelta | epoch: 009 | loss: 0.00000 - binary_acc: 0.3026 | val_loss: 0.00000 - val_binary_acc: 0.2354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.011s\n",
      "| AdaDelta | epoch: 010 | loss: 0.00000 - binary_acc: 0.3336 | val_loss: 0.00000 - val_binary_acc: 0.2354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.011s\n",
      "| AdaDelta | epoch: 011 | loss: 0.00000 - binary_acc: 0.3018 | val_loss: 0.00000 - val_binary_acc: 0.2354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.010s\n",
      "| AdaDelta | epoch: 012 | loss: 0.00000 - binary_acc: 0.3269 | val_loss: 0.00000 - val_binary_acc: 0.2354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.011s\n",
      "| AdaDelta | epoch: 013 | loss: 0.00000 - binary_acc: 0.3009 | val_loss: 0.00000 - val_binary_acc: 0.2354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.013s\n",
      "| AdaDelta | epoch: 014 | loss: 0.00000 - binary_acc: 0.3265 | val_loss: 0.00000 - val_binary_acc: 0.2354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.012s\n",
      "| AdaDelta | epoch: 015 | loss: 0.00000 - binary_acc: 0.3029 | val_loss: 0.00000 - val_binary_acc: 0.2354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.011s\n",
      "| AdaDelta | epoch: 016 | loss: 0.00000 - binary_acc: 0.3372 | val_loss: 0.00000 - val_binary_acc: 0.2354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.011s\n",
      "| AdaDelta | epoch: 017 | loss: 0.00000 - binary_acc: 0.3117 | val_loss: 0.00000 - val_binary_acc: 0.2354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.011s\n",
      "| AdaDelta | epoch: 018 | loss: 0.00000 - binary_acc: 0.3265 | val_loss: 0.00000 - val_binary_acc: 0.2354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.011s\n",
      "| AdaDelta | epoch: 019 | loss: 0.00000 - binary_acc: 0.3065 | val_loss: 0.00000 - val_binary_acc: 0.2354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.011s\n",
      "| AdaDelta | epoch: 020 | loss: 0.00000 - binary_acc: 0.3280 | val_loss: 0.00000 - val_binary_acc: 0.2354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.011s\n",
      "| AdaDelta | epoch: 021 | loss: 0.00000 - binary_acc: 0.3089 | val_loss: 0.00000 - val_binary_acc: 0.2354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.011s\n",
      "| AdaDelta | epoch: 022 | loss: 0.00000 - binary_acc: 0.3275 | val_loss: 0.00000 - val_binary_acc: 0.2354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.011s\n",
      "| AdaDelta | epoch: 023 | loss: 0.00000 - binary_acc: 0.3097 | val_loss: 0.00000 - val_binary_acc: 0.2354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.011s\n",
      "| AdaDelta | epoch: 024 | loss: 0.00000 - binary_acc: 0.3193 | val_loss: 0.00000 - val_binary_acc: 0.2354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.010s\n",
      "| AdaDelta | epoch: 025 | loss: 0.00000 - binary_acc: 0.3048 | val_loss: 0.00000 - val_binary_acc: 0.2354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.010s\n",
      "| AdaDelta | epoch: 026 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.2354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.011s\n",
      "| AdaDelta | epoch: 027 | loss: 0.00000 - binary_acc: 0.3021 | val_loss: 0.00000 - val_binary_acc: 0.2354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.011s\n",
      "| AdaDelta | epoch: 028 | loss: 0.00000 - binary_acc: 0.3114 | val_loss: 0.00000 - val_binary_acc: 0.2354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.010s\n",
      "| AdaDelta | epoch: 029 | loss: 0.00000 - binary_acc: 0.3004 | val_loss: 0.00000 - val_binary_acc: 0.2354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.012s\n",
      "| AdaDelta | epoch: 030 | loss: 0.00000 - binary_acc: 0.3084 | val_loss: 0.00000 - val_binary_acc: 0.2354 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'linear', 100, [0.2474645057024385]]\n",
      "AdaDelta\n",
      "linear\n",
      "35\n",
      "---------------------------------\n",
      "Run id: 7NQ253\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.115s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.4886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.006s\n",
      "| AdaDelta | epoch: 002 | loss: 0.00000 - binary_acc: 0.3881 | val_loss: 0.00000 - val_binary_acc: 0.4886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.007s\n",
      "| AdaDelta | epoch: 003 | loss: 0.00000 - binary_acc: 0.4815 | val_loss: 0.00000 - val_binary_acc: 0.4886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.007s\n",
      "| AdaDelta | epoch: 004 | loss: 0.00000 - binary_acc: 0.4129 | val_loss: 0.00000 - val_binary_acc: 0.4886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.008s\n",
      "| AdaDelta | epoch: 005 | loss: 0.00000 - binary_acc: 0.4747 | val_loss: 0.00000 - val_binary_acc: 0.4886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.009s\n",
      "| AdaDelta | epoch: 006 | loss: 0.00000 - binary_acc: 0.4345 | val_loss: 0.00000 - val_binary_acc: 0.4886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.008s\n",
      "| AdaDelta | epoch: 007 | loss: 0.00000 - binary_acc: 0.4751 | val_loss: 0.00000 - val_binary_acc: 0.4886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.008s\n",
      "| AdaDelta | epoch: 008 | loss: 0.00000 - binary_acc: 0.4251 | val_loss: 0.00000 - val_binary_acc: 0.4886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.008s\n",
      "| AdaDelta | epoch: 009 | loss: 0.00000 - binary_acc: 0.4659 | val_loss: 0.00000 - val_binary_acc: 0.4886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.008s\n",
      "| AdaDelta | epoch: 010 | loss: 0.00000 - binary_acc: 0.4841 | val_loss: 0.00000 - val_binary_acc: 0.4886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.008s\n",
      "| AdaDelta | epoch: 011 | loss: 0.00000 - binary_acc: 0.4927 | val_loss: 0.00000 - val_binary_acc: 0.4886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.008s\n",
      "| AdaDelta | epoch: 012 | loss: 0.00000 - binary_acc: 0.4559 | val_loss: 0.00000 - val_binary_acc: 0.4886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.009s\n",
      "| AdaDelta | epoch: 013 | loss: 0.00000 - binary_acc: 0.4757 | val_loss: 0.00000 - val_binary_acc: 0.4886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.008s\n",
      "| AdaDelta | epoch: 014 | loss: 0.00000 - binary_acc: 0.4866 | val_loss: 0.00000 - val_binary_acc: 0.4886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.008s\n",
      "| AdaDelta | epoch: 015 | loss: 0.00000 - binary_acc: 0.4927 | val_loss: 0.00000 - val_binary_acc: 0.4886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.007s\n",
      "| AdaDelta | epoch: 016 | loss: 0.00000 - binary_acc: 0.4489 | val_loss: 0.00000 - val_binary_acc: 0.4886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.008s\n",
      "| AdaDelta | epoch: 017 | loss: 0.00000 - binary_acc: 0.4681 | val_loss: 0.00000 - val_binary_acc: 0.4886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.007s\n",
      "| AdaDelta | epoch: 018 | loss: 0.00000 - binary_acc: 0.4389 | val_loss: 0.00000 - val_binary_acc: 0.4886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.008s\n",
      "| AdaDelta | epoch: 019 | loss: 0.00000 - binary_acc: 0.4600 | val_loss: 0.00000 - val_binary_acc: 0.4886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.009s\n",
      "| AdaDelta | epoch: 020 | loss: 0.00000 - binary_acc: 0.4489 | val_loss: 0.00000 - val_binary_acc: 0.4886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.007s\n",
      "| AdaDelta | epoch: 021 | loss: 0.00000 - binary_acc: 0.4654 | val_loss: 0.00000 - val_binary_acc: 0.4886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.008s\n",
      "| AdaDelta | epoch: 022 | loss: 0.00000 - binary_acc: 0.4573 | val_loss: 0.00000 - val_binary_acc: 0.4886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.008s\n",
      "| AdaDelta | epoch: 023 | loss: 0.00000 - binary_acc: 0.4703 | val_loss: 0.00000 - val_binary_acc: 0.4886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.008s\n",
      "| AdaDelta | epoch: 024 | loss: 0.00000 - binary_acc: 0.4447 | val_loss: 0.00000 - val_binary_acc: 0.4886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.008s\n",
      "| AdaDelta | epoch: 025 | loss: 0.00000 - binary_acc: 0.4604 | val_loss: 0.00000 - val_binary_acc: 0.4886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.008s\n",
      "| AdaDelta | epoch: 026 | loss: 0.00000 - binary_acc: 0.4505 | val_loss: 0.00000 - val_binary_acc: 0.4886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.008s\n",
      "| AdaDelta | epoch: 027 | loss: 0.00000 - binary_acc: 0.4638 | val_loss: 0.00000 - val_binary_acc: 0.4886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.008s\n",
      "| AdaDelta | epoch: 028 | loss: 0.00000 - binary_acc: 0.4468 | val_loss: 0.00000 - val_binary_acc: 0.4886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.008s\n",
      "| AdaDelta | epoch: 029 | loss: 0.00000 - binary_acc: 0.4602 | val_loss: 0.00000 - val_binary_acc: 0.4886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.009s\n",
      "| AdaDelta | epoch: 030 | loss: 0.00000 - binary_acc: 0.4462 | val_loss: 0.00000 - val_binary_acc: 0.4886 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'linear', 35, [0.48275861881567544]]\n",
      "AdaDelta\n",
      "softmax\n",
      "1000\n",
      "---------------------------------\n",
      "Run id: DMK5YQ\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.993s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.095s\n",
      "| AdaDelta | epoch: 002 | loss: 0.00000 - binary_acc: 0.2899 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.097s\n",
      "| AdaDelta | epoch: 003 | loss: 0.00000 - binary_acc: 0.3163 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.099s\n",
      "| AdaDelta | epoch: 004 | loss: 0.00000 - binary_acc: 0.3207 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.107s\n",
      "| AdaDelta | epoch: 005 | loss: 0.00000 - binary_acc: 0.3217 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.101s\n",
      "| AdaDelta | epoch: 006 | loss: 0.00000 - binary_acc: 0.3220 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.099s\n",
      "| AdaDelta | epoch: 007 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.097s\n",
      "| AdaDelta | epoch: 008 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.103s\n",
      "| AdaDelta | epoch: 009 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.110s\n",
      "| AdaDelta | epoch: 010 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.103s\n",
      "| AdaDelta | epoch: 011 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.099s\n",
      "| AdaDelta | epoch: 012 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.108s\n",
      "| AdaDelta | epoch: 013 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.097s\n",
      "| AdaDelta | epoch: 014 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.101s\n",
      "| AdaDelta | epoch: 015 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.099s\n",
      "| AdaDelta | epoch: 016 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.102s\n",
      "| AdaDelta | epoch: 017 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.097s\n",
      "| AdaDelta | epoch: 018 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.102s\n",
      "| AdaDelta | epoch: 019 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.098s\n",
      "| AdaDelta | epoch: 020 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.108s\n",
      "| AdaDelta | epoch: 021 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.103s\n",
      "| AdaDelta | epoch: 022 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.088s\n",
      "| AdaDelta | epoch: 023 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.109s\n",
      "| AdaDelta | epoch: 024 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.095s\n",
      "| AdaDelta | epoch: 025 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.090s\n",
      "| AdaDelta | epoch: 026 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.167s\n",
      "| AdaDelta | epoch: 027 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.111s\n",
      "| AdaDelta | epoch: 028 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.108s\n",
      "| AdaDelta | epoch: 029 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.108s\n",
      "| AdaDelta | epoch: 030 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'softmax', 1000, [0.3002028369758482]]\n",
      "AdaDelta\n",
      "softmax\n",
      "100\n",
      "---------------------------------\n",
      "Run id: 611WPM\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.150s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.010s\n",
      "| AdaDelta | epoch: 002 | loss: 0.00000 - binary_acc: 0.2939 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.012s\n",
      "| AdaDelta | epoch: 003 | loss: 0.00000 - binary_acc: 0.3206 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.012s\n",
      "| AdaDelta | epoch: 004 | loss: 0.00000 - binary_acc: 0.3251 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.012s\n",
      "| AdaDelta | epoch: 005 | loss: 0.00000 - binary_acc: 0.3261 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.014s\n",
      "| AdaDelta | epoch: 006 | loss: 0.00000 - binary_acc: 0.3264 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.012s\n",
      "| AdaDelta | epoch: 007 | loss: 0.00000 - binary_acc: 0.3265 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.012s\n",
      "| AdaDelta | epoch: 008 | loss: 0.00000 - binary_acc: 0.3265 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.011s\n",
      "| AdaDelta | epoch: 009 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.014s\n",
      "| AdaDelta | epoch: 010 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.014s\n",
      "| AdaDelta | epoch: 011 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.013s\n",
      "| AdaDelta | epoch: 012 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.009s\n",
      "| AdaDelta | epoch: 013 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.013s\n",
      "| AdaDelta | epoch: 014 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.010s\n",
      "| AdaDelta | epoch: 015 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.023s\n",
      "| AdaDelta | epoch: 016 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.013s\n",
      "| AdaDelta | epoch: 017 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.014s\n",
      "| AdaDelta | epoch: 018 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.011s\n",
      "| AdaDelta | epoch: 019 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.012s\n",
      "| AdaDelta | epoch: 020 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.012s\n",
      "| AdaDelta | epoch: 021 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.019s\n",
      "| AdaDelta | epoch: 022 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.011s\n",
      "| AdaDelta | epoch: 023 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.012s\n",
      "| AdaDelta | epoch: 024 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.012s\n",
      "| AdaDelta | epoch: 025 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.011s\n",
      "| AdaDelta | epoch: 026 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.011s\n",
      "| AdaDelta | epoch: 027 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.013s\n",
      "| AdaDelta | epoch: 028 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.012s\n",
      "| AdaDelta | epoch: 029 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.012s\n",
      "| AdaDelta | epoch: 030 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'softmax', 100, [0.3002028369758482]]\n",
      "AdaDelta\n",
      "softmax\n",
      "35\n",
      "---------------------------------\n",
      "Run id: MB3AHX\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.131s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.009s\n",
      "| AdaDelta | epoch: 002 | loss: 0.00000 - binary_acc: 0.2876 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.010s\n",
      "| AdaDelta | epoch: 003 | loss: 0.00000 - binary_acc: 0.3138 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.010s\n",
      "| AdaDelta | epoch: 004 | loss: 0.00000 - binary_acc: 0.3181 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.010s\n",
      "| AdaDelta | epoch: 005 | loss: 0.00000 - binary_acc: 0.3191 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.010s\n",
      "| AdaDelta | epoch: 006 | loss: 0.00000 - binary_acc: 0.3194 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.009s\n",
      "| AdaDelta | epoch: 007 | loss: 0.00000 - binary_acc: 0.3195 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.010s\n",
      "| AdaDelta | epoch: 008 | loss: 0.00000 - binary_acc: 0.3196 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.010s\n",
      "| AdaDelta | epoch: 009 | loss: 0.00000 - binary_acc: 0.3196 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.007s\n",
      "| AdaDelta | epoch: 010 | loss: 0.00000 - binary_acc: 0.3196 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.010s\n",
      "| AdaDelta | epoch: 011 | loss: 0.00000 - binary_acc: 0.3196 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.011s\n",
      "| AdaDelta | epoch: 012 | loss: 0.00000 - binary_acc: 0.3196 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.009s\n",
      "| AdaDelta | epoch: 013 | loss: 0.00000 - binary_acc: 0.3196 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.010s\n",
      "| AdaDelta | epoch: 014 | loss: 0.00000 - binary_acc: 0.3196 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.009s\n",
      "| AdaDelta | epoch: 015 | loss: 0.00000 - binary_acc: 0.3196 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.009s\n",
      "| AdaDelta | epoch: 016 | loss: 0.00000 - binary_acc: 0.3196 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.009s\n",
      "| AdaDelta | epoch: 017 | loss: 0.00000 - binary_acc: 0.3196 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.009s\n",
      "| AdaDelta | epoch: 018 | loss: 0.00000 - binary_acc: 0.3196 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.008s\n",
      "| AdaDelta | epoch: 019 | loss: 0.00000 - binary_acc: 0.3196 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.009s\n",
      "| AdaDelta | epoch: 020 | loss: 0.00000 - binary_acc: 0.3196 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.009s\n",
      "| AdaDelta | epoch: 021 | loss: 0.00000 - binary_acc: 0.3196 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.009s\n",
      "| AdaDelta | epoch: 022 | loss: 0.00000 - binary_acc: 0.3196 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.009s\n",
      "| AdaDelta | epoch: 023 | loss: 0.00000 - binary_acc: 0.3196 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.010s\n",
      "| AdaDelta | epoch: 024 | loss: 0.00000 - binary_acc: 0.3196 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.009s\n",
      "| AdaDelta | epoch: 025 | loss: 0.00000 - binary_acc: 0.3196 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.009s\n",
      "| AdaDelta | epoch: 026 | loss: 0.00000 - binary_acc: 0.3196 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.009s\n",
      "| AdaDelta | epoch: 027 | loss: 0.00000 - binary_acc: 0.3196 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.010s\n",
      "| AdaDelta | epoch: 028 | loss: 0.00000 - binary_acc: 0.3196 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.008s\n",
      "| AdaDelta | epoch: 029 | loss: 0.00000 - binary_acc: 0.3196 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.010s\n",
      "| AdaDelta | epoch: 030 | loss: 0.00000 - binary_acc: 0.3196 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'softmax', 35, [0.3002028369758482]]\n",
      "AdaDelta\n",
      "sigmoid\n",
      "1000\n",
      "---------------------------------\n",
      "Run id: HLU9UY\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.351s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.102s\n",
      "| AdaDelta | epoch: 002 | loss: 0.00000 - binary_acc: 0.2899 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.099s\n",
      "| AdaDelta | epoch: 003 | loss: 0.00000 - binary_acc: 0.3163 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.092s\n",
      "| AdaDelta | epoch: 004 | loss: 0.00000 - binary_acc: 0.3207 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.091s\n",
      "| AdaDelta | epoch: 005 | loss: 0.00000 - binary_acc: 0.3217 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.166s\n",
      "| AdaDelta | epoch: 006 | loss: 0.00000 - binary_acc: 0.3220 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.096s\n",
      "| AdaDelta | epoch: 007 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.092s\n",
      "| AdaDelta | epoch: 008 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.094s\n",
      "| AdaDelta | epoch: 009 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.095s\n",
      "| AdaDelta | epoch: 010 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.101s\n",
      "| AdaDelta | epoch: 011 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.100s\n",
      "| AdaDelta | epoch: 012 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.101s\n",
      "| AdaDelta | epoch: 013 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.111s\n",
      "| AdaDelta | epoch: 014 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.099s\n",
      "| AdaDelta | epoch: 015 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.097s\n",
      "| AdaDelta | epoch: 016 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.092s\n",
      "| AdaDelta | epoch: 017 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.095s\n",
      "| AdaDelta | epoch: 018 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.093s\n",
      "| AdaDelta | epoch: 019 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.093s\n",
      "| AdaDelta | epoch: 020 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.092s\n",
      "| AdaDelta | epoch: 021 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.096s\n",
      "| AdaDelta | epoch: 022 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.095s\n",
      "| AdaDelta | epoch: 023 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.091s\n",
      "| AdaDelta | epoch: 024 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.097s\n",
      "| AdaDelta | epoch: 025 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.102s\n",
      "| AdaDelta | epoch: 026 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.098s\n",
      "| AdaDelta | epoch: 027 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.094s\n",
      "| AdaDelta | epoch: 028 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.092s\n",
      "| AdaDelta | epoch: 029 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.112s\n",
      "| AdaDelta | epoch: 030 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'sigmoid', 1000, [0.3002028369758482]]\n",
      "AdaDelta\n",
      "sigmoid\n",
      "100\n",
      "---------------------------------\n",
      "Run id: C5TLZA\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.118s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.010s\n",
      "| AdaDelta | epoch: 002 | loss: 0.00000 - binary_acc: 0.2831 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.011s\n",
      "| AdaDelta | epoch: 003 | loss: 0.00000 - binary_acc: 0.3088 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.011s\n",
      "| AdaDelta | epoch: 004 | loss: 0.00000 - binary_acc: 0.3131 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.011s\n",
      "| AdaDelta | epoch: 005 | loss: 0.00000 - binary_acc: 0.3141 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.016s\n",
      "| AdaDelta | epoch: 006 | loss: 0.00000 - binary_acc: 0.3144 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.010s\n",
      "| AdaDelta | epoch: 007 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.011s\n",
      "| AdaDelta | epoch: 008 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.011s\n",
      "| AdaDelta | epoch: 009 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.010s\n",
      "| AdaDelta | epoch: 010 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.010s\n",
      "| AdaDelta | epoch: 011 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.010s\n",
      "| AdaDelta | epoch: 012 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.011s\n",
      "| AdaDelta | epoch: 013 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.011s\n",
      "| AdaDelta | epoch: 014 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.010s\n",
      "| AdaDelta | epoch: 015 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.011s\n",
      "| AdaDelta | epoch: 016 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.010s\n",
      "| AdaDelta | epoch: 017 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.009s\n",
      "| AdaDelta | epoch: 018 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.009s\n",
      "| AdaDelta | epoch: 019 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.011s\n",
      "| AdaDelta | epoch: 020 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.012s\n",
      "| AdaDelta | epoch: 021 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.010s\n",
      "| AdaDelta | epoch: 022 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.011s\n",
      "| AdaDelta | epoch: 023 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.010s\n",
      "| AdaDelta | epoch: 024 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.010s\n",
      "| AdaDelta | epoch: 025 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.012s\n",
      "| AdaDelta | epoch: 026 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.010s\n",
      "| AdaDelta | epoch: 027 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.012s\n",
      "| AdaDelta | epoch: 028 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.011s\n",
      "| AdaDelta | epoch: 029 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.010s\n",
      "| AdaDelta | epoch: 030 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'sigmoid', 100, [0.3002028369758482]]\n",
      "AdaDelta\n",
      "sigmoid\n",
      "35\n",
      "---------------------------------\n",
      "Run id: C8RXU0\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.160s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.007s\n",
      "| AdaDelta | epoch: 002 | loss: 0.00000 - binary_acc: 0.2893 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.008s\n",
      "| AdaDelta | epoch: 003 | loss: 0.00000 - binary_acc: 0.3157 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.008s\n",
      "| AdaDelta | epoch: 004 | loss: 0.00000 - binary_acc: 0.3200 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.008s\n",
      "| AdaDelta | epoch: 005 | loss: 0.00000 - binary_acc: 0.3210 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.009s\n",
      "| AdaDelta | epoch: 006 | loss: 0.00000 - binary_acc: 0.3213 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.009s\n",
      "| AdaDelta | epoch: 007 | loss: 0.00000 - binary_acc: 0.3214 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.009s\n",
      "| AdaDelta | epoch: 008 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.008s\n",
      "| AdaDelta | epoch: 009 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.009s\n",
      "| AdaDelta | epoch: 010 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.009s\n",
      "| AdaDelta | epoch: 011 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.007s\n",
      "| AdaDelta | epoch: 012 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.009s\n",
      "| AdaDelta | epoch: 013 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.008s\n",
      "| AdaDelta | epoch: 014 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.008s\n",
      "| AdaDelta | epoch: 015 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.008s\n",
      "| AdaDelta | epoch: 016 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.009s\n",
      "| AdaDelta | epoch: 017 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.009s\n",
      "| AdaDelta | epoch: 018 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.009s\n",
      "| AdaDelta | epoch: 019 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.009s\n",
      "| AdaDelta | epoch: 020 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.008s\n",
      "| AdaDelta | epoch: 021 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.005s\n",
      "| AdaDelta | epoch: 022 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.009s\n",
      "| AdaDelta | epoch: 023 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.008s\n",
      "| AdaDelta | epoch: 024 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.010s\n",
      "| AdaDelta | epoch: 025 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.009s\n",
      "| AdaDelta | epoch: 026 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.009s\n",
      "| AdaDelta | epoch: 027 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.009s\n",
      "| AdaDelta | epoch: 028 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.008s\n",
      "| AdaDelta | epoch: 029 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.008s\n",
      "| AdaDelta | epoch: 030 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'sigmoid', 35, [0.3002028369758482]]\n",
      "AdaDelta\n",
      "tanh\n",
      "1000\n",
      "---------------------------------\n",
      "Run id: PSHT9V\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.830s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.092s\n",
      "| AdaDelta | epoch: 002 | loss: 0.00000 - binary_acc: 0.2437 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.097s\n",
      "| AdaDelta | epoch: 003 | loss: 0.00000 - binary_acc: 0.2658 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.091s\n",
      "| AdaDelta | epoch: 004 | loss: 0.00000 - binary_acc: 0.2695 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.096s\n",
      "| AdaDelta | epoch: 005 | loss: 0.00000 - binary_acc: 0.2704 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.102s\n",
      "| AdaDelta | epoch: 006 | loss: 0.00000 - binary_acc: 0.3338 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.089s\n",
      "| AdaDelta | epoch: 007 | loss: 0.00000 - binary_acc: 0.2960 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.097s\n",
      "| AdaDelta | epoch: 008 | loss: 0.00000 - binary_acc: 0.3496 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.101s\n",
      "| AdaDelta | epoch: 009 | loss: 0.00000 - binary_acc: 0.3079 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.094s\n",
      "| AdaDelta | epoch: 010 | loss: 0.00000 - binary_acc: 0.3312 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.092s\n",
      "| AdaDelta | epoch: 011 | loss: 0.00000 - binary_acc: 0.3026 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.093s\n",
      "| AdaDelta | epoch: 012 | loss: 0.00000 - binary_acc: 0.3350 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.102s\n",
      "| AdaDelta | epoch: 013 | loss: 0.00000 - binary_acc: 0.3075 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.101s\n",
      "| AdaDelta | epoch: 014 | loss: 0.00000 - binary_acc: 0.3353 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.093s\n",
      "| AdaDelta | epoch: 015 | loss: 0.00000 - binary_acc: 0.3100 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.094s\n",
      "| AdaDelta | epoch: 016 | loss: 0.00000 - binary_acc: 0.2953 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.094s\n",
      "| AdaDelta | epoch: 017 | loss: 0.00000 - binary_acc: 0.2865 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.099s\n",
      "| AdaDelta | epoch: 018 | loss: 0.00000 - binary_acc: 0.3096 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.096s\n",
      "| AdaDelta | epoch: 019 | loss: 0.00000 - binary_acc: 0.2966 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.101s\n",
      "| AdaDelta | epoch: 020 | loss: 0.00000 - binary_acc: 0.3136 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.091s\n",
      "| AdaDelta | epoch: 021 | loss: 0.00000 - binary_acc: 0.3003 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.096s\n",
      "| AdaDelta | epoch: 022 | loss: 0.00000 - binary_acc: 0.3186 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.101s\n",
      "| AdaDelta | epoch: 023 | loss: 0.00000 - binary_acc: 0.3047 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.094s\n",
      "| AdaDelta | epoch: 024 | loss: 0.00000 - binary_acc: 0.3187 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.108s\n",
      "| AdaDelta | epoch: 025 | loss: 0.00000 - binary_acc: 0.3057 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.089s\n",
      "| AdaDelta | epoch: 026 | loss: 0.00000 - binary_acc: 0.3150 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.098s\n",
      "| AdaDelta | epoch: 027 | loss: 0.00000 - binary_acc: 0.3037 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.100s\n",
      "| AdaDelta | epoch: 028 | loss: 0.00000 - binary_acc: 0.3134 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.101s\n",
      "| AdaDelta | epoch: 029 | loss: 0.00000 - binary_acc: 0.3030 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.109s\n",
      "| AdaDelta | epoch: 030 | loss: 0.00000 - binary_acc: 0.3158 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'tanh', 1000, [0.2718052733500637]]\n",
      "AdaDelta\n",
      "tanh\n",
      "100\n",
      "---------------------------------\n",
      "Run id: WA42U6\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.127s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.5139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.010s\n",
      "| AdaDelta | epoch: 002 | loss: 0.00000 - binary_acc: 0.3424 | val_loss: 0.00000 - val_binary_acc: 0.5139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.010s\n",
      "| AdaDelta | epoch: 003 | loss: 0.00000 - binary_acc: 0.4649 | val_loss: 0.00000 - val_binary_acc: 0.5139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.017s\n",
      "| AdaDelta | epoch: 004 | loss: 0.00000 - binary_acc: 0.4111 | val_loss: 0.00000 - val_binary_acc: 0.5139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.011s\n",
      "| AdaDelta | epoch: 005 | loss: 0.00000 - binary_acc: 0.4672 | val_loss: 0.00000 - val_binary_acc: 0.5139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.010s\n",
      "| AdaDelta | epoch: 006 | loss: 0.00000 - binary_acc: 0.4253 | val_loss: 0.00000 - val_binary_acc: 0.5139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.010s\n",
      "| AdaDelta | epoch: 007 | loss: 0.00000 - binary_acc: 0.4654 | val_loss: 0.00000 - val_binary_acc: 0.5139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.010s\n",
      "| AdaDelta | epoch: 008 | loss: 0.00000 - binary_acc: 0.4205 | val_loss: 0.00000 - val_binary_acc: 0.5139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.011s\n",
      "| AdaDelta | epoch: 009 | loss: 0.00000 - binary_acc: 0.4584 | val_loss: 0.00000 - val_binary_acc: 0.5139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.012s\n",
      "| AdaDelta | epoch: 010 | loss: 0.00000 - binary_acc: 0.4315 | val_loss: 0.00000 - val_binary_acc: 0.5139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.010s\n",
      "| AdaDelta | epoch: 011 | loss: 0.00000 - binary_acc: 0.4602 | val_loss: 0.00000 - val_binary_acc: 0.5139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.011s\n",
      "| AdaDelta | epoch: 012 | loss: 0.00000 - binary_acc: 0.4403 | val_loss: 0.00000 - val_binary_acc: 0.5139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.011s\n",
      "| AdaDelta | epoch: 013 | loss: 0.00000 - binary_acc: 0.4625 | val_loss: 0.00000 - val_binary_acc: 0.5139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.012s\n",
      "| AdaDelta | epoch: 014 | loss: 0.00000 - binary_acc: 0.4385 | val_loss: 0.00000 - val_binary_acc: 0.5139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.011s\n",
      "| AdaDelta | epoch: 015 | loss: 0.00000 - binary_acc: 0.4595 | val_loss: 0.00000 - val_binary_acc: 0.5139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.010s\n",
      "| AdaDelta | epoch: 016 | loss: 0.00000 - binary_acc: 0.4451 | val_loss: 0.00000 - val_binary_acc: 0.5139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.013s\n",
      "| AdaDelta | epoch: 017 | loss: 0.00000 - binary_acc: 0.4620 | val_loss: 0.00000 - val_binary_acc: 0.5139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.010s\n",
      "| AdaDelta | epoch: 018 | loss: 0.00000 - binary_acc: 0.4480 | val_loss: 0.00000 - val_binary_acc: 0.5139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.010s\n",
      "| AdaDelta | epoch: 019 | loss: 0.00000 - binary_acc: 0.4627 | val_loss: 0.00000 - val_binary_acc: 0.5139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.010s\n",
      "| AdaDelta | epoch: 020 | loss: 0.00000 - binary_acc: 0.4524 | val_loss: 0.00000 - val_binary_acc: 0.5139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.012s\n",
      "| AdaDelta | epoch: 021 | loss: 0.00000 - binary_acc: 0.4647 | val_loss: 0.00000 - val_binary_acc: 0.5139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.009s\n",
      "| AdaDelta | epoch: 022 | loss: 0.00000 - binary_acc: 0.4579 | val_loss: 0.00000 - val_binary_acc: 0.5139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.010s\n",
      "| AdaDelta | epoch: 023 | loss: 0.00000 - binary_acc: 0.4678 | val_loss: 0.00000 - val_binary_acc: 0.5139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.010s\n",
      "| AdaDelta | epoch: 024 | loss: 0.00000 - binary_acc: 0.4559 | val_loss: 0.00000 - val_binary_acc: 0.5139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.011s\n",
      "| AdaDelta | epoch: 025 | loss: 0.00000 - binary_acc: 0.4658 | val_loss: 0.00000 - val_binary_acc: 0.5139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.011s\n",
      "| AdaDelta | epoch: 026 | loss: 0.00000 - binary_acc: 0.4593 | val_loss: 0.00000 - val_binary_acc: 0.5139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.011s\n",
      "| AdaDelta | epoch: 027 | loss: 0.00000 - binary_acc: 0.4677 | val_loss: 0.00000 - val_binary_acc: 0.5139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.011s\n",
      "| AdaDelta | epoch: 028 | loss: 0.00000 - binary_acc: 0.4608 | val_loss: 0.00000 - val_binary_acc: 0.5139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.010s\n",
      "| AdaDelta | epoch: 029 | loss: 0.00000 - binary_acc: 0.4684 | val_loss: 0.00000 - val_binary_acc: 0.5139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.011s\n",
      "| AdaDelta | epoch: 030 | loss: 0.00000 - binary_acc: 0.4632 | val_loss: 0.00000 - val_binary_acc: 0.5139 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'tanh', 100, [0.4847870206736164]]\n",
      "AdaDelta\n",
      "tanh\n",
      "35\n",
      "---------------------------------\n",
      "Run id: 92YBRT\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.130s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.006s\n",
      "| AdaDelta | epoch: 002 | loss: 0.00000 - binary_acc: 0.3367 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.011s\n",
      "| AdaDelta | epoch: 003 | loss: 0.00000 - binary_acc: 0.2729 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.010s\n",
      "| AdaDelta | epoch: 004 | loss: 0.00000 - binary_acc: 0.3426 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.009s\n",
      "| AdaDelta | epoch: 005 | loss: 0.00000 - binary_acc: 0.2845 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.009s\n",
      "| AdaDelta | epoch: 006 | loss: 0.00000 - binary_acc: 0.3067 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.008s\n",
      "| AdaDelta | epoch: 007 | loss: 0.00000 - binary_acc: 0.2779 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.008s\n",
      "| AdaDelta | epoch: 008 | loss: 0.00000 - binary_acc: 0.2671 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.008s\n",
      "| AdaDelta | epoch: 009 | loss: 0.00000 - binary_acc: 0.2627 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.009s\n",
      "| AdaDelta | epoch: 010 | loss: 0.00000 - binary_acc: 0.3098 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.009s\n",
      "| AdaDelta | epoch: 011 | loss: 0.00000 - binary_acc: 0.2856 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.009s\n",
      "| AdaDelta | epoch: 012 | loss: 0.00000 - binary_acc: 0.3189 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.008s\n",
      "| AdaDelta | epoch: 013 | loss: 0.00000 - binary_acc: 0.2931 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.009s\n",
      "| AdaDelta | epoch: 014 | loss: 0.00000 - binary_acc: 0.3224 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.008s\n",
      "| AdaDelta | epoch: 015 | loss: 0.00000 - binary_acc: 0.2975 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.009s\n",
      "| AdaDelta | epoch: 016 | loss: 0.00000 - binary_acc: 0.3205 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.009s\n",
      "| AdaDelta | epoch: 017 | loss: 0.00000 - binary_acc: 0.2983 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.008s\n",
      "| AdaDelta | epoch: 018 | loss: 0.00000 - binary_acc: 0.2846 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.008s\n",
      "| AdaDelta | epoch: 019 | loss: 0.00000 - binary_acc: 0.2760 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.008s\n",
      "| AdaDelta | epoch: 020 | loss: 0.00000 - binary_acc: 0.3002 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.008s\n",
      "| AdaDelta | epoch: 021 | loss: 0.00000 - binary_acc: 0.2873 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.009s\n",
      "| AdaDelta | epoch: 022 | loss: 0.00000 - binary_acc: 0.3103 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.008s\n",
      "| AdaDelta | epoch: 023 | loss: 0.00000 - binary_acc: 0.2953 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.009s\n",
      "| AdaDelta | epoch: 024 | loss: 0.00000 - binary_acc: 0.3082 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.008s\n",
      "| AdaDelta | epoch: 025 | loss: 0.00000 - binary_acc: 0.2947 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.008s\n",
      "| AdaDelta | epoch: 026 | loss: 0.00000 - binary_acc: 0.3085 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.009s\n",
      "| AdaDelta | epoch: 027 | loss: 0.00000 - binary_acc: 0.2957 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.009s\n",
      "| AdaDelta | epoch: 028 | loss: 0.00000 - binary_acc: 0.3088 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.009s\n",
      "| AdaDelta | epoch: 029 | loss: 0.00000 - binary_acc: 0.2966 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.008s\n",
      "| AdaDelta | epoch: 030 | loss: 0.00000 - binary_acc: 0.3072 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'tanh', 35, [0.27180527449863195]]\n",
      "AdaDelta\n",
      "prelu\n",
      "1000\n",
      "---------------------------------\n",
      "Run id: IQ6V3L\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 2.610s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.112s\n",
      "| AdaDelta | epoch: 002 | loss: nan - binary_acc: 0.3989 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.112s\n",
      "| AdaDelta | epoch: 003 | loss: nan - binary_acc: 0.4336 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.115s\n",
      "| AdaDelta | epoch: 004 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.115s\n",
      "| AdaDelta | epoch: 005 | loss: nan - binary_acc: 0.4408 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.116s\n",
      "| AdaDelta | epoch: 006 | loss: nan - binary_acc: 0.4411 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.115s\n",
      "| AdaDelta | epoch: 007 | loss: nan - binary_acc: 0.4413 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.115s\n",
      "| AdaDelta | epoch: 008 | loss: nan - binary_acc: 0.4413 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.119s\n",
      "| AdaDelta | epoch: 009 | loss: nan - binary_acc: 0.4413 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.117s\n",
      "| AdaDelta | epoch: 010 | loss: nan - binary_acc: 0.4413 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.115s\n",
      "| AdaDelta | epoch: 011 | loss: nan - binary_acc: 0.4413 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.108s\n",
      "| AdaDelta | epoch: 012 | loss: nan - binary_acc: 0.4413 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.133s\n",
      "| AdaDelta | epoch: 013 | loss: nan - binary_acc: 0.4413 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.115s\n",
      "| AdaDelta | epoch: 014 | loss: nan - binary_acc: 0.4413 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.115s\n",
      "| AdaDelta | epoch: 015 | loss: nan - binary_acc: 0.4413 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.115s\n",
      "| AdaDelta | epoch: 016 | loss: nan - binary_acc: 0.4413 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.115s\n",
      "| AdaDelta | epoch: 017 | loss: nan - binary_acc: 0.4413 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.121s\n",
      "| AdaDelta | epoch: 018 | loss: nan - binary_acc: 0.4413 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.111s\n",
      "| AdaDelta | epoch: 019 | loss: nan - binary_acc: 0.4413 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.114s\n",
      "| AdaDelta | epoch: 020 | loss: nan - binary_acc: 0.4413 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.133s\n",
      "| AdaDelta | epoch: 021 | loss: nan - binary_acc: 0.4413 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.114s\n",
      "| AdaDelta | epoch: 022 | loss: nan - binary_acc: 0.4413 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.117s\n",
      "| AdaDelta | epoch: 023 | loss: nan - binary_acc: 0.4413 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.112s\n",
      "| AdaDelta | epoch: 024 | loss: nan - binary_acc: 0.4413 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.115s\n",
      "| AdaDelta | epoch: 025 | loss: nan - binary_acc: 0.4413 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.118s\n",
      "| AdaDelta | epoch: 026 | loss: nan - binary_acc: 0.4413 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.116s\n",
      "| AdaDelta | epoch: 027 | loss: nan - binary_acc: 0.4413 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.111s\n",
      "| AdaDelta | epoch: 028 | loss: nan - binary_acc: 0.4413 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.120s\n",
      "| AdaDelta | epoch: 029 | loss: nan - binary_acc: 0.4413 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.125s\n",
      "| AdaDelta | epoch: 030 | loss: nan - binary_acc: 0.4413 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'prelu', 1000, [0.45436105404132276]]\n",
      "AdaDelta\n",
      "prelu\n",
      "100\n",
      "---------------------------------\n",
      "Run id: PO1PRW\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.159s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaDelta | epoch: 002 | loss: nan - binary_acc: 0.3521 | val_loss: nan - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| AdaDelta | epoch: 003 | loss: nan - binary_acc: 0.4194 | val_loss: nan - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| AdaDelta | epoch: 004 | loss: nan - binary_acc: 0.4306 | val_loss: nan - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| AdaDelta | epoch: 005 | loss: nan - binary_acc: 0.4332 | val_loss: nan - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| AdaDelta | epoch: 006 | loss: nan - binary_acc: 0.4340 | val_loss: nan - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| AdaDelta | epoch: 007 | loss: nan - binary_acc: 0.4342 | val_loss: nan - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| AdaDelta | epoch: 008 | loss: nan - binary_acc: 0.4343 | val_loss: nan - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| AdaDelta | epoch: 009 | loss: nan - binary_acc: 0.4343 | val_loss: nan - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| AdaDelta | epoch: 010 | loss: nan - binary_acc: 0.4344 | val_loss: nan - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| AdaDelta | epoch: 011 | loss: nan - binary_acc: 0.4344 | val_loss: nan - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| AdaDelta | epoch: 012 | loss: nan - binary_acc: 0.4344 | val_loss: nan - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| AdaDelta | epoch: 013 | loss: nan - binary_acc: 0.4344 | val_loss: nan - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| AdaDelta | epoch: 014 | loss: nan - binary_acc: 0.4344 | val_loss: nan - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| AdaDelta | epoch: 015 | loss: nan - binary_acc: 0.4344 | val_loss: nan - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaDelta | epoch: 016 | loss: nan - binary_acc: 0.4344 | val_loss: nan - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaDelta | epoch: 017 | loss: nan - binary_acc: 0.4344 | val_loss: nan - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| AdaDelta | epoch: 018 | loss: nan - binary_acc: 0.4344 | val_loss: nan - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| AdaDelta | epoch: 019 | loss: nan - binary_acc: 0.4344 | val_loss: nan - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| AdaDelta | epoch: 020 | loss: nan - binary_acc: 0.4344 | val_loss: nan - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.016s\n",
      "| AdaDelta | epoch: 021 | loss: nan - binary_acc: 0.4344 | val_loss: nan - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| AdaDelta | epoch: 022 | loss: nan - binary_acc: 0.4344 | val_loss: nan - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| AdaDelta | epoch: 023 | loss: nan - binary_acc: 0.4344 | val_loss: nan - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| AdaDelta | epoch: 024 | loss: nan - binary_acc: 0.4344 | val_loss: nan - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| AdaDelta | epoch: 025 | loss: nan - binary_acc: 0.4344 | val_loss: nan - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| AdaDelta | epoch: 026 | loss: nan - binary_acc: 0.4344 | val_loss: nan - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| AdaDelta | epoch: 027 | loss: nan - binary_acc: 0.4344 | val_loss: nan - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| AdaDelta | epoch: 028 | loss: nan - binary_acc: 0.4344 | val_loss: nan - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaDelta | epoch: 029 | loss: nan - binary_acc: 0.4344 | val_loss: nan - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| AdaDelta | epoch: 030 | loss: nan - binary_acc: 0.4344 | val_loss: nan - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'prelu', 100, [0.45436105404132276]]\n",
      "AdaDelta\n",
      "prelu\n",
      "35\n",
      "---------------------------------\n",
      "Run id: U8B429\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.149s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 002 | loss: nan - binary_acc: 0.3601 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 003 | loss: nan - binary_acc: 0.4250 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 004 | loss: nan - binary_acc: 0.4358 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 005 | loss: nan - binary_acc: 0.4383 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 006 | loss: nan - binary_acc: 0.4390 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 007 | loss: nan - binary_acc: 0.4393 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaDelta | epoch: 008 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 009 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 010 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 011 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 012 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 013 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 014 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 015 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 016 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 017 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 018 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 019 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaDelta | epoch: 020 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 021 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 022 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 023 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 024 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 025 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 026 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 027 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaDelta | epoch: 028 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 029 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 030 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'prelu', 35, [0.45436105404132276]]\n",
      "RMSProp\n",
      "relu\n",
      "1000\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/training/rmsprop.py:123: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "---------------------------------\n",
      "Run id: 9ADV1P\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.531s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.083s\n",
      "| RMSProp | epoch: 002 | loss: nan - binary_acc: 0.3236 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.084s\n",
      "| RMSProp | epoch: 003 | loss: nan - binary_acc: 0.4215 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.091s\n",
      "| RMSProp | epoch: 004 | loss: nan - binary_acc: 0.4378 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.083s\n",
      "| RMSProp | epoch: 005 | loss: nan - binary_acc: 0.4416 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.087s\n",
      "| RMSProp | epoch: 006 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.093s\n",
      "| RMSProp | epoch: 007 | loss: nan - binary_acc: 0.4430 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.091s\n",
      "| RMSProp | epoch: 008 | loss: nan - binary_acc: 0.4431 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.108s\n",
      "| RMSProp | epoch: 009 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.102s\n",
      "| RMSProp | epoch: 010 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.107s\n",
      "| RMSProp | epoch: 011 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.089s\n",
      "| RMSProp | epoch: 012 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.099s\n",
      "| RMSProp | epoch: 013 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.111s\n",
      "| RMSProp | epoch: 014 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.099s\n",
      "| RMSProp | epoch: 015 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.083s\n",
      "| RMSProp | epoch: 016 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.082s\n",
      "| RMSProp | epoch: 017 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.082s\n",
      "| RMSProp | epoch: 018 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.094s\n",
      "| RMSProp | epoch: 019 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.092s\n",
      "| RMSProp | epoch: 020 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.085s\n",
      "| RMSProp | epoch: 021 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.096s\n",
      "| RMSProp | epoch: 022 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.083s\n",
      "| RMSProp | epoch: 023 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.084s\n",
      "| RMSProp | epoch: 024 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.081s\n",
      "| RMSProp | epoch: 025 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.098s\n",
      "| RMSProp | epoch: 026 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.082s\n",
      "| RMSProp | epoch: 027 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.092s\n",
      "| RMSProp | epoch: 028 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.084s\n",
      "| RMSProp | epoch: 029 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.080s\n",
      "| RMSProp | epoch: 030 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'relu', 1000, [0.45436105404132276]]\n",
      "RMSProp\n",
      "relu\n",
      "100\n",
      "---------------------------------\n",
      "Run id: 77L5YN\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.109s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 002 | loss: nan - binary_acc: 0.3921 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| RMSProp | epoch: 003 | loss: nan - binary_acc: 0.4308 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| RMSProp | epoch: 004 | loss: nan - binary_acc: 0.4373 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| RMSProp | epoch: 005 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| RMSProp | epoch: 006 | loss: nan - binary_acc: 0.4392 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 007 | loss: nan - binary_acc: 0.4393 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| RMSProp | epoch: 008 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| RMSProp | epoch: 009 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 010 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| RMSProp | epoch: 011 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 012 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 013 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| RMSProp | epoch: 014 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 015 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 016 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| RMSProp | epoch: 017 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| RMSProp | epoch: 018 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 019 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 020 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 021 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| RMSProp | epoch: 022 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 023 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| RMSProp | epoch: 024 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 025 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| RMSProp | epoch: 026 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 027 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| RMSProp | epoch: 028 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| RMSProp | epoch: 029 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 030 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'relu', 100, [0.45436105404132276]]\n",
      "RMSProp\n",
      "relu\n",
      "35\n",
      "---------------------------------\n",
      "Run id: Q2WTXF\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.109s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.006s\n",
      "| RMSProp | epoch: 002 | loss: nan - binary_acc: 0.2871 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| RMSProp | epoch: 003 | loss: nan - binary_acc: 0.4123 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 004 | loss: nan - binary_acc: 0.4331 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| RMSProp | epoch: 005 | loss: nan - binary_acc: 0.4379 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| RMSProp | epoch: 006 | loss: nan - binary_acc: 0.4393 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.006s\n",
      "| RMSProp | epoch: 007 | loss: nan - binary_acc: 0.4398 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 008 | loss: nan - binary_acc: 0.4399 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 009 | loss: nan - binary_acc: 0.4400 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| RMSProp | epoch: 010 | loss: nan - binary_acc: 0.4400 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| RMSProp | epoch: 011 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| RMSProp | epoch: 012 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 013 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| RMSProp | epoch: 014 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| RMSProp | epoch: 015 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 016 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 017 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 018 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 019 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 020 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 021 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 022 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 023 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 024 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 025 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 026 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 027 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 028 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 029 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 030 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'relu', 35, [0.45436105404132276]]\n",
      "RMSProp\n",
      "linear\n",
      "1000\n",
      "---------------------------------\n",
      "Run id: BM4WID\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.219s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.4709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.078s\n",
      "| RMSProp | epoch: 002 | loss: 0.00000 - binary_acc: 0.3944 | val_loss: 0.00000 - val_binary_acc: 0.4709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.080s\n",
      "| RMSProp | epoch: 003 | loss: 0.00000 - binary_acc: 0.4878 | val_loss: 0.00000 - val_binary_acc: 0.4709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.080s\n",
      "| RMSProp | epoch: 004 | loss: 0.00000 - binary_acc: 0.4106 | val_loss: 0.00000 - val_binary_acc: 0.4709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.097s\n",
      "| RMSProp | epoch: 005 | loss: 0.00000 - binary_acc: 0.4784 | val_loss: 0.00000 - val_binary_acc: 0.4709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.125s\n",
      "| RMSProp | epoch: 006 | loss: 0.00000 - binary_acc: 0.4183 | val_loss: 0.00000 - val_binary_acc: 0.4709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.084s\n",
      "| RMSProp | epoch: 007 | loss: 0.00000 - binary_acc: 0.4725 | val_loss: 0.00000 - val_binary_acc: 0.4709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.090s\n",
      "| RMSProp | epoch: 008 | loss: 0.00000 - binary_acc: 0.4293 | val_loss: 0.00000 - val_binary_acc: 0.4709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.091s\n",
      "| RMSProp | epoch: 009 | loss: 0.00000 - binary_acc: 0.4712 | val_loss: 0.00000 - val_binary_acc: 0.4709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.088s\n",
      "| RMSProp | epoch: 010 | loss: 0.00000 - binary_acc: 0.4579 | val_loss: 0.00000 - val_binary_acc: 0.4709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.081s\n",
      "| RMSProp | epoch: 011 | loss: 0.00000 - binary_acc: 0.4819 | val_loss: 0.00000 - val_binary_acc: 0.4709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.098s\n",
      "| RMSProp | epoch: 012 | loss: 0.00000 - binary_acc: 0.4482 | val_loss: 0.00000 - val_binary_acc: 0.4709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.099s\n",
      "| RMSProp | epoch: 013 | loss: 0.00000 - binary_acc: 0.4741 | val_loss: 0.00000 - val_binary_acc: 0.4709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.090s\n",
      "| RMSProp | epoch: 014 | loss: 0.00000 - binary_acc: 0.4444 | val_loss: 0.00000 - val_binary_acc: 0.4709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.087s\n",
      "| RMSProp | epoch: 015 | loss: 0.00000 - binary_acc: 0.4695 | val_loss: 0.00000 - val_binary_acc: 0.4709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.081s\n",
      "| RMSProp | epoch: 016 | loss: 0.00000 - binary_acc: 0.4437 | val_loss: 0.00000 - val_binary_acc: 0.4709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.086s\n",
      "| RMSProp | epoch: 017 | loss: 0.00000 - binary_acc: 0.4671 | val_loss: 0.00000 - val_binary_acc: 0.4709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.087s\n",
      "| RMSProp | epoch: 018 | loss: 0.00000 - binary_acc: 0.4410 | val_loss: 0.00000 - val_binary_acc: 0.4709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.089s\n",
      "| RMSProp | epoch: 019 | loss: 0.00000 - binary_acc: 0.4635 | val_loss: 0.00000 - val_binary_acc: 0.4709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.097s\n",
      "| RMSProp | epoch: 020 | loss: 0.00000 - binary_acc: 0.4564 | val_loss: 0.00000 - val_binary_acc: 0.4709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.150s\n",
      "| RMSProp | epoch: 021 | loss: 0.00000 - binary_acc: 0.4726 | val_loss: 0.00000 - val_binary_acc: 0.4709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.097s\n",
      "| RMSProp | epoch: 022 | loss: 0.00000 - binary_acc: 0.4628 | val_loss: 0.00000 - val_binary_acc: 0.4709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.097s\n",
      "| RMSProp | epoch: 023 | loss: 0.00000 - binary_acc: 0.4761 | val_loss: 0.00000 - val_binary_acc: 0.4709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.081s\n",
      "| RMSProp | epoch: 024 | loss: 0.00000 - binary_acc: 0.4665 | val_loss: 0.00000 - val_binary_acc: 0.4709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.079s\n",
      "| RMSProp | epoch: 025 | loss: 0.00000 - binary_acc: 0.4780 | val_loss: 0.00000 - val_binary_acc: 0.4709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.081s\n",
      "| RMSProp | epoch: 026 | loss: 0.00000 - binary_acc: 0.4721 | val_loss: 0.00000 - val_binary_acc: 0.4709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.081s\n",
      "| RMSProp | epoch: 027 | loss: 0.00000 - binary_acc: 0.4815 | val_loss: 0.00000 - val_binary_acc: 0.4709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.083s\n",
      "| RMSProp | epoch: 028 | loss: 0.00000 - binary_acc: 0.4635 | val_loss: 0.00000 - val_binary_acc: 0.4709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.092s\n",
      "| RMSProp | epoch: 029 | loss: 0.00000 - binary_acc: 0.4745 | val_loss: 0.00000 - val_binary_acc: 0.4709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.085s\n",
      "| RMSProp | epoch: 030 | loss: 0.00000 - binary_acc: 0.4623 | val_loss: 0.00000 - val_binary_acc: 0.4709 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'linear', 1000, [0.49898580164019524]]\n",
      "RMSProp\n",
      "linear\n",
      "100\n",
      "---------------------------------\n",
      "Run id: D91PUF\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.104s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.009s\n",
      "| RMSProp | epoch: 002 | loss: 0.00000 - binary_acc: 0.3613 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.010s\n",
      "| RMSProp | epoch: 003 | loss: 0.00000 - binary_acc: 0.4813 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.009s\n",
      "| RMSProp | epoch: 004 | loss: 0.00000 - binary_acc: 0.5013 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.011s\n",
      "| RMSProp | epoch: 005 | loss: 0.00000 - binary_acc: 0.5059 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.012s\n",
      "| RMSProp | epoch: 006 | loss: 0.00000 - binary_acc: 0.5072 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.012s\n",
      "| RMSProp | epoch: 007 | loss: 0.00000 - binary_acc: 0.5076 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.011s\n",
      "| RMSProp | epoch: 008 | loss: 0.00000 - binary_acc: 0.4486 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.010s\n",
      "| RMSProp | epoch: 009 | loss: 0.00000 - binary_acc: 0.4800 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.010s\n",
      "| RMSProp | epoch: 010 | loss: 0.00000 - binary_acc: 0.4391 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.009s\n",
      "| RMSProp | epoch: 011 | loss: 0.00000 - binary_acc: 0.4717 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.010s\n",
      "| RMSProp | epoch: 012 | loss: 0.00000 - binary_acc: 0.4443 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.009s\n",
      "| RMSProp | epoch: 013 | loss: 0.00000 - binary_acc: 0.4716 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.010s\n",
      "| RMSProp | epoch: 014 | loss: 0.00000 - binary_acc: 0.4865 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.011s\n",
      "| RMSProp | epoch: 015 | loss: 0.00000 - binary_acc: 0.4949 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.011s\n",
      "| RMSProp | epoch: 016 | loss: 0.00000 - binary_acc: 0.4653 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.010s\n",
      "| RMSProp | epoch: 017 | loss: 0.00000 - binary_acc: 0.4806 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.011s\n",
      "| RMSProp | epoch: 018 | loss: 0.00000 - binary_acc: 0.4565 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.011s\n",
      "| RMSProp | epoch: 019 | loss: 0.00000 - binary_acc: 0.4736 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.010s\n",
      "| RMSProp | epoch: 020 | loss: 0.00000 - binary_acc: 0.4514 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.014s\n",
      "| RMSProp | epoch: 021 | loss: 0.00000 - binary_acc: 0.4690 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.011s\n",
      "| RMSProp | epoch: 022 | loss: 0.00000 - binary_acc: 0.4580 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.009s\n",
      "| RMSProp | epoch: 023 | loss: 0.00000 - binary_acc: 0.4725 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.011s\n",
      "| RMSProp | epoch: 024 | loss: 0.00000 - binary_acc: 0.4625 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.011s\n",
      "| RMSProp | epoch: 025 | loss: 0.00000 - binary_acc: 0.4749 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.008s\n",
      "| RMSProp | epoch: 026 | loss: 0.00000 - binary_acc: 0.4650 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.011s\n",
      "| RMSProp | epoch: 027 | loss: 0.00000 - binary_acc: 0.4760 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.011s\n",
      "| RMSProp | epoch: 028 | loss: 0.00000 - binary_acc: 0.4677 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.010s\n",
      "| RMSProp | epoch: 029 | loss: 0.00000 - binary_acc: 0.4775 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.012s\n",
      "| RMSProp | epoch: 030 | loss: 0.00000 - binary_acc: 0.4667 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'linear', 100, [0.5010141992061181]]\n",
      "RMSProp\n",
      "linear\n",
      "35\n",
      "---------------------------------\n",
      "Run id: O4SX2U\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.116s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.007s\n",
      "| RMSProp | epoch: 002 | loss: 0.00000 - binary_acc: 0.3504 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.008s\n",
      "| RMSProp | epoch: 003 | loss: 0.00000 - binary_acc: 0.3345 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.010s\n",
      "| RMSProp | epoch: 004 | loss: 0.00000 - binary_acc: 0.3752 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.008s\n",
      "| RMSProp | epoch: 005 | loss: 0.00000 - binary_acc: 0.3446 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.009s\n",
      "| RMSProp | epoch: 006 | loss: 0.00000 - binary_acc: 0.3725 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.008s\n",
      "| RMSProp | epoch: 007 | loss: 0.00000 - binary_acc: 0.3476 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.008s\n",
      "| RMSProp | epoch: 008 | loss: 0.00000 - binary_acc: 0.3686 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.008s\n",
      "| RMSProp | epoch: 009 | loss: 0.00000 - binary_acc: 0.3487 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.010s\n",
      "| RMSProp | epoch: 010 | loss: 0.00000 - binary_acc: 0.3468 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.009s\n",
      "| RMSProp | epoch: 011 | loss: 0.00000 - binary_acc: 0.3393 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.009s\n",
      "| RMSProp | epoch: 012 | loss: 0.00000 - binary_acc: 0.3564 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.007s\n",
      "| RMSProp | epoch: 013 | loss: 0.00000 - binary_acc: 0.3455 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.008s\n",
      "| RMSProp | epoch: 014 | loss: 0.00000 - binary_acc: 0.3401 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.009s\n",
      "| RMSProp | epoch: 015 | loss: 0.00000 - binary_acc: 0.3365 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.008s\n",
      "| RMSProp | epoch: 016 | loss: 0.00000 - binary_acc: 0.3352 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.007s\n",
      "| RMSProp | epoch: 017 | loss: 0.00000 - binary_acc: 0.3341 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.008s\n",
      "| RMSProp | epoch: 018 | loss: 0.00000 - binary_acc: 0.3511 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.008s\n",
      "| RMSProp | epoch: 019 | loss: 0.00000 - binary_acc: 0.3459 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.009s\n",
      "| RMSProp | epoch: 020 | loss: 0.00000 - binary_acc: 0.3423 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.008s\n",
      "| RMSProp | epoch: 021 | loss: 0.00000 - binary_acc: 0.3388 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.006s\n",
      "| RMSProp | epoch: 022 | loss: 0.00000 - binary_acc: 0.3477 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.008s\n",
      "| RMSProp | epoch: 023 | loss: 0.00000 - binary_acc: 0.3430 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.008s\n",
      "| RMSProp | epoch: 024 | loss: 0.00000 - binary_acc: 0.3446 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.009s\n",
      "| RMSProp | epoch: 025 | loss: 0.00000 - binary_acc: 0.3411 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.007s\n",
      "| RMSProp | epoch: 026 | loss: 0.00000 - binary_acc: 0.3522 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.009s\n",
      "| RMSProp | epoch: 027 | loss: 0.00000 - binary_acc: 0.3469 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.007s\n",
      "| RMSProp | epoch: 028 | loss: 0.00000 - binary_acc: 0.3528 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.010s\n",
      "| RMSProp | epoch: 029 | loss: 0.00000 - binary_acc: 0.3475 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.009s\n",
      "| RMSProp | epoch: 030 | loss: 0.00000 - binary_acc: 0.3575 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'linear', 35, [0.33265720032775137]]\n",
      "RMSProp\n",
      "softmax\n",
      "1000\n",
      "---------------------------------\n",
      "Run id: 5OFXCX\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.210s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.143s\n",
      "| RMSProp | epoch: 002 | loss: 0.00000 - binary_acc: 0.2831 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.097s\n",
      "| RMSProp | epoch: 003 | loss: 0.00000 - binary_acc: 0.3088 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.100s\n",
      "| RMSProp | epoch: 004 | loss: 0.00000 - binary_acc: 0.3131 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.098s\n",
      "| RMSProp | epoch: 005 | loss: 0.00000 - binary_acc: 0.3141 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.103s\n",
      "| RMSProp | epoch: 006 | loss: 0.00000 - binary_acc: 0.3144 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.097s\n",
      "| RMSProp | epoch: 007 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.096s\n",
      "| RMSProp | epoch: 008 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.101s\n",
      "| RMSProp | epoch: 009 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.098s\n",
      "| RMSProp | epoch: 010 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.099s\n",
      "| RMSProp | epoch: 011 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.101s\n",
      "| RMSProp | epoch: 012 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.100s\n",
      "| RMSProp | epoch: 013 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.097s\n",
      "| RMSProp | epoch: 014 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.101s\n",
      "| RMSProp | epoch: 015 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.105s\n",
      "| RMSProp | epoch: 016 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.102s\n",
      "| RMSProp | epoch: 017 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.099s\n",
      "| RMSProp | epoch: 018 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.103s\n",
      "| RMSProp | epoch: 019 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.099s\n",
      "| RMSProp | epoch: 020 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.102s\n",
      "| RMSProp | epoch: 021 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.099s\n",
      "| RMSProp | epoch: 022 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.094s\n",
      "| RMSProp | epoch: 023 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.103s\n",
      "| RMSProp | epoch: 024 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.096s\n",
      "| RMSProp | epoch: 025 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.103s\n",
      "| RMSProp | epoch: 026 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.098s\n",
      "| RMSProp | epoch: 027 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.098s\n",
      "| RMSProp | epoch: 028 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.145s\n",
      "| RMSProp | epoch: 029 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.096s\n",
      "| RMSProp | epoch: 030 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'softmax', 1000, [0.3002028369758482]]\n",
      "RMSProp\n",
      "softmax\n",
      "100\n",
      "---------------------------------\n",
      "Run id: C86R4I\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.127s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3620 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.010s\n",
      "| RMSProp | epoch: 002 | loss: 0.00000 - binary_acc: 0.2825 | val_loss: 0.00000 - val_binary_acc: 0.3620 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.011s\n",
      "| RMSProp | epoch: 003 | loss: 0.00000 - binary_acc: 0.3082 | val_loss: 0.00000 - val_binary_acc: 0.3620 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.009s\n",
      "| RMSProp | epoch: 004 | loss: 0.00000 - binary_acc: 0.3125 | val_loss: 0.00000 - val_binary_acc: 0.3620 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.012s\n",
      "| RMSProp | epoch: 005 | loss: 0.00000 - binary_acc: 0.3134 | val_loss: 0.00000 - val_binary_acc: 0.3620 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.013s\n",
      "| RMSProp | epoch: 006 | loss: 0.00000 - binary_acc: 0.3137 | val_loss: 0.00000 - val_binary_acc: 0.3620 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.011s\n",
      "| RMSProp | epoch: 007 | loss: 0.00000 - binary_acc: 0.3138 | val_loss: 0.00000 - val_binary_acc: 0.3620 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.013s\n",
      "| RMSProp | epoch: 008 | loss: 0.00000 - binary_acc: 0.3139 | val_loss: 0.00000 - val_binary_acc: 0.3620 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.012s\n",
      "| RMSProp | epoch: 009 | loss: 0.00000 - binary_acc: 0.3139 | val_loss: 0.00000 - val_binary_acc: 0.3620 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.012s\n",
      "| RMSProp | epoch: 010 | loss: 0.00000 - binary_acc: 0.3139 | val_loss: 0.00000 - val_binary_acc: 0.3620 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.013s\n",
      "| RMSProp | epoch: 011 | loss: 0.00000 - binary_acc: 0.3139 | val_loss: 0.00000 - val_binary_acc: 0.3620 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.011s\n",
      "| RMSProp | epoch: 012 | loss: 0.00000 - binary_acc: 0.3139 | val_loss: 0.00000 - val_binary_acc: 0.3620 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.011s\n",
      "| RMSProp | epoch: 013 | loss: 0.00000 - binary_acc: 0.3139 | val_loss: 0.00000 - val_binary_acc: 0.3620 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.013s\n",
      "| RMSProp | epoch: 014 | loss: 0.00000 - binary_acc: 0.3139 | val_loss: 0.00000 - val_binary_acc: 0.3620 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.012s\n",
      "| RMSProp | epoch: 015 | loss: 0.00000 - binary_acc: 0.3139 | val_loss: 0.00000 - val_binary_acc: 0.3620 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.011s\n",
      "| RMSProp | epoch: 016 | loss: 0.00000 - binary_acc: 0.3139 | val_loss: 0.00000 - val_binary_acc: 0.3620 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.014s\n",
      "| RMSProp | epoch: 017 | loss: 0.00000 - binary_acc: 0.3139 | val_loss: 0.00000 - val_binary_acc: 0.3620 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.011s\n",
      "| RMSProp | epoch: 018 | loss: 0.00000 - binary_acc: 0.3139 | val_loss: 0.00000 - val_binary_acc: 0.3620 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.012s\n",
      "| RMSProp | epoch: 019 | loss: 0.00000 - binary_acc: 0.3139 | val_loss: 0.00000 - val_binary_acc: 0.3620 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.011s\n",
      "| RMSProp | epoch: 020 | loss: 0.00000 - binary_acc: 0.3139 | val_loss: 0.00000 - val_binary_acc: 0.3620 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.013s\n",
      "| RMSProp | epoch: 021 | loss: 0.00000 - binary_acc: 0.3139 | val_loss: 0.00000 - val_binary_acc: 0.3620 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.012s\n",
      "| RMSProp | epoch: 022 | loss: 0.00000 - binary_acc: 0.3139 | val_loss: 0.00000 - val_binary_acc: 0.3620 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.012s\n",
      "| RMSProp | epoch: 023 | loss: 0.00000 - binary_acc: 0.3139 | val_loss: 0.00000 - val_binary_acc: 0.3620 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.013s\n",
      "| RMSProp | epoch: 024 | loss: 0.00000 - binary_acc: 0.3139 | val_loss: 0.00000 - val_binary_acc: 0.3620 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.013s\n",
      "| RMSProp | epoch: 025 | loss: 0.00000 - binary_acc: 0.3139 | val_loss: 0.00000 - val_binary_acc: 0.3620 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.012s\n",
      "| RMSProp | epoch: 026 | loss: 0.00000 - binary_acc: 0.3139 | val_loss: 0.00000 - val_binary_acc: 0.3620 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.015s\n",
      "| RMSProp | epoch: 027 | loss: 0.00000 - binary_acc: 0.3139 | val_loss: 0.00000 - val_binary_acc: 0.3620 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.011s\n",
      "| RMSProp | epoch: 028 | loss: 0.00000 - binary_acc: 0.3139 | val_loss: 0.00000 - val_binary_acc: 0.3620 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.015s\n",
      "| RMSProp | epoch: 029 | loss: 0.00000 - binary_acc: 0.3139 | val_loss: 0.00000 - val_binary_acc: 0.3620 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.011s\n",
      "| RMSProp | epoch: 030 | loss: 0.00000 - binary_acc: 0.3139 | val_loss: 0.00000 - val_binary_acc: 0.3620 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'softmax', 100, [0.3002028369758482]]\n",
      "RMSProp\n",
      "softmax\n",
      "35\n",
      "---------------------------------\n",
      "Run id: JW2IXC\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.126s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.008s\n",
      "| RMSProp | epoch: 002 | loss: 0.00000 - binary_acc: 0.3002 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.010s\n",
      "| RMSProp | epoch: 003 | loss: 0.00000 - binary_acc: 0.3275 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.009s\n",
      "| RMSProp | epoch: 004 | loss: 0.00000 - binary_acc: 0.3320 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.009s\n",
      "| RMSProp | epoch: 005 | loss: 0.00000 - binary_acc: 0.3331 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.009s\n",
      "| RMSProp | epoch: 006 | loss: 0.00000 - binary_acc: 0.3334 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.009s\n",
      "| RMSProp | epoch: 007 | loss: 0.00000 - binary_acc: 0.3335 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.009s\n",
      "| RMSProp | epoch: 008 | loss: 0.00000 - binary_acc: 0.3335 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.011s\n",
      "| RMSProp | epoch: 009 | loss: 0.00000 - binary_acc: 0.3335 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.014s\n",
      "| RMSProp | epoch: 010 | loss: 0.00000 - binary_acc: 0.3335 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.008s\n",
      "| RMSProp | epoch: 011 | loss: 0.00000 - binary_acc: 0.3335 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.010s\n",
      "| RMSProp | epoch: 012 | loss: 0.00000 - binary_acc: 0.3335 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.009s\n",
      "| RMSProp | epoch: 013 | loss: 0.00000 - binary_acc: 0.3335 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.010s\n",
      "| RMSProp | epoch: 014 | loss: 0.00000 - binary_acc: 0.3335 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.010s\n",
      "| RMSProp | epoch: 015 | loss: 0.00000 - binary_acc: 0.3335 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.009s\n",
      "| RMSProp | epoch: 016 | loss: 0.00000 - binary_acc: 0.3335 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.010s\n",
      "| RMSProp | epoch: 017 | loss: 0.00000 - binary_acc: 0.3335 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.009s\n",
      "| RMSProp | epoch: 018 | loss: 0.00000 - binary_acc: 0.3335 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.009s\n",
      "| RMSProp | epoch: 019 | loss: 0.00000 - binary_acc: 0.3335 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.009s\n",
      "| RMSProp | epoch: 020 | loss: 0.00000 - binary_acc: 0.3335 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.010s\n",
      "| RMSProp | epoch: 021 | loss: 0.00000 - binary_acc: 0.3335 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.009s\n",
      "| RMSProp | epoch: 022 | loss: 0.00000 - binary_acc: 0.3335 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.009s\n",
      "| RMSProp | epoch: 023 | loss: 0.00000 - binary_acc: 0.3335 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.010s\n",
      "| RMSProp | epoch: 024 | loss: 0.00000 - binary_acc: 0.3335 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.008s\n",
      "| RMSProp | epoch: 025 | loss: 0.00000 - binary_acc: 0.3335 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.011s\n",
      "| RMSProp | epoch: 026 | loss: 0.00000 - binary_acc: 0.3335 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.009s\n",
      "| RMSProp | epoch: 027 | loss: 0.00000 - binary_acc: 0.3335 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.009s\n",
      "| RMSProp | epoch: 028 | loss: 0.00000 - binary_acc: 0.3335 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.009s\n",
      "| RMSProp | epoch: 029 | loss: 0.00000 - binary_acc: 0.3335 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.009s\n",
      "| RMSProp | epoch: 030 | loss: 0.00000 - binary_acc: 0.3335 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'softmax', 35, [0.3002028369758482]]\n",
      "RMSProp\n",
      "sigmoid\n",
      "1000\n",
      "---------------------------------\n",
      "Run id: NUH15R\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.215s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.085s\n",
      "| RMSProp | epoch: 002 | loss: 0.00000 - binary_acc: 0.2905 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.096s\n",
      "| RMSProp | epoch: 003 | loss: 0.00000 - binary_acc: 0.3169 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.100s\n",
      "| RMSProp | epoch: 004 | loss: 0.00000 - binary_acc: 0.3213 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.094s\n",
      "| RMSProp | epoch: 005 | loss: 0.00000 - binary_acc: 0.3223 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.084s\n",
      "| RMSProp | epoch: 006 | loss: 0.00000 - binary_acc: 0.3226 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.086s\n",
      "| RMSProp | epoch: 007 | loss: 0.00000 - binary_acc: 0.3227 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.082s\n",
      "| RMSProp | epoch: 008 | loss: 0.00000 - binary_acc: 0.3227 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.099s\n",
      "| RMSProp | epoch: 009 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.100s\n",
      "| RMSProp | epoch: 010 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.101s\n",
      "| RMSProp | epoch: 011 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.088s\n",
      "| RMSProp | epoch: 012 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.093s\n",
      "| RMSProp | epoch: 013 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.098s\n",
      "| RMSProp | epoch: 014 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.095s\n",
      "| RMSProp | epoch: 015 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.091s\n",
      "| RMSProp | epoch: 016 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.095s\n",
      "| RMSProp | epoch: 017 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.094s\n",
      "| RMSProp | epoch: 018 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.095s\n",
      "| RMSProp | epoch: 019 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.090s\n",
      "| RMSProp | epoch: 020 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.092s\n",
      "| RMSProp | epoch: 021 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.092s\n",
      "| RMSProp | epoch: 022 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.091s\n",
      "| RMSProp | epoch: 023 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.094s\n",
      "| RMSProp | epoch: 024 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.651s\n",
      "| RMSProp | epoch: 025 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.693s\n",
      "| RMSProp | epoch: 026 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.663s\n",
      "| RMSProp | epoch: 027 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.126s\n",
      "| RMSProp | epoch: 028 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.131s\n",
      "| RMSProp | epoch: 029 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.122s\n",
      "| RMSProp | epoch: 030 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'sigmoid', 1000, [0.3002028369758482]]\n",
      "RMSProp\n",
      "sigmoid\n",
      "100\n",
      "---------------------------------\n",
      "Run id: KD0SMN\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.196s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.012s\n",
      "| RMSProp | epoch: 002 | loss: 0.00000 - binary_acc: 0.2945 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.012s\n",
      "| RMSProp | epoch: 003 | loss: 0.00000 - binary_acc: 0.3213 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.013s\n",
      "| RMSProp | epoch: 004 | loss: 0.00000 - binary_acc: 0.3257 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.013s\n",
      "| RMSProp | epoch: 005 | loss: 0.00000 - binary_acc: 0.3267 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.012s\n",
      "| RMSProp | epoch: 006 | loss: 0.00000 - binary_acc: 0.3270 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.014s\n",
      "| RMSProp | epoch: 007 | loss: 0.00000 - binary_acc: 0.3271 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.012s\n",
      "| RMSProp | epoch: 008 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.013s\n",
      "| RMSProp | epoch: 009 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.012s\n",
      "| RMSProp | epoch: 010 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.012s\n",
      "| RMSProp | epoch: 011 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.012s\n",
      "| RMSProp | epoch: 012 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.013s\n",
      "| RMSProp | epoch: 013 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.011s\n",
      "| RMSProp | epoch: 014 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.011s\n",
      "| RMSProp | epoch: 015 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.012s\n",
      "| RMSProp | epoch: 016 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.012s\n",
      "| RMSProp | epoch: 017 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.013s\n",
      "| RMSProp | epoch: 018 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.011s\n",
      "| RMSProp | epoch: 019 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.012s\n",
      "| RMSProp | epoch: 020 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.011s\n",
      "| RMSProp | epoch: 021 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.012s\n",
      "| RMSProp | epoch: 022 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.012s\n",
      "| RMSProp | epoch: 023 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.012s\n",
      "| RMSProp | epoch: 024 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.012s\n",
      "| RMSProp | epoch: 025 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.012s\n",
      "| RMSProp | epoch: 026 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.011s\n",
      "| RMSProp | epoch: 027 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.012s\n",
      "| RMSProp | epoch: 028 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.011s\n",
      "| RMSProp | epoch: 029 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.011s\n",
      "| RMSProp | epoch: 030 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'sigmoid', 100, [0.3002028369758482]]\n",
      "RMSProp\n",
      "sigmoid\n",
      "35\n",
      "---------------------------------\n",
      "Run id: EJDGFW\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.162s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.010s\n",
      "| RMSProp | epoch: 002 | loss: 0.00000 - binary_acc: 0.2916 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.009s\n",
      "| RMSProp | epoch: 003 | loss: 0.00000 - binary_acc: 0.3181 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.009s\n",
      "| RMSProp | epoch: 004 | loss: 0.00000 - binary_acc: 0.3226 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.009s\n",
      "| RMSProp | epoch: 005 | loss: 0.00000 - binary_acc: 0.3236 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.009s\n",
      "| RMSProp | epoch: 006 | loss: 0.00000 - binary_acc: 0.3239 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.009s\n",
      "| RMSProp | epoch: 007 | loss: 0.00000 - binary_acc: 0.3240 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.010s\n",
      "| RMSProp | epoch: 008 | loss: 0.00000 - binary_acc: 0.3240 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.009s\n",
      "| RMSProp | epoch: 009 | loss: 0.00000 - binary_acc: 0.3240 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.009s\n",
      "| RMSProp | epoch: 010 | loss: 0.00000 - binary_acc: 0.3240 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.009s\n",
      "| RMSProp | epoch: 011 | loss: 0.00000 - binary_acc: 0.3240 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.010s\n",
      "| RMSProp | epoch: 012 | loss: 0.00000 - binary_acc: 0.3240 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.010s\n",
      "| RMSProp | epoch: 013 | loss: 0.00000 - binary_acc: 0.3240 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.009s\n",
      "| RMSProp | epoch: 014 | loss: 0.00000 - binary_acc: 0.3240 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.010s\n",
      "| RMSProp | epoch: 015 | loss: 0.00000 - binary_acc: 0.3240 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.009s\n",
      "| RMSProp | epoch: 016 | loss: 0.00000 - binary_acc: 0.3240 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.009s\n",
      "| RMSProp | epoch: 017 | loss: 0.00000 - binary_acc: 0.3240 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.010s\n",
      "| RMSProp | epoch: 018 | loss: 0.00000 - binary_acc: 0.3240 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.009s\n",
      "| RMSProp | epoch: 019 | loss: 0.00000 - binary_acc: 0.3240 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.010s\n",
      "| RMSProp | epoch: 020 | loss: 0.00000 - binary_acc: 0.3240 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.009s\n",
      "| RMSProp | epoch: 021 | loss: 0.00000 - binary_acc: 0.3240 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.009s\n",
      "| RMSProp | epoch: 022 | loss: 0.00000 - binary_acc: 0.3240 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.009s\n",
      "| RMSProp | epoch: 023 | loss: 0.00000 - binary_acc: 0.3240 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.010s\n",
      "| RMSProp | epoch: 024 | loss: 0.00000 - binary_acc: 0.3240 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.010s\n",
      "| RMSProp | epoch: 025 | loss: 0.00000 - binary_acc: 0.3240 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.009s\n",
      "| RMSProp | epoch: 026 | loss: 0.00000 - binary_acc: 0.3240 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.009s\n",
      "| RMSProp | epoch: 027 | loss: 0.00000 - binary_acc: 0.3240 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.009s\n",
      "| RMSProp | epoch: 028 | loss: 0.00000 - binary_acc: 0.3240 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.009s\n",
      "| RMSProp | epoch: 029 | loss: 0.00000 - binary_acc: 0.3240 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.010s\n",
      "| RMSProp | epoch: 030 | loss: 0.00000 - binary_acc: 0.3240 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'sigmoid', 35, [0.3002028369758482]]\n",
      "RMSProp\n",
      "tanh\n",
      "1000\n",
      "---------------------------------\n",
      "Run id: WHHTGM\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.277s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.2785 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.125s\n",
      "| RMSProp | epoch: 002 | loss: 0.00000 - binary_acc: 0.2408 | val_loss: 0.00000 - val_binary_acc: 0.2785 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.128s\n",
      "| RMSProp | epoch: 003 | loss: 0.00000 - binary_acc: 0.2627 | val_loss: 0.00000 - val_binary_acc: 0.2785 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.121s\n",
      "| RMSProp | epoch: 004 | loss: 0.00000 - binary_acc: 0.3444 | val_loss: 0.00000 - val_binary_acc: 0.2785 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.128s\n",
      "| RMSProp | epoch: 005 | loss: 0.00000 - binary_acc: 0.2912 | val_loss: 0.00000 - val_binary_acc: 0.2785 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.123s\n",
      "| RMSProp | epoch: 006 | loss: 0.00000 - binary_acc: 0.3502 | val_loss: 0.00000 - val_binary_acc: 0.2785 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.125s\n",
      "| RMSProp | epoch: 007 | loss: 0.00000 - binary_acc: 0.3006 | val_loss: 0.00000 - val_binary_acc: 0.2785 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.135s\n",
      "| RMSProp | epoch: 008 | loss: 0.00000 - binary_acc: 0.3448 | val_loss: 0.00000 - val_binary_acc: 0.2785 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.123s\n",
      "| RMSProp | epoch: 009 | loss: 0.00000 - binary_acc: 0.3039 | val_loss: 0.00000 - val_binary_acc: 0.2785 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.129s\n",
      "| RMSProp | epoch: 010 | loss: 0.00000 - binary_acc: 0.3470 | val_loss: 0.00000 - val_binary_acc: 0.2785 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.144s\n",
      "| RMSProp | epoch: 011 | loss: 0.00000 - binary_acc: 0.3094 | val_loss: 0.00000 - val_binary_acc: 0.2785 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.133s\n",
      "| RMSProp | epoch: 012 | loss: 0.00000 - binary_acc: 0.2906 | val_loss: 0.00000 - val_binary_acc: 0.2785 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.126s\n",
      "| RMSProp | epoch: 013 | loss: 0.00000 - binary_acc: 0.2807 | val_loss: 0.00000 - val_binary_acc: 0.2785 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.123s\n",
      "| RMSProp | epoch: 014 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.2785 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.124s\n",
      "| RMSProp | epoch: 015 | loss: 0.00000 - binary_acc: 0.3012 | val_loss: 0.00000 - val_binary_acc: 0.2785 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.125s\n",
      "| RMSProp | epoch: 016 | loss: 0.00000 - binary_acc: 0.3307 | val_loss: 0.00000 - val_binary_acc: 0.2785 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.121s\n",
      "| RMSProp | epoch: 017 | loss: 0.00000 - binary_acc: 0.3080 | val_loss: 0.00000 - val_binary_acc: 0.2785 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.122s\n",
      "| RMSProp | epoch: 018 | loss: 0.00000 - binary_acc: 0.3252 | val_loss: 0.00000 - val_binary_acc: 0.2785 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.123s\n",
      "| RMSProp | epoch: 019 | loss: 0.00000 - binary_acc: 0.3060 | val_loss: 0.00000 - val_binary_acc: 0.2785 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.122s\n",
      "| RMSProp | epoch: 020 | loss: 0.00000 - binary_acc: 0.2936 | val_loss: 0.00000 - val_binary_acc: 0.2785 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.127s\n",
      "| RMSProp | epoch: 021 | loss: 0.00000 - binary_acc: 0.2856 | val_loss: 0.00000 - val_binary_acc: 0.2785 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.123s\n",
      "| RMSProp | epoch: 022 | loss: 0.00000 - binary_acc: 0.3137 | val_loss: 0.00000 - val_binary_acc: 0.2785 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.123s\n",
      "| RMSProp | epoch: 023 | loss: 0.00000 - binary_acc: 0.3003 | val_loss: 0.00000 - val_binary_acc: 0.2785 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.125s\n",
      "| RMSProp | epoch: 024 | loss: 0.00000 - binary_acc: 0.3123 | val_loss: 0.00000 - val_binary_acc: 0.2785 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.122s\n",
      "| RMSProp | epoch: 025 | loss: 0.00000 - binary_acc: 0.3001 | val_loss: 0.00000 - val_binary_acc: 0.2785 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.122s\n",
      "| RMSProp | epoch: 026 | loss: 0.00000 - binary_acc: 0.3170 | val_loss: 0.00000 - val_binary_acc: 0.2785 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.124s\n",
      "| RMSProp | epoch: 027 | loss: 0.00000 - binary_acc: 0.3043 | val_loss: 0.00000 - val_binary_acc: 0.2785 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.124s\n",
      "| RMSProp | epoch: 028 | loss: 0.00000 - binary_acc: 0.3146 | val_loss: 0.00000 - val_binary_acc: 0.2785 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.136s\n",
      "| RMSProp | epoch: 029 | loss: 0.00000 - binary_acc: 0.3032 | val_loss: 0.00000 - val_binary_acc: 0.2785 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.128s\n",
      "| RMSProp | epoch: 030 | loss: 0.00000 - binary_acc: 0.3207 | val_loss: 0.00000 - val_binary_acc: 0.2785 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'tanh', 1000, [0.27180527449863195]]\n",
      "RMSProp\n",
      "tanh\n",
      "100\n",
      "---------------------------------\n",
      "Run id: 630OGO\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.166s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.4759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.012s\n",
      "| RMSProp | epoch: 002 | loss: 0.00000 - binary_acc: 0.4423 | val_loss: 0.00000 - val_binary_acc: 0.4759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.012s\n",
      "| RMSProp | epoch: 003 | loss: 0.00000 - binary_acc: 0.4820 | val_loss: 0.00000 - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.013s\n",
      "| RMSProp | epoch: 004 | loss: 0.00000 - binary_acc: 0.4377 | val_loss: 0.00000 - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.011s\n",
      "| RMSProp | epoch: 005 | loss: 0.00000 - binary_acc: 0.4749 | val_loss: 0.00000 - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.013s\n",
      "| RMSProp | epoch: 006 | loss: 0.00000 - binary_acc: 0.4851 | val_loss: 0.00000 - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.011s\n",
      "| RMSProp | epoch: 007 | loss: 0.00000 - binary_acc: 0.4885 | val_loss: 0.00000 - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.013s\n",
      "| RMSProp | epoch: 008 | loss: 0.00000 - binary_acc: 0.4898 | val_loss: 0.00000 - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.012s\n",
      "| RMSProp | epoch: 009 | loss: 0.00000 - binary_acc: 0.4910 | val_loss: 0.00000 - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.012s\n",
      "| RMSProp | epoch: 010 | loss: 0.00000 - binary_acc: 0.4316 | val_loss: 0.00000 - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.012s\n",
      "| RMSProp | epoch: 011 | loss: 0.00000 - binary_acc: 0.4597 | val_loss: 0.00000 - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.012s\n",
      "| RMSProp | epoch: 012 | loss: 0.00000 - binary_acc: 0.4371 | val_loss: 0.00000 - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.012s\n",
      "| RMSProp | epoch: 013 | loss: 0.00000 - binary_acc: 0.4607 | val_loss: 0.00000 - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.011s\n",
      "| RMSProp | epoch: 014 | loss: 0.00000 - binary_acc: 0.4286 | val_loss: 0.00000 - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.012s\n",
      "| RMSProp | epoch: 015 | loss: 0.00000 - binary_acc: 0.4532 | val_loss: 0.00000 - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.016s\n",
      "| RMSProp | epoch: 016 | loss: 0.00000 - binary_acc: 0.4302 | val_loss: 0.00000 - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.012s\n",
      "| RMSProp | epoch: 017 | loss: 0.00000 - binary_acc: 0.4523 | val_loss: 0.00000 - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.011s\n",
      "| RMSProp | epoch: 018 | loss: 0.00000 - binary_acc: 0.4329 | val_loss: 0.00000 - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1310.583s\n",
      "| RMSProp | epoch: 019 | loss: 0.00000 - binary_acc: 0.4524 | val_loss: 0.00000 - val_binary_acc: 0.4759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 17.122s\n",
      "| RMSProp | epoch: 020 | loss: 0.00000 - binary_acc: 0.4372 | val_loss: 0.00000 - val_binary_acc: 0.4759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.010s\n",
      "| RMSProp | epoch: 021 | loss: 0.00000 - binary_acc: 0.4533 | val_loss: 0.00000 - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.013s\n",
      "| RMSProp | epoch: 022 | loss: 0.00000 - binary_acc: 0.4442 | val_loss: 0.00000 - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.011s\n",
      "| RMSProp | epoch: 023 | loss: 0.00000 - binary_acc: 0.4575 | val_loss: 0.00000 - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.010s\n",
      "| RMSProp | epoch: 024 | loss: 0.00000 - binary_acc: 0.4476 | val_loss: 0.00000 - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.008s\n",
      "| RMSProp | epoch: 025 | loss: 0.00000 - binary_acc: 0.4592 | val_loss: 0.00000 - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.010s\n",
      "| RMSProp | epoch: 026 | loss: 0.00000 - binary_acc: 0.4449 | val_loss: 0.00000 - val_binary_acc: 0.4759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.011s\n",
      "| RMSProp | epoch: 027 | loss: 0.00000 - binary_acc: 0.4566 | val_loss: 0.00000 - val_binary_acc: 0.4759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.010s\n",
      "| RMSProp | epoch: 028 | loss: 0.00000 - binary_acc: 0.4502 | val_loss: 0.00000 - val_binary_acc: 0.4759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.011s\n",
      "| RMSProp | epoch: 029 | loss: 0.00000 - binary_acc: 0.4596 | val_loss: 0.00000 - val_binary_acc: 0.4759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.011s\n",
      "| RMSProp | epoch: 030 | loss: 0.00000 - binary_acc: 0.4505 | val_loss: 0.00000 - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'tanh', 100, [0.4929006077938583]]\n",
      "RMSProp\n",
      "tanh\n",
      "35\n",
      "---------------------------------\n",
      "Run id: M9UBXF\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 2.001s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.2861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.007s\n",
      "| RMSProp | epoch: 002 | loss: 0.00000 - binary_acc: 0.3356 | val_loss: 0.00000 - val_binary_acc: 0.2861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.009s\n",
      "| RMSProp | epoch: 003 | loss: 0.00000 - binary_acc: 0.2784 | val_loss: 0.00000 - val_binary_acc: 0.2861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.012s\n",
      "| RMSProp | epoch: 004 | loss: 0.00000 - binary_acc: 0.3326 | val_loss: 0.00000 - val_binary_acc: 0.2861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.009s\n",
      "| RMSProp | epoch: 005 | loss: 0.00000 - binary_acc: 0.2863 | val_loss: 0.00000 - val_binary_acc: 0.2861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.007s\n",
      "| RMSProp | epoch: 006 | loss: 0.00000 - binary_acc: 0.3387 | val_loss: 0.00000 - val_binary_acc: 0.2861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.006s\n",
      "| RMSProp | epoch: 007 | loss: 0.00000 - binary_acc: 0.2949 | val_loss: 0.00000 - val_binary_acc: 0.2861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.009s\n",
      "| RMSProp | epoch: 008 | loss: 0.00000 - binary_acc: 0.3334 | val_loss: 0.00000 - val_binary_acc: 0.2861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.007s\n",
      "| RMSProp | epoch: 009 | loss: 0.00000 - binary_acc: 0.2976 | val_loss: 0.00000 - val_binary_acc: 0.2861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.008s\n",
      "| RMSProp | epoch: 010 | loss: 0.00000 - binary_acc: 0.3381 | val_loss: 0.00000 - val_binary_acc: 0.2861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.008s\n",
      "| RMSProp | epoch: 011 | loss: 0.00000 - binary_acc: 0.3038 | val_loss: 0.00000 - val_binary_acc: 0.2861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.008s\n",
      "| RMSProp | epoch: 012 | loss: 0.00000 - binary_acc: 0.3255 | val_loss: 0.00000 - val_binary_acc: 0.2861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.008s\n",
      "| RMSProp | epoch: 013 | loss: 0.00000 - binary_acc: 0.2998 | val_loss: 0.00000 - val_binary_acc: 0.2861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.008s\n",
      "| RMSProp | epoch: 014 | loss: 0.00000 - binary_acc: 0.3284 | val_loss: 0.00000 - val_binary_acc: 0.2861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.008s\n",
      "| RMSProp | epoch: 015 | loss: 0.00000 - binary_acc: 0.3039 | val_loss: 0.00000 - val_binary_acc: 0.2861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.009s\n",
      "| RMSProp | epoch: 016 | loss: 0.00000 - binary_acc: 0.3243 | val_loss: 0.00000 - val_binary_acc: 0.2861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.009s\n",
      "| RMSProp | epoch: 017 | loss: 0.00000 - binary_acc: 0.3032 | val_loss: 0.00000 - val_binary_acc: 0.2861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.009s\n",
      "| RMSProp | epoch: 018 | loss: 0.00000 - binary_acc: 0.3148 | val_loss: 0.00000 - val_binary_acc: 0.2861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.008s\n",
      "| RMSProp | epoch: 019 | loss: 0.00000 - binary_acc: 0.2988 | val_loss: 0.00000 - val_binary_acc: 0.2861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.009s\n",
      "| RMSProp | epoch: 020 | loss: 0.00000 - binary_acc: 0.3122 | val_loss: 0.00000 - val_binary_acc: 0.2861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.008s\n",
      "| RMSProp | epoch: 021 | loss: 0.00000 - binary_acc: 0.2982 | val_loss: 0.00000 - val_binary_acc: 0.2861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.009s\n",
      "| RMSProp | epoch: 022 | loss: 0.00000 - binary_acc: 0.3084 | val_loss: 0.00000 - val_binary_acc: 0.2861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.009s\n",
      "| RMSProp | epoch: 023 | loss: 0.00000 - binary_acc: 0.2964 | val_loss: 0.00000 - val_binary_acc: 0.2861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.008s\n",
      "| RMSProp | epoch: 024 | loss: 0.00000 - binary_acc: 0.3011 | val_loss: 0.00000 - val_binary_acc: 0.2861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.008s\n",
      "| RMSProp | epoch: 025 | loss: 0.00000 - binary_acc: 0.2918 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.009s\n",
      "| RMSProp | epoch: 026 | loss: 0.00000 - binary_acc: 0.3069 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.008s\n",
      "| RMSProp | epoch: 027 | loss: 0.00000 - binary_acc: 0.2966 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.008s\n",
      "| RMSProp | epoch: 028 | loss: 0.00000 - binary_acc: 0.3114 | val_loss: 0.00000 - val_binary_acc: 0.2861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.014s\n",
      "| RMSProp | epoch: 029 | loss: 0.00000 - binary_acc: 0.3006 | val_loss: 0.00000 - val_binary_acc: 0.2861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.009s\n",
      "| RMSProp | epoch: 030 | loss: 0.00000 - binary_acc: 0.3152 | val_loss: 0.00000 - val_binary_acc: 0.2861 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'tanh', 35, [0.2758620684819096]]\n",
      "RMSProp\n",
      "prelu\n",
      "1000\n",
      "---------------------------------\n",
      "Run id: 4JWA0P\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.561s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.117s\n",
      "| RMSProp | epoch: 002 | loss: nan - binary_acc: 0.3088 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.120s\n",
      "| RMSProp | epoch: 003 | loss: nan - binary_acc: 0.4193 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.123s\n",
      "| RMSProp | epoch: 004 | loss: nan - binary_acc: 0.4377 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.120s\n",
      "| RMSProp | epoch: 005 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.113s\n",
      "| RMSProp | epoch: 006 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.114s\n",
      "| RMSProp | epoch: 007 | loss: nan - binary_acc: 0.4436 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.110s\n",
      "| RMSProp | epoch: 008 | loss: nan - binary_acc: 0.4438 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.109s\n",
      "| RMSProp | epoch: 009 | loss: nan - binary_acc: 0.4438 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.118s\n",
      "| RMSProp | epoch: 010 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.111s\n",
      "| RMSProp | epoch: 011 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.114s\n",
      "| RMSProp | epoch: 012 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.119s\n",
      "| RMSProp | epoch: 013 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.111s\n",
      "| RMSProp | epoch: 014 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.114s\n",
      "| RMSProp | epoch: 015 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.113s\n",
      "| RMSProp | epoch: 016 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.113s\n",
      "| RMSProp | epoch: 017 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.114s\n",
      "| RMSProp | epoch: 018 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.160s\n",
      "| RMSProp | epoch: 019 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.116s\n",
      "| RMSProp | epoch: 020 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.114s\n",
      "| RMSProp | epoch: 021 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.122s\n",
      "| RMSProp | epoch: 022 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.123s\n",
      "| RMSProp | epoch: 023 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.112s\n",
      "| RMSProp | epoch: 024 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.113s\n",
      "| RMSProp | epoch: 025 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.118s\n",
      "| RMSProp | epoch: 026 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.112s\n",
      "| RMSProp | epoch: 027 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.124s\n",
      "| RMSProp | epoch: 028 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.114s\n",
      "| RMSProp | epoch: 029 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.115s\n",
      "| RMSProp | epoch: 030 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'prelu', 1000, [0.45436105404132276]]\n",
      "RMSProp\n",
      "prelu\n",
      "100\n",
      "---------------------------------\n",
      "Run id: 37G016\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.169s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| RMSProp | epoch: 002 | loss: nan - binary_acc: 0.3247 | val_loss: nan - val_binary_acc: 0.4835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| RMSProp | epoch: 003 | loss: nan - binary_acc: 0.4108 | val_loss: nan - val_binary_acc: 0.4835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| RMSProp | epoch: 004 | loss: nan - binary_acc: 0.4251 | val_loss: nan - val_binary_acc: 0.4835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| RMSProp | epoch: 005 | loss: nan - binary_acc: 0.4285 | val_loss: nan - val_binary_acc: 0.4835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| RMSProp | epoch: 006 | loss: nan - binary_acc: 0.4294 | val_loss: nan - val_binary_acc: 0.4835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| RMSProp | epoch: 007 | loss: nan - binary_acc: 0.4297 | val_loss: nan - val_binary_acc: 0.4835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.014s\n",
      "| RMSProp | epoch: 008 | loss: nan - binary_acc: 0.4298 | val_loss: nan - val_binary_acc: 0.4835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| RMSProp | epoch: 009 | loss: nan - binary_acc: 0.4299 | val_loss: nan - val_binary_acc: 0.4835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| RMSProp | epoch: 010 | loss: nan - binary_acc: 0.4299 | val_loss: nan - val_binary_acc: 0.4835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| RMSProp | epoch: 011 | loss: nan - binary_acc: 0.4299 | val_loss: nan - val_binary_acc: 0.4835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| RMSProp | epoch: 012 | loss: nan - binary_acc: 0.4299 | val_loss: nan - val_binary_acc: 0.4835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| RMSProp | epoch: 013 | loss: nan - binary_acc: 0.4299 | val_loss: nan - val_binary_acc: 0.4835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| RMSProp | epoch: 014 | loss: nan - binary_acc: 0.4299 | val_loss: nan - val_binary_acc: 0.4835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| RMSProp | epoch: 015 | loss: nan - binary_acc: 0.4299 | val_loss: nan - val_binary_acc: 0.4835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| RMSProp | epoch: 016 | loss: nan - binary_acc: 0.4299 | val_loss: nan - val_binary_acc: 0.4835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| RMSProp | epoch: 017 | loss: nan - binary_acc: 0.4299 | val_loss: nan - val_binary_acc: 0.4835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| RMSProp | epoch: 018 | loss: nan - binary_acc: 0.4299 | val_loss: nan - val_binary_acc: 0.4835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| RMSProp | epoch: 019 | loss: nan - binary_acc: 0.4299 | val_loss: nan - val_binary_acc: 0.4835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.014s\n",
      "| RMSProp | epoch: 020 | loss: nan - binary_acc: 0.4299 | val_loss: nan - val_binary_acc: 0.4835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| RMSProp | epoch: 021 | loss: nan - binary_acc: 0.4299 | val_loss: nan - val_binary_acc: 0.4835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.014s\n",
      "| RMSProp | epoch: 022 | loss: nan - binary_acc: 0.4299 | val_loss: nan - val_binary_acc: 0.4835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| RMSProp | epoch: 023 | loss: nan - binary_acc: 0.4299 | val_loss: nan - val_binary_acc: 0.4835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| RMSProp | epoch: 024 | loss: nan - binary_acc: 0.4299 | val_loss: nan - val_binary_acc: 0.4835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| RMSProp | epoch: 025 | loss: nan - binary_acc: 0.4299 | val_loss: nan - val_binary_acc: 0.4835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| RMSProp | epoch: 026 | loss: nan - binary_acc: 0.4299 | val_loss: nan - val_binary_acc: 0.4835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| RMSProp | epoch: 027 | loss: nan - binary_acc: 0.4299 | val_loss: nan - val_binary_acc: 0.4835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| RMSProp | epoch: 028 | loss: nan - binary_acc: 0.4299 | val_loss: nan - val_binary_acc: 0.4835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| RMSProp | epoch: 029 | loss: nan - binary_acc: 0.4299 | val_loss: nan - val_binary_acc: 0.4835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| RMSProp | epoch: 030 | loss: nan - binary_acc: 0.4299 | val_loss: nan - val_binary_acc: 0.4835 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'prelu', 100, [0.45436105404132276]]\n",
      "RMSProp\n",
      "prelu\n",
      "35\n",
      "---------------------------------\n",
      "Run id: REG03R\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.144s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 002 | loss: nan - binary_acc: 0.2990 | val_loss: nan - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 003 | loss: nan - binary_acc: 0.4082 | val_loss: nan - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 004 | loss: nan - binary_acc: 0.4264 | val_loss: nan - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 005 | loss: nan - binary_acc: 0.4306 | val_loss: nan - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 006 | loss: nan - binary_acc: 0.4318 | val_loss: nan - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 007 | loss: nan - binary_acc: 0.4322 | val_loss: nan - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 008 | loss: nan - binary_acc: 0.4324 | val_loss: nan - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 009 | loss: nan - binary_acc: 0.4324 | val_loss: nan - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 010 | loss: nan - binary_acc: 0.4324 | val_loss: nan - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 011 | loss: nan - binary_acc: 0.4325 | val_loss: nan - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 012 | loss: nan - binary_acc: 0.4325 | val_loss: nan - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 013 | loss: nan - binary_acc: 0.4325 | val_loss: nan - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 014 | loss: nan - binary_acc: 0.4325 | val_loss: nan - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| RMSProp | epoch: 015 | loss: nan - binary_acc: 0.4325 | val_loss: nan - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 016 | loss: nan - binary_acc: 0.4325 | val_loss: nan - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 017 | loss: nan - binary_acc: 0.4325 | val_loss: nan - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 018 | loss: nan - binary_acc: 0.4325 | val_loss: nan - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 019 | loss: nan - binary_acc: 0.4325 | val_loss: nan - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 020 | loss: nan - binary_acc: 0.4325 | val_loss: nan - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 021 | loss: nan - binary_acc: 0.4325 | val_loss: nan - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 022 | loss: nan - binary_acc: 0.4325 | val_loss: nan - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 023 | loss: nan - binary_acc: 0.4325 | val_loss: nan - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 024 | loss: nan - binary_acc: 0.4325 | val_loss: nan - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 025 | loss: nan - binary_acc: 0.4325 | val_loss: nan - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 026 | loss: nan - binary_acc: 0.4325 | val_loss: nan - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 027 | loss: nan - binary_acc: 0.4325 | val_loss: nan - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| RMSProp | epoch: 028 | loss: nan - binary_acc: 0.4325 | val_loss: nan - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 029 | loss: nan - binary_acc: 0.4325 | val_loss: nan - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 030 | loss: nan - binary_acc: 0.4325 | val_loss: nan - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'prelu', 35, [0.45436105404132276]]\n",
      "AdaGrad\n",
      "relu\n",
      "1000\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/training/adagrad.py:76: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "---------------------------------\n",
      "Run id: 1OC9FE\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.201s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.082s\n",
      "| AdaGrad | epoch: 002 | loss: nan - binary_acc: 0.2876 | val_loss: nan - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.080s\n",
      "| AdaGrad | epoch: 003 | loss: nan - binary_acc: 0.4092 | val_loss: nan - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.083s\n",
      "| AdaGrad | epoch: 004 | loss: nan - binary_acc: 0.4295 | val_loss: nan - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.080s\n",
      "| AdaGrad | epoch: 005 | loss: nan - binary_acc: 0.4342 | val_loss: nan - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.081s\n",
      "| AdaGrad | epoch: 006 | loss: nan - binary_acc: 0.4355 | val_loss: nan - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.080s\n",
      "| AdaGrad | epoch: 007 | loss: nan - binary_acc: 0.4360 | val_loss: nan - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.109s\n",
      "| AdaGrad | epoch: 008 | loss: nan - binary_acc: 0.4361 | val_loss: nan - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.082s\n",
      "| AdaGrad | epoch: 009 | loss: nan - binary_acc: 0.4362 | val_loss: nan - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.081s\n",
      "| AdaGrad | epoch: 010 | loss: nan - binary_acc: 0.4362 | val_loss: nan - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.083s\n",
      "| AdaGrad | epoch: 011 | loss: nan - binary_acc: 0.4363 | val_loss: nan - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.081s\n",
      "| AdaGrad | epoch: 012 | loss: nan - binary_acc: 0.4363 | val_loss: nan - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.084s\n",
      "| AdaGrad | epoch: 013 | loss: nan - binary_acc: 0.4363 | val_loss: nan - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.081s\n",
      "| AdaGrad | epoch: 014 | loss: nan - binary_acc: 0.4363 | val_loss: nan - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.081s\n",
      "| AdaGrad | epoch: 015 | loss: nan - binary_acc: 0.4363 | val_loss: nan - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.082s\n",
      "| AdaGrad | epoch: 016 | loss: nan - binary_acc: 0.4363 | val_loss: nan - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.083s\n",
      "| AdaGrad | epoch: 017 | loss: nan - binary_acc: 0.4363 | val_loss: nan - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.085s\n",
      "| AdaGrad | epoch: 018 | loss: nan - binary_acc: 0.4363 | val_loss: nan - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.081s\n",
      "| AdaGrad | epoch: 019 | loss: nan - binary_acc: 0.4363 | val_loss: nan - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.080s\n",
      "| AdaGrad | epoch: 020 | loss: nan - binary_acc: 0.4363 | val_loss: nan - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.083s\n",
      "| AdaGrad | epoch: 021 | loss: nan - binary_acc: 0.4363 | val_loss: nan - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.081s\n",
      "| AdaGrad | epoch: 022 | loss: nan - binary_acc: 0.4363 | val_loss: nan - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.083s\n",
      "| AdaGrad | epoch: 023 | loss: nan - binary_acc: 0.4363 | val_loss: nan - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.136s\n",
      "| AdaGrad | epoch: 024 | loss: nan - binary_acc: 0.4363 | val_loss: nan - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.082s\n",
      "| AdaGrad | epoch: 025 | loss: nan - binary_acc: 0.4363 | val_loss: nan - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.085s\n",
      "| AdaGrad | epoch: 026 | loss: nan - binary_acc: 0.4363 | val_loss: nan - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.080s\n",
      "| AdaGrad | epoch: 027 | loss: nan - binary_acc: 0.4363 | val_loss: nan - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.081s\n",
      "| AdaGrad | epoch: 028 | loss: nan - binary_acc: 0.4363 | val_loss: nan - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.082s\n",
      "| AdaGrad | epoch: 029 | loss: nan - binary_acc: 0.4363 | val_loss: nan - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.081s\n",
      "| AdaGrad | epoch: 030 | loss: nan - binary_acc: 0.4363 | val_loss: nan - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'relu', 1000, [0.45436105404132276]]\n",
      "AdaGrad\n",
      "relu\n",
      "100\n",
      "---------------------------------\n",
      "Run id: 0JZE71\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.094s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 002 | loss: nan - binary_acc: 0.3909 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaGrad | epoch: 003 | loss: nan - binary_acc: 0.4270 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaGrad | epoch: 004 | loss: nan - binary_acc: 0.4330 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaGrad | epoch: 005 | loss: nan - binary_acc: 0.4344 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 006 | loss: nan - binary_acc: 0.4348 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 007 | loss: nan - binary_acc: 0.4349 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaGrad | epoch: 008 | loss: nan - binary_acc: 0.4350 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 009 | loss: nan - binary_acc: 0.4350 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaGrad | epoch: 010 | loss: nan - binary_acc: 0.4350 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaGrad | epoch: 011 | loss: nan - binary_acc: 0.4350 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaGrad | epoch: 012 | loss: nan - binary_acc: 0.4350 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaGrad | epoch: 013 | loss: nan - binary_acc: 0.4350 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 014 | loss: nan - binary_acc: 0.4350 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| AdaGrad | epoch: 015 | loss: nan - binary_acc: 0.4350 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 016 | loss: nan - binary_acc: 0.4350 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 017 | loss: nan - binary_acc: 0.4350 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 018 | loss: nan - binary_acc: 0.4350 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 019 | loss: nan - binary_acc: 0.4350 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaGrad | epoch: 020 | loss: nan - binary_acc: 0.4350 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaGrad | epoch: 021 | loss: nan - binary_acc: 0.4350 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 022 | loss: nan - binary_acc: 0.4350 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 023 | loss: nan - binary_acc: 0.4350 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaGrad | epoch: 024 | loss: nan - binary_acc: 0.4350 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaGrad | epoch: 025 | loss: nan - binary_acc: 0.4350 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaGrad | epoch: 026 | loss: nan - binary_acc: 0.4350 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 027 | loss: nan - binary_acc: 0.4350 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaGrad | epoch: 028 | loss: nan - binary_acc: 0.4350 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaGrad | epoch: 029 | loss: nan - binary_acc: 0.4350 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaGrad | epoch: 030 | loss: nan - binary_acc: 0.4350 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'relu', 100, [0.45436105404132276]]\n",
      "AdaGrad\n",
      "relu\n",
      "35\n",
      "---------------------------------\n",
      "Run id: 349RZ6\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.124s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaGrad | epoch: 002 | loss: nan - binary_acc: 0.3613 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 003 | loss: nan - binary_acc: 0.4237 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 004 | loss: nan - binary_acc: 0.4341 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 005 | loss: nan - binary_acc: 0.4365 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 006 | loss: nan - binary_acc: 0.4372 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 007 | loss: nan - binary_acc: 0.4374 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 008 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 009 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 010 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 011 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 012 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 013 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 014 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 015 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 016 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 017 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 018 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 019 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 020 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 021 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 022 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 023 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 024 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 025 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 026 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 027 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 028 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaGrad | epoch: 029 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 030 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'relu', 35, [0.45436105404132276]]\n",
      "AdaGrad\n",
      "linear\n",
      "1000\n",
      "---------------------------------\n",
      "Run id: F03MOM\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.183s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.084s\n",
      "| AdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.3698 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.084s\n",
      "| AdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.4730 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.087s\n",
      "| AdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.4069 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.088s\n",
      "| AdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.4685 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.083s\n",
      "| AdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.4213 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.099s\n",
      "| AdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.4660 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.084s\n",
      "| AdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.4828 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.090s\n",
      "| AdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.4897 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.083s\n",
      "| AdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.4462 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.083s\n",
      "| AdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.4697 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.086s\n",
      "| AdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.4815 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.120s\n",
      "| AdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.4877 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.099s\n",
      "| AdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.4910 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.090s\n",
      "| AdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.4582 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.082s\n",
      "| AdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.4723 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.083s\n",
      "| AdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.4808 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.085s\n",
      "| AdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.4575 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.088s\n",
      "| AdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.4703 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.083s\n",
      "| AdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.4536 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.088s\n",
      "| AdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.4668 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.086s\n",
      "| AdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.4485 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.083s\n",
      "| AdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.4622 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.086s\n",
      "| AdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.4414 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.081s\n",
      "| AdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.4562 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.083s\n",
      "| AdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.4429 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.085s\n",
      "| AdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.4565 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.100s\n",
      "| AdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.4410 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.081s\n",
      "| AdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.4543 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.082s\n",
      "| AdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.4415 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'linear', 1000, [0.5091277906183781]]\n",
      "AdaGrad\n",
      "linear\n",
      "100\n",
      "---------------------------------\n",
      "Run id: MZBCLL\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.106s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.008s\n",
      "| AdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.3373 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.011s\n",
      "| AdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.2668 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.011s\n",
      "| AdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3359 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.010s\n",
      "| AdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.2772 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.011s\n",
      "| AdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.2604 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.010s\n",
      "| AdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.2548 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.011s\n",
      "| AdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3009 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.010s\n",
      "| AdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.2745 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.011s\n",
      "| AdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3050 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.010s\n",
      "| AdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.2795 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.010s\n",
      "| AdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.2667 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.009s\n",
      "| AdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.2600 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.010s\n",
      "| AdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3088 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.011s\n",
      "| AdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.2862 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.011s\n",
      "| AdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3154 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.011s\n",
      "| AdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.2922 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.011s\n",
      "| AdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3098 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.010s\n",
      "| AdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.2903 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.010s\n",
      "| AdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3203 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.012s\n",
      "| AdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.2988 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.010s\n",
      "| AdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3172 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.012s\n",
      "| AdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.2980 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.011s\n",
      "| AdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3182 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.011s\n",
      "| AdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.2999 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.011s\n",
      "| AdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3157 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.011s\n",
      "| AdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.2991 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.011s\n",
      "| AdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3156 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.011s\n",
      "| AdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.2999 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.009s\n",
      "| AdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3122 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'linear', 100, [0.259634886805958]]\n",
      "AdaGrad\n",
      "linear\n",
      "35\n",
      "---------------------------------\n",
      "Run id: MWWEIU\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.105s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.006s\n",
      "| AdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.3521 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.008s\n",
      "| AdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.4775 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.008s\n",
      "| AdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.4984 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.008s\n",
      "| AdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.5032 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.009s\n",
      "| AdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.5046 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.009s\n",
      "| AdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.5051 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.007s\n",
      "| AdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.4539 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.008s\n",
      "| AdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.4812 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.007s\n",
      "| AdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.4365 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.008s\n",
      "| AdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.4691 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.008s\n",
      "| AdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.4401 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.008s\n",
      "| AdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.4681 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.009s\n",
      "| AdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.4335 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.009s\n",
      "| AdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.4616 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.008s\n",
      "| AdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.4357 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.007s\n",
      "| AdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.4608 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.009s\n",
      "| AdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.4411 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.010s\n",
      "| AdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.4625 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.008s\n",
      "| AdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.4519 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.009s\n",
      "| AdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.4685 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.010s\n",
      "| AdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.4544 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.008s\n",
      "| AdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.4692 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.008s\n",
      "| AdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.4551 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.008s\n",
      "| AdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.4688 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.009s\n",
      "| AdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.4584 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.008s\n",
      "| AdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.4705 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.009s\n",
      "| AdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.4602 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.008s\n",
      "| AdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.4712 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.008s\n",
      "| AdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.4587 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'linear', 35, [0.5010142003546864]]\n",
      "AdaGrad\n",
      "softmax\n",
      "1000\n",
      "---------------------------------\n",
      "Run id: YLIMVK\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 2.098s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.139s\n",
      "| AdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.2911 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.090s\n",
      "| AdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.3175 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.092s\n",
      "| AdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3219 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.096s\n",
      "| AdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.3229 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.091s\n",
      "| AdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3232 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.095s\n",
      "| AdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.3233 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.102s\n",
      "| AdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.093s\n",
      "| AdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.091s\n",
      "| AdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.092s\n",
      "| AdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.092s\n",
      "| AdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.092s\n",
      "| AdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.092s\n",
      "| AdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.106s\n",
      "| AdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.122s\n",
      "| AdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.097s\n",
      "| AdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.102s\n",
      "| AdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.097s\n",
      "| AdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.097s\n",
      "| AdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.107s\n",
      "| AdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.103s\n",
      "| AdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.094s\n",
      "| AdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.092s\n",
      "| AdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.109s\n",
      "| AdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.100s\n",
      "| AdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.114s\n",
      "| AdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.093s\n",
      "| AdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.106s\n",
      "| AdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.114s\n",
      "| AdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'softmax', 1000, [0.3002028369758482]]\n",
      "AdaGrad\n",
      "softmax\n",
      "100\n",
      "---------------------------------\n",
      "Run id: LUHV25\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.120s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.014s\n",
      "| AdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.2956 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.010s\n",
      "| AdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.3225 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.012s\n",
      "| AdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3270 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.012s\n",
      "| AdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.3280 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.011s\n",
      "| AdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3283 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.011s\n",
      "| AdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.3284 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.012s\n",
      "| AdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3284 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.012s\n",
      "| AdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.011s\n",
      "| AdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.011s\n",
      "| AdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.012s\n",
      "| AdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.015s\n",
      "| AdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.011s\n",
      "| AdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.013s\n",
      "| AdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.011s\n",
      "| AdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.012s\n",
      "| AdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.014s\n",
      "| AdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.011s\n",
      "| AdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.011s\n",
      "| AdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.014s\n",
      "| AdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.011s\n",
      "| AdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.012s\n",
      "| AdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.011s\n",
      "| AdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.013s\n",
      "| AdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.012s\n",
      "| AdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.011s\n",
      "| AdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.012s\n",
      "| AdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.011s\n",
      "| AdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.012s\n",
      "| AdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'softmax', 100, [0.3002028369758482]]\n",
      "AdaGrad\n",
      "softmax\n",
      "35\n",
      "---------------------------------\n",
      "Run id: BA0ZZO\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.160s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.008s\n",
      "| AdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.2956 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.008s\n",
      "| AdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.3225 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.008s\n",
      "| AdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3270 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.008s\n",
      "| AdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.3280 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.014s\n",
      "| AdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3283 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.009s\n",
      "| AdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.3284 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.011s\n",
      "| AdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3284 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.008s\n",
      "| AdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.010s\n",
      "| AdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.011s\n",
      "| AdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.012s\n",
      "| AdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.009s\n",
      "| AdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.009s\n",
      "| AdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.009s\n",
      "| AdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.010s\n",
      "| AdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.009s\n",
      "| AdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.008s\n",
      "| AdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.010s\n",
      "| AdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.009s\n",
      "| AdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.010s\n",
      "| AdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.010s\n",
      "| AdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.009s\n",
      "| AdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.010s\n",
      "| AdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.009s\n",
      "| AdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.009s\n",
      "| AdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.010s\n",
      "| AdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.010s\n",
      "| AdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.012s\n",
      "| AdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.010s\n",
      "| AdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'softmax', 35, [0.3002028369758482]]\n",
      "AdaGrad\n",
      "sigmoid\n",
      "1000\n",
      "---------------------------------\n",
      "Run id: J4VTKB\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.219s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.084s\n",
      "| AdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.2911 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.088s\n",
      "| AdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.3175 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.085s\n",
      "| AdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3219 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.087s\n",
      "| AdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.3229 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.088s\n",
      "| AdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3232 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.085s\n",
      "| AdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.3233 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.086s\n",
      "| AdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.085s\n",
      "| AdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.114s\n",
      "| AdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.098s\n",
      "| AdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.087s\n",
      "| AdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.116s\n",
      "| AdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.096s\n",
      "| AdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.084s\n",
      "| AdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.086s\n",
      "| AdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.093s\n",
      "| AdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.086s\n",
      "| AdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.111s\n",
      "| AdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.087s\n",
      "| AdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.088s\n",
      "| AdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.090s\n",
      "| AdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.084s\n",
      "| AdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.109s\n",
      "| AdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.085s\n",
      "| AdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.088s\n",
      "| AdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.089s\n",
      "| AdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.085s\n",
      "| AdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.095s\n",
      "| AdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.087s\n",
      "| AdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'sigmoid', 1000, [0.3002028369758482]]\n",
      "AdaGrad\n",
      "sigmoid\n",
      "100\n",
      "---------------------------------\n",
      "Run id: GG9CQH\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.166s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.011s\n",
      "| AdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.2951 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.013s\n",
      "| AdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.3219 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.010s\n",
      "| AdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3263 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.011s\n",
      "| AdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.3274 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.011s\n",
      "| AdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3277 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.011s\n",
      "| AdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.011s\n",
      "| AdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.011s\n",
      "| AdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.013s\n",
      "| AdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.010s\n",
      "| AdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.011s\n",
      "| AdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.012s\n",
      "| AdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.012s\n",
      "| AdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.010s\n",
      "| AdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.009s\n",
      "| AdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.012s\n",
      "| AdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.012s\n",
      "| AdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.010s\n",
      "| AdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.011s\n",
      "| AdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.012s\n",
      "| AdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.010s\n",
      "| AdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.011s\n",
      "| AdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.011s\n",
      "| AdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.011s\n",
      "| AdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.012s\n",
      "| AdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.011s\n",
      "| AdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.012s\n",
      "| AdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.013s\n",
      "| AdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.010s\n",
      "| AdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'sigmoid', 100, [0.3002028369758482]]\n",
      "AdaGrad\n",
      "sigmoid\n",
      "35\n",
      "---------------------------------\n",
      "Run id: 2RN0T7\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.110s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.006s\n",
      "| AdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.2939 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.009s\n",
      "| AdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.3206 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.009s\n",
      "| AdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3251 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.008s\n",
      "| AdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.3261 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.008s\n",
      "| AdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3264 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.007s\n",
      "| AdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.3265 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.008s\n",
      "| AdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3265 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.007s\n",
      "| AdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.008s\n",
      "| AdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.008s\n",
      "| AdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.009s\n",
      "| AdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.008s\n",
      "| AdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.008s\n",
      "| AdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.007s\n",
      "| AdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.010s\n",
      "| AdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.008s\n",
      "| AdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.008s\n",
      "| AdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.009s\n",
      "| AdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.009s\n",
      "| AdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.007s\n",
      "| AdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.008s\n",
      "| AdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.009s\n",
      "| AdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.008s\n",
      "| AdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.008s\n",
      "| AdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.009s\n",
      "| AdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.008s\n",
      "| AdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.009s\n",
      "| AdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.008s\n",
      "| AdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.008s\n",
      "| AdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'sigmoid', 35, [0.3002028369758482]]\n",
      "AdaGrad\n",
      "tanh\n",
      "1000\n",
      "---------------------------------\n",
      "Run id: FTUMEH\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 2.071s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.2810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.084s\n",
      "| AdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.087s\n",
      "| AdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.2704 | val_loss: 0.00000 - val_binary_acc: 0.2810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.086s\n",
      "| AdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.2602 | val_loss: 0.00000 - val_binary_acc: 0.2810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.104s\n",
      "| AdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.2579 | val_loss: 0.00000 - val_binary_acc: 0.2810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.100s\n",
      "| AdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3420 | val_loss: 0.00000 - val_binary_acc: 0.2810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.096s\n",
      "| AdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.2909 | val_loss: 0.00000 - val_binary_acc: 0.2810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.095s\n",
      "| AdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3349 | val_loss: 0.00000 - val_binary_acc: 0.2810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.096s\n",
      "| AdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.2935 | val_loss: 0.00000 - val_binary_acc: 0.2810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.094s\n",
      "| AdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.098s\n",
      "| AdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.2962 | val_loss: 0.00000 - val_binary_acc: 0.2810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.128s\n",
      "| AdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.2810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.100s\n",
      "| AdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.2941 | val_loss: 0.00000 - val_binary_acc: 0.2810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.094s\n",
      "| AdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.2789 | val_loss: 0.00000 - val_binary_acc: 0.2810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.103s\n",
      "| AdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.2702 | val_loss: 0.00000 - val_binary_acc: 0.2810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.083s\n",
      "| AdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3078 | val_loss: 0.00000 - val_binary_acc: 0.2810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.086s\n",
      "| AdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.2894 | val_loss: 0.00000 - val_binary_acc: 0.2810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.094s\n",
      "| AdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3152 | val_loss: 0.00000 - val_binary_acc: 0.2810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.086s\n",
      "| AdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.2958 | val_loss: 0.00000 - val_binary_acc: 0.2810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.084s\n",
      "| AdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3059 | val_loss: 0.00000 - val_binary_acc: 0.2810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.085s\n",
      "| AdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.2906 | val_loss: 0.00000 - val_binary_acc: 0.2810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.085s\n",
      "| AdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3048 | val_loss: 0.00000 - val_binary_acc: 0.2810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.087s\n",
      "| AdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.2909 | val_loss: 0.00000 - val_binary_acc: 0.2810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.088s\n",
      "| AdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3041 | val_loss: 0.00000 - val_binary_acc: 0.2810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.088s\n",
      "| AdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.2912 | val_loss: 0.00000 - val_binary_acc: 0.2810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.114s\n",
      "| AdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3048 | val_loss: 0.00000 - val_binary_acc: 0.2810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.088s\n",
      "| AdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.2925 | val_loss: 0.00000 - val_binary_acc: 0.2810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.090s\n",
      "| AdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3008 | val_loss: 0.00000 - val_binary_acc: 0.2810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.085s\n",
      "| AdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.2901 | val_loss: 0.00000 - val_binary_acc: 0.2810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.100s\n",
      "| AdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3027 | val_loss: 0.00000 - val_binary_acc: 0.2810 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'tanh', 1000, [0.24137931070753332]]\n",
      "AdaGrad\n",
      "tanh\n",
      "100\n",
      "---------------------------------\n",
      "Run id: CP1W9Z\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.174s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.2329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.009s\n",
      "| AdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.3270 | val_loss: 0.00000 - val_binary_acc: 0.2329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.010s\n",
      "| AdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.2851 | val_loss: 0.00000 - val_binary_acc: 0.2329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.012s\n",
      "| AdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3447 | val_loss: 0.00000 - val_binary_acc: 0.2329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.011s\n",
      "| AdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.2970 | val_loss: 0.00000 - val_binary_acc: 0.2329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.012s\n",
      "| AdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3425 | val_loss: 0.00000 - val_binary_acc: 0.2329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.013s\n",
      "| AdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.3025 | val_loss: 0.00000 - val_binary_acc: 0.2329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.011s\n",
      "| AdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.2882 | val_loss: 0.00000 - val_binary_acc: 0.2329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.012s\n",
      "| AdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.2823 | val_loss: 0.00000 - val_binary_acc: 0.2329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.011s\n",
      "| AdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.2797 | val_loss: 0.00000 - val_binary_acc: 0.2329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.012s\n",
      "| AdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.2785 | val_loss: 0.00000 - val_binary_acc: 0.2329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.011s\n",
      "| AdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.2779 | val_loss: 0.00000 - val_binary_acc: 0.2329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.012s\n",
      "| AdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.2775 | val_loss: 0.00000 - val_binary_acc: 0.2329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.011s\n",
      "| AdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.2989 | val_loss: 0.00000 - val_binary_acc: 0.2329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.011s\n",
      "| AdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.2904 | val_loss: 0.00000 - val_binary_acc: 0.2329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.009s\n",
      "| AdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3151 | val_loss: 0.00000 - val_binary_acc: 0.2329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.011s\n",
      "| AdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.3014 | val_loss: 0.00000 - val_binary_acc: 0.2329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.011s\n",
      "| AdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3134 | val_loss: 0.00000 - val_binary_acc: 0.2329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.011s\n",
      "| AdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.3013 | val_loss: 0.00000 - val_binary_acc: 0.2329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.012s\n",
      "| AdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3137 | val_loss: 0.00000 - val_binary_acc: 0.2329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.011s\n",
      "| AdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.3024 | val_loss: 0.00000 - val_binary_acc: 0.2329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.012s\n",
      "| AdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3144 | val_loss: 0.00000 - val_binary_acc: 0.2329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.010s\n",
      "| AdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.3034 | val_loss: 0.00000 - val_binary_acc: 0.2329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.011s\n",
      "| AdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3095 | val_loss: 0.00000 - val_binary_acc: 0.2329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.011s\n",
      "| AdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3005 | val_loss: 0.00000 - val_binary_acc: 0.2329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.010s\n",
      "| AdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3072 | val_loss: 0.00000 - val_binary_acc: 0.2329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.011s\n",
      "| AdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.2993 | val_loss: 0.00000 - val_binary_acc: 0.2329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.011s\n",
      "| AdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3080 | val_loss: 0.00000 - val_binary_acc: 0.2329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.011s\n",
      "| AdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.3004 | val_loss: 0.00000 - val_binary_acc: 0.2329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.010s\n",
      "| AdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3072 | val_loss: 0.00000 - val_binary_acc: 0.2329 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'tanh', 100, [0.26774847706964966]]\n",
      "AdaGrad\n",
      "tanh\n",
      "35\n",
      "---------------------------------\n",
      "Run id: 12RZYD\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.124s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.5165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.007s\n",
      "| AdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.3350 | val_loss: 0.00000 - val_binary_acc: 0.5165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.008s\n",
      "| AdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.4651 | val_loss: 0.00000 - val_binary_acc: 0.5165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.008s\n",
      "| AdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.4107 | val_loss: 0.00000 - val_binary_acc: 0.5165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.008s\n",
      "| AdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.4683 | val_loss: 0.00000 - val_binary_acc: 0.5165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.009s\n",
      "| AdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.4180 | val_loss: 0.00000 - val_binary_acc: 0.5165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.009s\n",
      "| AdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.4636 | val_loss: 0.00000 - val_binary_acc: 0.5165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.009s\n",
      "| AdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.4400 | val_loss: 0.00000 - val_binary_acc: 0.5165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.009s\n",
      "| AdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.4686 | val_loss: 0.00000 - val_binary_acc: 0.5165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.009s\n",
      "| AdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.4245 | val_loss: 0.00000 - val_binary_acc: 0.5165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.008s\n",
      "| AdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.4574 | val_loss: 0.00000 - val_binary_acc: 0.5165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.009s\n",
      "| AdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.4496 | val_loss: 0.00000 - val_binary_acc: 0.5165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.009s\n",
      "| AdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.4681 | val_loss: 0.00000 - val_binary_acc: 0.5165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.010s\n",
      "| AdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.4312 | val_loss: 0.00000 - val_binary_acc: 0.5165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.011s\n",
      "| AdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.4553 | val_loss: 0.00000 - val_binary_acc: 0.5165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.009s\n",
      "| AdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.4460 | val_loss: 0.00000 - val_binary_acc: 0.5165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.008s\n",
      "| AdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.4628 | val_loss: 0.00000 - val_binary_acc: 0.5165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.008s\n",
      "| AdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.4400 | val_loss: 0.00000 - val_binary_acc: 0.5165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.010s\n",
      "| AdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.4576 | val_loss: 0.00000 - val_binary_acc: 0.5165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.009s\n",
      "| AdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.4444 | val_loss: 0.00000 - val_binary_acc: 0.5165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.008s\n",
      "| AdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.4590 | val_loss: 0.00000 - val_binary_acc: 0.5165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.010s\n",
      "| AdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.4507 | val_loss: 0.00000 - val_binary_acc: 0.5165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.010s\n",
      "| AdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.4632 | val_loss: 0.00000 - val_binary_acc: 0.5165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.009s\n",
      "| AdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.4519 | val_loss: 0.00000 - val_binary_acc: 0.5165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.008s\n",
      "| AdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.4634 | val_loss: 0.00000 - val_binary_acc: 0.5165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.009s\n",
      "| AdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.4525 | val_loss: 0.00000 - val_binary_acc: 0.5165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.010s\n",
      "| AdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.4632 | val_loss: 0.00000 - val_binary_acc: 0.5165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.009s\n",
      "| AdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.4566 | val_loss: 0.00000 - val_binary_acc: 0.5139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.010s\n",
      "| AdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.4657 | val_loss: 0.00000 - val_binary_acc: 0.5139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.010s\n",
      "| AdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.4539 | val_loss: 0.00000 - val_binary_acc: 0.5139 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'tanh', 35, [0.488843810364876]]\n",
      "AdaGrad\n",
      "prelu\n",
      "1000\n",
      "---------------------------------\n",
      "Run id: HA4UUP\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.385s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.112s\n",
      "| AdaGrad | epoch: 002 | loss: nan - binary_acc: 0.2854 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.106s\n",
      "| AdaGrad | epoch: 003 | loss: nan - binary_acc: 0.4182 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.109s\n",
      "| AdaGrad | epoch: 004 | loss: nan - binary_acc: 0.4403 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.118s\n",
      "| AdaGrad | epoch: 005 | loss: nan - binary_acc: 0.4454 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.121s\n",
      "| AdaGrad | epoch: 006 | loss: nan - binary_acc: 0.4469 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.172s\n",
      "| AdaGrad | epoch: 007 | loss: nan - binary_acc: 0.4474 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.117s\n",
      "| AdaGrad | epoch: 008 | loss: nan - binary_acc: 0.4475 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.126s\n",
      "| AdaGrad | epoch: 009 | loss: nan - binary_acc: 0.4476 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.122s\n",
      "| AdaGrad | epoch: 010 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.130s\n",
      "| AdaGrad | epoch: 011 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.149s\n",
      "| AdaGrad | epoch: 012 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.110s\n",
      "| AdaGrad | epoch: 013 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.116s\n",
      "| AdaGrad | epoch: 014 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.119s\n",
      "| AdaGrad | epoch: 015 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.117s\n",
      "| AdaGrad | epoch: 016 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.117s\n",
      "| AdaGrad | epoch: 017 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.125s\n",
      "| AdaGrad | epoch: 018 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.118s\n",
      "| AdaGrad | epoch: 019 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.162s\n",
      "| AdaGrad | epoch: 020 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.113s\n",
      "| AdaGrad | epoch: 021 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.115s\n",
      "| AdaGrad | epoch: 022 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.120s\n",
      "| AdaGrad | epoch: 023 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.114s\n",
      "| AdaGrad | epoch: 024 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.113s\n",
      "| AdaGrad | epoch: 025 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.120s\n",
      "| AdaGrad | epoch: 026 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.122s\n",
      "| AdaGrad | epoch: 027 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.139s\n",
      "| AdaGrad | epoch: 028 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.126s\n",
      "| AdaGrad | epoch: 029 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.109s\n",
      "| AdaGrad | epoch: 030 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'prelu', 1000, [0.45436105404132276]]\n",
      "AdaGrad\n",
      "prelu\n",
      "100\n",
      "---------------------------------\n",
      "Run id: ZKLI2O\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.144s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.015s\n",
      "| AdaGrad | epoch: 002 | loss: nan - binary_acc: 0.2985 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.016s\n",
      "| AdaGrad | epoch: 003 | loss: nan - binary_acc: 0.4159 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| AdaGrad | epoch: 004 | loss: nan - binary_acc: 0.4355 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.015s\n",
      "| AdaGrad | epoch: 005 | loss: nan - binary_acc: 0.4400 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.016s\n",
      "| AdaGrad | epoch: 006 | loss: nan - binary_acc: 0.4413 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| AdaGrad | epoch: 007 | loss: nan - binary_acc: 0.4417 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.014s\n",
      "| AdaGrad | epoch: 008 | loss: nan - binary_acc: 0.4419 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.014s\n",
      "| AdaGrad | epoch: 009 | loss: nan - binary_acc: 0.4419 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.016s\n",
      "| AdaGrad | epoch: 010 | loss: nan - binary_acc: 0.4419 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| AdaGrad | epoch: 011 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| AdaGrad | epoch: 012 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| AdaGrad | epoch: 013 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.014s\n",
      "| AdaGrad | epoch: 014 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| AdaGrad | epoch: 015 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| AdaGrad | epoch: 016 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.026s\n",
      "| AdaGrad | epoch: 017 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.014s\n",
      "| AdaGrad | epoch: 018 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.016s\n",
      "| AdaGrad | epoch: 019 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.014s\n",
      "| AdaGrad | epoch: 020 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| AdaGrad | epoch: 021 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| AdaGrad | epoch: 022 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.014s\n",
      "| AdaGrad | epoch: 023 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.014s\n",
      "| AdaGrad | epoch: 024 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.025s\n",
      "| AdaGrad | epoch: 025 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| AdaGrad | epoch: 026 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.014s\n",
      "| AdaGrad | epoch: 027 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| AdaGrad | epoch: 028 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.015s\n",
      "| AdaGrad | epoch: 029 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.014s\n",
      "| AdaGrad | epoch: 030 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'prelu', 100, [0.45436105404132276]]\n",
      "AdaGrad\n",
      "prelu\n",
      "35\n",
      "---------------------------------\n",
      "Run id: P34L8A\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.214s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 002 | loss: nan - binary_acc: 0.2916 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 003 | loss: nan - binary_acc: 0.4167 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 004 | loss: nan - binary_acc: 0.4376 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 005 | loss: nan - binary_acc: 0.4424 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 006 | loss: nan - binary_acc: 0.4438 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaGrad | epoch: 007 | loss: nan - binary_acc: 0.4442 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaGrad | epoch: 008 | loss: nan - binary_acc: 0.4444 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaGrad | epoch: 009 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 010 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 011 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 012 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 013 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaGrad | epoch: 014 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 015 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 016 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 017 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 018 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 019 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 020 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 021 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 022 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 023 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 024 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 025 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 026 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 027 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaGrad | epoch: 028 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 029 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 030 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'prelu', 35, [0.45436105404132276]]\n",
      "ProximalAdaGrad\n",
      "relu\n",
      "1000\n",
      "---------------------------------\n",
      "Run id: WTC30P\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.196s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.118s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: nan - binary_acc: 0.3989 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.094s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: nan - binary_acc: 0.4352 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.086s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: nan - binary_acc: 0.4412 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.083s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.090s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: nan - binary_acc: 0.4430 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.091s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.094s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.093s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.093s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.090s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.090s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.115s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.093s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.093s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.090s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.088s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.090s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.096s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.093s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.102s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.088s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.089s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.121s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.095s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.092s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.088s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.095s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.096s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.091s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'relu', 1000, [0.45436105404132276]]\n",
      "ProximalAdaGrad\n",
      "relu\n",
      "100\n",
      "---------------------------------\n",
      "Run id: OEHLNL\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.134s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: nan - binary_acc: 0.3122 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: nan - binary_acc: 0.4163 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.014s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: nan - binary_acc: 0.4337 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: nan - binary_acc: 0.4377 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: nan - binary_acc: 0.4392 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: nan - binary_acc: 0.4393 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'relu', 100, [0.45436105404132276]]\n",
      "ProximalAdaGrad\n",
      "relu\n",
      "35\n",
      "---------------------------------\n",
      "Run id: KO847I\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.148s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: nan - binary_acc: 0.3088 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: nan - binary_acc: 0.4141 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: nan - binary_acc: 0.4317 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: nan - binary_acc: 0.4357 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: nan - binary_acc: 0.4373 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: nan - binary_acc: 0.4374 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'relu', 35, [0.45436105404132276]]\n",
      "ProximalAdaGrad\n",
      "linear\n",
      "1000\n",
      "---------------------------------\n",
      "Run id: Q38MZ1\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.195s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.082s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.3504 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.090s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.4741 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.089s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.4947 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.090s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.4995 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.082s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.5008 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.084s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.5013 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.081s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.4529 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.102s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.4787 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.096s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.4445 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.083s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.4715 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.090s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.4348 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.081s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.4634 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.101s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.4378 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.088s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.4628 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.088s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.4424 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.086s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.4637 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.095s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.4498 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.097s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.4671 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.088s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.4400 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.115s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.4591 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.089s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.4487 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.091s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.4640 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.099s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.4464 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.093s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.4615 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.106s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.4474 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.097s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.4613 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.116s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.4479 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.114s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.4610 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.096s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.4481 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'linear', 1000, [0.494929004211213]]\n",
      "ProximalAdaGrad\n",
      "linear\n",
      "100\n",
      "---------------------------------\n",
      "Run id: 9G6A9U\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.123s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.2253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.3230 | val_loss: 0.00000 - val_binary_acc: 0.2253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.2891 | val_loss: 0.00000 - val_binary_acc: 0.2253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.2834 | val_loss: 0.00000 - val_binary_acc: 0.2253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.2821 | val_loss: 0.00000 - val_binary_acc: 0.2253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3413 | val_loss: 0.00000 - val_binary_acc: 0.2253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.3054 | val_loss: 0.00000 - val_binary_acc: 0.2253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3255 | val_loss: 0.00000 - val_binary_acc: 0.2253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.3022 | val_loss: 0.00000 - val_binary_acc: 0.2253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3391 | val_loss: 0.00000 - val_binary_acc: 0.2253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.3119 | val_loss: 0.00000 - val_binary_acc: 0.2253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3362 | val_loss: 0.00000 - val_binary_acc: 0.2253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.014s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.3128 | val_loss: 0.00000 - val_binary_acc: 0.2253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3355 | val_loss: 0.00000 - val_binary_acc: 0.2253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.3144 | val_loss: 0.00000 - val_binary_acc: 0.2253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3282 | val_loss: 0.00000 - val_binary_acc: 0.2253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.3114 | val_loss: 0.00000 - val_binary_acc: 0.2253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3011 | val_loss: 0.00000 - val_binary_acc: 0.2253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.2946 | val_loss: 0.00000 - val_binary_acc: 0.2253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.2904 | val_loss: 0.00000 - val_binary_acc: 0.2253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.2876 | val_loss: 0.00000 - val_binary_acc: 0.2253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.013s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.2858 | val_loss: 0.00000 - val_binary_acc: 0.2253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.2846 | val_loss: 0.00000 - val_binary_acc: 0.2253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.2837 | val_loss: 0.00000 - val_binary_acc: 0.2253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.2831 | val_loss: 0.00000 - val_binary_acc: 0.2253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.2827 | val_loss: 0.00000 - val_binary_acc: 0.2253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.2824 | val_loss: 0.00000 - val_binary_acc: 0.2253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.2822 | val_loss: 0.00000 - val_binary_acc: 0.2253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.2820 | val_loss: 0.00000 - val_binary_acc: 0.2253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.2819 | val_loss: 0.00000 - val_binary_acc: 0.2253 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'linear', 100, [0.27586206963047777]]\n",
      "ProximalAdaGrad\n",
      "linear\n",
      "35\n",
      "---------------------------------\n",
      "Run id: 3464UH\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.112s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.3367 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.4654 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.4074 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.4665 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.4833 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.4886 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.4392 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.4682 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.4221 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.4562 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.4292 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.4564 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.4710 | val_loss: 0.00000 - val_binary_acc: 0.5367 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.4800 | val_loss: 0.00000 - val_binary_acc: 0.5342 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.4436 | val_loss: 0.00000 - val_binary_acc: 0.5342 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.4627 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.4744 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.4843 | val_loss: 0.00000 - val_binary_acc: 0.5418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.4619 | val_loss: 0.00000 - val_binary_acc: 0.5418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.4744 | val_loss: 0.00000 - val_binary_acc: 0.5418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.4571 | val_loss: 0.00000 - val_binary_acc: 0.5418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.4702 | val_loss: 0.00000 - val_binary_acc: 0.5367 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.4589 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.4710 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.4521 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.4655 | val_loss: 0.00000 - val_binary_acc: 0.5367 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.4512 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.4641 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.4488 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'linear', 35, [0.4929006089424265]]\n",
      "ProximalAdaGrad\n",
      "softmax\n",
      "1000\n",
      "---------------------------------\n",
      "Run id: 2T27CH\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.219s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3367 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.089s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.2882 | val_loss: 0.00000 - val_binary_acc: 0.3367 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.107s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.3144 | val_loss: 0.00000 - val_binary_acc: 0.3367 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.097s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3188 | val_loss: 0.00000 - val_binary_acc: 0.3367 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.093s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.3198 | val_loss: 0.00000 - val_binary_acc: 0.3367 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.116s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3201 | val_loss: 0.00000 - val_binary_acc: 0.3367 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.101s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.3202 | val_loss: 0.00000 - val_binary_acc: 0.3367 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.108s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3202 | val_loss: 0.00000 - val_binary_acc: 0.3367 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.100s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.3202 | val_loss: 0.00000 - val_binary_acc: 0.3367 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.096s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3202 | val_loss: 0.00000 - val_binary_acc: 0.3367 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.097s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.3202 | val_loss: 0.00000 - val_binary_acc: 0.3367 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.092s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3202 | val_loss: 0.00000 - val_binary_acc: 0.3367 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.102s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.3202 | val_loss: 0.00000 - val_binary_acc: 0.3367 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.101s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3202 | val_loss: 0.00000 - val_binary_acc: 0.3367 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.094s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.3202 | val_loss: 0.00000 - val_binary_acc: 0.3367 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.116s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3202 | val_loss: 0.00000 - val_binary_acc: 0.3367 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.094s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.3202 | val_loss: 0.00000 - val_binary_acc: 0.3367 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.111s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3202 | val_loss: 0.00000 - val_binary_acc: 0.3367 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.098s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.3202 | val_loss: 0.00000 - val_binary_acc: 0.3367 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.093s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3202 | val_loss: 0.00000 - val_binary_acc: 0.3367 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.094s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.3202 | val_loss: 0.00000 - val_binary_acc: 0.3367 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.109s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3202 | val_loss: 0.00000 - val_binary_acc: 0.3367 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.148s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.3202 | val_loss: 0.00000 - val_binary_acc: 0.3367 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.099s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3202 | val_loss: 0.00000 - val_binary_acc: 0.3367 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.090s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3202 | val_loss: 0.00000 - val_binary_acc: 0.3367 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.151s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3202 | val_loss: 0.00000 - val_binary_acc: 0.3367 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.111s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.3202 | val_loss: 0.00000 - val_binary_acc: 0.3367 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.116s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3202 | val_loss: 0.00000 - val_binary_acc: 0.3367 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.106s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.3202 | val_loss: 0.00000 - val_binary_acc: 0.3367 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.116s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3202 | val_loss: 0.00000 - val_binary_acc: 0.3367 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'softmax', 1000, [0.3002028369758482]]\n",
      "ProximalAdaGrad\n",
      "softmax\n",
      "100\n",
      "---------------------------------\n",
      "Run id: BPCE8Z\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.127s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.2979 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.015s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.3250 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.020s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3295 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.013s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.3305 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3308 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.3309 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.014s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.013s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.013s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.013s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.013s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.014s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.013s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.013s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'softmax', 100, [0.3002028369758482]]\n",
      "ProximalAdaGrad\n",
      "softmax\n",
      "35\n",
      "---------------------------------\n",
      "Run id: MG5SUU\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.127s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.2911 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.3175 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3219 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.3229 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3232 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.3233 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.013s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'softmax', 35, [0.3002028369758482]]\n",
      "ProximalAdaGrad\n",
      "sigmoid\n",
      "1000\n",
      "---------------------------------\n",
      "Run id: M6Y7OI\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.246s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.084s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.2979 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.087s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.3250 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.106s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3295 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.088s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.3305 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.087s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3308 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.085s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.3309 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.117s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.102s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.096s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.094s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.111s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.115s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.104s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.099s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.102s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.143s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.094s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.119s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.125s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.102s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.090s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.096s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.100s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.101s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.134s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.088s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.091s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.092s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.088s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'sigmoid', 1000, [0.3002028369758482]]\n",
      "ProximalAdaGrad\n",
      "sigmoid\n",
      "100\n",
      "---------------------------------\n",
      "Run id: MA8FME\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.110s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.2939 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.3206 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3251 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.3261 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3264 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.3265 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3265 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'sigmoid', 100, [0.3002028369758482]]\n",
      "ProximalAdaGrad\n",
      "sigmoid\n",
      "35\n",
      "---------------------------------\n",
      "Run id: BU5345\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.104s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.2911 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.3175 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3219 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.3229 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3232 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.3233 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.006s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'sigmoid', 35, [0.3002028369758482]]\n",
      "ProximalAdaGrad\n",
      "tanh\n",
      "1000\n",
      "---------------------------------\n",
      "Run id: XGU2Z6\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.194s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.4759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.100s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.3772 | val_loss: 0.00000 - val_binary_acc: 0.4759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.096s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.4852 | val_loss: 0.00000 - val_binary_acc: 0.4759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.091s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.4081 | val_loss: 0.00000 - val_binary_acc: 0.4759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.090s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.4781 | val_loss: 0.00000 - val_binary_acc: 0.4759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.093s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.4382 | val_loss: 0.00000 - val_binary_acc: 0.4759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.094s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.4808 | val_loss: 0.00000 - val_binary_acc: 0.4759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.090s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.4379 | val_loss: 0.00000 - val_binary_acc: 0.4759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.092s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.4756 | val_loss: 0.00000 - val_binary_acc: 0.4759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.091s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.4309 | val_loss: 0.00000 - val_binary_acc: 0.4759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.087s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.4680 | val_loss: 0.00000 - val_binary_acc: 0.4759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.089s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.4403 | val_loss: 0.00000 - val_binary_acc: 0.4759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.093s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.4698 | val_loss: 0.00000 - val_binary_acc: 0.4759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.094s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.4496 | val_loss: 0.00000 - val_binary_acc: 0.4759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.109s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.4729 | val_loss: 0.00000 - val_binary_acc: 0.4759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.100s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.4452 | val_loss: 0.00000 - val_binary_acc: 0.4759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.104s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.4682 | val_loss: 0.00000 - val_binary_acc: 0.4759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.103s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.4824 | val_loss: 0.00000 - val_binary_acc: 0.4759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.105s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.4913 | val_loss: 0.00000 - val_binary_acc: 0.4759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.105s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.4614 | val_loss: 0.00000 - val_binary_acc: 0.4759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.089s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.4762 | val_loss: 0.00000 - val_binary_acc: 0.4759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.113s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.4557 | val_loss: 0.00000 - val_binary_acc: 0.4759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.112s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.4712 | val_loss: 0.00000 - val_binary_acc: 0.4759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.107s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.4559 | val_loss: 0.00000 - val_binary_acc: 0.4759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.104s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.4704 | val_loss: 0.00000 - val_binary_acc: 0.4759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.098s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.4555 | val_loss: 0.00000 - val_binary_acc: 0.4759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.093s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.4693 | val_loss: 0.00000 - val_binary_acc: 0.4759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.111s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.4569 | val_loss: 0.00000 - val_binary_acc: 0.4759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.097s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.4696 | val_loss: 0.00000 - val_binary_acc: 0.4759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.096s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.4554 | val_loss: 0.00000 - val_binary_acc: 0.4759 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'tanh', 1000, [0.5030425967720411]]\n",
      "ProximalAdaGrad\n",
      "tanh\n",
      "100\n",
      "---------------------------------\n",
      "Run id: 42NSWK\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.128s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.3595 | val_loss: 0.00000 - val_binary_acc: 0.3342 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.3658 | val_loss: 0.00000 - val_binary_acc: 0.3342 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3854 | val_loss: 0.00000 - val_binary_acc: 0.3342 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.3732 | val_loss: 0.00000 - val_binary_acc: 0.3367 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3758 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.3710 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.013s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3813 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.3738 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3920 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.3803 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3895 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.3799 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3884 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.3801 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3753 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.013s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.3726 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3832 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.3779 | val_loss: 0.00000 - val_binary_acc: 0.3367 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3877 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.3805 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3773 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.3743 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3789 | val_loss: 0.00000 - val_binary_acc: 0.3342 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3757 | val_loss: 0.00000 - val_binary_acc: 0.3342 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3803 | val_loss: 0.00000 - val_binary_acc: 0.3367 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.3769 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3791 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.3762 | val_loss: 0.00000 - val_binary_acc: 0.3367 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3784 | val_loss: 0.00000 - val_binary_acc: 0.3342 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'tanh', 100, [0.336713998603047]]\n",
      "ProximalAdaGrad\n",
      "tanh\n",
      "35\n",
      "---------------------------------\n",
      "Run id: M843EB\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.111s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.2684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.2876 | val_loss: 0.00000 - val_binary_acc: 0.2658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.2686 | val_loss: 0.00000 - val_binary_acc: 0.2684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3463 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.2914 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.2753 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.2703 | val_loss: 0.00000 - val_binary_acc: 0.2658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.2884 | val_loss: 0.00000 - val_binary_acc: 0.2608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.2767 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3327 | val_loss: 0.00000 - val_binary_acc: 0.2608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.3025 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.3044 | val_loss: 0.00000 - val_binary_acc: 0.2608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3282 | val_loss: 0.00000 - val_binary_acc: 0.2608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.3060 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3351 | val_loss: 0.00000 - val_binary_acc: 0.2608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.3133 | val_loss: 0.00000 - val_binary_acc: 0.2608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3366 | val_loss: 0.00000 - val_binary_acc: 0.2608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.3157 | val_loss: 0.00000 - val_binary_acc: 0.2658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3324 | val_loss: 0.00000 - val_binary_acc: 0.2684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.3147 | val_loss: 0.00000 - val_binary_acc: 0.2608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3331 | val_loss: 0.00000 - val_binary_acc: 0.2608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.3163 | val_loss: 0.00000 - val_binary_acc: 0.2608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3318 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3157 | val_loss: 0.00000 - val_binary_acc: 0.2608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.2608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.3129 | val_loss: 0.00000 - val_binary_acc: 0.2608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3270 | val_loss: 0.00000 - val_binary_acc: 0.2608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.3137 | val_loss: 0.00000 - val_binary_acc: 0.2608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3270 | val_loss: 0.00000 - val_binary_acc: 0.2608 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'tanh', 35, [0.29208924900929295]]\n",
      "ProximalAdaGrad\n",
      "prelu\n",
      "1000\n",
      "---------------------------------\n",
      "Run id: M7XE3C\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.266s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4177 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.152s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: nan - binary_acc: 0.3139 | val_loss: nan - val_binary_acc: 0.4177 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.117s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: nan - binary_acc: 0.4223 | val_loss: nan - val_binary_acc: 0.4177 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.114s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: nan - binary_acc: 0.4404 | val_loss: nan - val_binary_acc: 0.4177 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.122s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: nan - binary_acc: 0.4446 | val_loss: nan - val_binary_acc: 0.4177 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.110s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: nan - binary_acc: 0.4458 | val_loss: nan - val_binary_acc: 0.4177 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.113s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: nan - binary_acc: 0.4462 | val_loss: nan - val_binary_acc: 0.4177 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.124s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: nan - binary_acc: 0.4463 | val_loss: nan - val_binary_acc: 0.4177 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.147s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: nan - binary_acc: 0.4464 | val_loss: nan - val_binary_acc: 0.4177 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.111s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: nan - binary_acc: 0.4464 | val_loss: nan - val_binary_acc: 0.4177 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.132s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: nan - binary_acc: 0.4464 | val_loss: nan - val_binary_acc: 0.4177 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.127s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: nan - binary_acc: 0.4464 | val_loss: nan - val_binary_acc: 0.4177 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.120s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: nan - binary_acc: 0.4464 | val_loss: nan - val_binary_acc: 0.4177 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.129s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: nan - binary_acc: 0.4464 | val_loss: nan - val_binary_acc: 0.4177 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.112s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: nan - binary_acc: 0.4464 | val_loss: nan - val_binary_acc: 0.4177 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.159s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: nan - binary_acc: 0.4464 | val_loss: nan - val_binary_acc: 0.4177 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.119s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: nan - binary_acc: 0.4464 | val_loss: nan - val_binary_acc: 0.4177 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.108s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: nan - binary_acc: 0.4464 | val_loss: nan - val_binary_acc: 0.4177 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.108s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: nan - binary_acc: 0.4464 | val_loss: nan - val_binary_acc: 0.4177 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.124s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: nan - binary_acc: 0.4464 | val_loss: nan - val_binary_acc: 0.4177 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.121s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: nan - binary_acc: 0.4464 | val_loss: nan - val_binary_acc: 0.4177 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.115s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: nan - binary_acc: 0.4464 | val_loss: nan - val_binary_acc: 0.4177 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.134s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: nan - binary_acc: 0.4464 | val_loss: nan - val_binary_acc: 0.4177 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.116s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: nan - binary_acc: 0.4464 | val_loss: nan - val_binary_acc: 0.4177 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.122s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: nan - binary_acc: 0.4464 | val_loss: nan - val_binary_acc: 0.4177 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.124s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: nan - binary_acc: 0.4464 | val_loss: nan - val_binary_acc: 0.4177 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.128s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: nan - binary_acc: 0.4464 | val_loss: nan - val_binary_acc: 0.4177 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.123s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: nan - binary_acc: 0.4464 | val_loss: nan - val_binary_acc: 0.4177 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.121s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: nan - binary_acc: 0.4464 | val_loss: nan - val_binary_acc: 0.4177 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.145s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: nan - binary_acc: 0.4464 | val_loss: nan - val_binary_acc: 0.4177 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'prelu', 1000, [0.45436105404132276]]\n",
      "ProximalAdaGrad\n",
      "prelu\n",
      "100\n",
      "---------------------------------\n",
      "Run id: 1HKSB2\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.162s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: nan - binary_acc: 0.3185 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.014s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: nan - binary_acc: 0.4195 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: nan - binary_acc: 0.4364 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.014s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: nan - binary_acc: 0.4403 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.017s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: nan - binary_acc: 0.4414 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: nan - binary_acc: 0.4417 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: nan - binary_acc: 0.4419 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.017s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: nan - binary_acc: 0.4419 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.014s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.015s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.015s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.015s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.015s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.014s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.016s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.015s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.015s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.014s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'prelu', 100, [0.45436105404132276]]\n",
      "ProximalAdaGrad\n",
      "prelu\n",
      "35\n",
      "---------------------------------\n",
      "Run id: QIKI1E\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.188s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: nan - binary_acc: 0.3430 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: nan - binary_acc: 0.4250 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: nan - binary_acc: 0.4387 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: nan - binary_acc: 0.4418 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: nan - binary_acc: 0.4427 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: nan - binary_acc: 0.4430 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'prelu', 35, [0.45436105404132276]]\n"
     ]
    }
   ],
   "source": [
    "#\"ProximalAdaGrad\",\"sgd\",'RMSProp','AdaGrad',\"ProximalAdaGrad\" \"momentum\",\"momentum\",'RMSProp' \" \"momentum\"\n",
    "optimizadores=[\"AdaDelta\",'RMSProp','AdaGrad',\"ProximalAdaGrad\"]\n",
    "#\n",
    "tf.reset_default_graph()\n",
    "activator=[  \"relu\", \"linear\" ,\"softmax\" ,'sigmoid','tanh','prelu']\n",
    "tamanio=[[1000,1000,1],[100,100],[35,35]]\n",
    "#t#amanio=[[64,64,30,10]]\n",
    "#sgd = tflearn.SGD(learning_rate=0.01,lr_decay=0.96 , decay_step=500)\n",
    "resultados=[]\n",
    "for o in optimizadores:\n",
    "    for a in activator:\n",
    "        for t in tamanio:\n",
    "            \n",
    "            print(o)\n",
    "            print(a)\n",
    "            print(str(t[0]))\n",
    "            tf.reset_default_graph()\n",
    "            net = tflearn.input_data(shape=[None, 6])\n",
    "            net = tflearn.fully_connected(net,t[0], activation=a,regularizer=\"L2\", weights_init='normal', weight_decay=0.001)\n",
    "            net = tflearn.fully_connected(net,t[1], activation=a,regularizer=\"L2\", weights_init='normal', weight_decay=0.001)\n",
    "\n",
    "            net = tflearn.fully_connected(net,1, activation=a,regularizer=\"L2\", weights_init='normal', weight_decay=0.001)\n",
    "            net = tflearn.regression(net, optimizer=o,loss=\"categorical_crossentropy\",metric=\"accuracy\")\n",
    "            model = tflearn.DNN(net)\n",
    "            model.fit(entrenamiento, entrenamiento_lbl,show_metric=True,validation_set=0.2,n_epoch=30,batch_size=len(entrenamiento))\n",
    "            accu=model.evaluate(validacion, validacion_lbl)\n",
    "            \n",
    "            #print(accu)\n",
    "            config=[o,a,t[0],accu]\n",
    "            print(config)\n",
    "            resultados.append(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados=pd.DataFrame(resultados)\n",
    "a=resultados[3]\n",
    "accu=[i[0] for i in a]\n",
    "resultados[\"accu\"]=accu\n",
    "\n",
    "resultados=resultados.sort_values(by=\"accu\",ascending=False)\n",
    "resultados.to_csv(\"resultados_rna_ECI_a.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNA a una capa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaDelta\n",
      "relu\n",
      "1000\n",
      "---------------------------------\n",
      "Run id: QL9A0J\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.197s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.3975 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaDelta | epoch: 002 | loss: nan - binary_acc: 0.3413 | val_loss: nan - val_binary_acc: 0.3975 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.014s\n",
      "| AdaDelta | epoch: 003 | loss: nan - binary_acc: 0.4315 | val_loss: nan - val_binary_acc: 0.3975 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.015s\n",
      "| AdaDelta | epoch: 004 | loss: nan - binary_acc: 0.4465 | val_loss: nan - val_binary_acc: 0.3975 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| AdaDelta | epoch: 005 | loss: nan - binary_acc: 0.4499 | val_loss: nan - val_binary_acc: 0.3975 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.014s\n",
      "| AdaDelta | epoch: 006 | loss: nan - binary_acc: 0.4509 | val_loss: nan - val_binary_acc: 0.3975 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| AdaDelta | epoch: 007 | loss: nan - binary_acc: 0.4513 | val_loss: nan - val_binary_acc: 0.3975 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.014s\n",
      "| AdaDelta | epoch: 008 | loss: nan - binary_acc: 0.4514 | val_loss: nan - val_binary_acc: 0.3975 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| AdaDelta | epoch: 009 | loss: nan - binary_acc: 0.4514 | val_loss: nan - val_binary_acc: 0.3975 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| AdaDelta | epoch: 010 | loss: nan - binary_acc: 0.4515 | val_loss: nan - val_binary_acc: 0.3975 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.014s\n",
      "| AdaDelta | epoch: 011 | loss: nan - binary_acc: 0.4515 | val_loss: nan - val_binary_acc: 0.3975 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| AdaDelta | epoch: 012 | loss: nan - binary_acc: 0.4515 | val_loss: nan - val_binary_acc: 0.3975 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| AdaDelta | epoch: 013 | loss: nan - binary_acc: 0.4515 | val_loss: nan - val_binary_acc: 0.3975 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| AdaDelta | epoch: 014 | loss: nan - binary_acc: 0.4515 | val_loss: nan - val_binary_acc: 0.3975 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| AdaDelta | epoch: 015 | loss: nan - binary_acc: 0.4515 | val_loss: nan - val_binary_acc: 0.3975 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| AdaDelta | epoch: 016 | loss: nan - binary_acc: 0.4515 | val_loss: nan - val_binary_acc: 0.3975 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| AdaDelta | epoch: 017 | loss: nan - binary_acc: 0.4515 | val_loss: nan - val_binary_acc: 0.3975 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| AdaDelta | epoch: 018 | loss: nan - binary_acc: 0.4515 | val_loss: nan - val_binary_acc: 0.3975 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| AdaDelta | epoch: 019 | loss: nan - binary_acc: 0.4515 | val_loss: nan - val_binary_acc: 0.3975 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| AdaDelta | epoch: 020 | loss: nan - binary_acc: 0.4515 | val_loss: nan - val_binary_acc: 0.3975 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| AdaDelta | epoch: 021 | loss: nan - binary_acc: 0.4515 | val_loss: nan - val_binary_acc: 0.3975 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| AdaDelta | epoch: 022 | loss: nan - binary_acc: 0.4515 | val_loss: nan - val_binary_acc: 0.3975 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| AdaDelta | epoch: 023 | loss: nan - binary_acc: 0.4515 | val_loss: nan - val_binary_acc: 0.3975 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| AdaDelta | epoch: 024 | loss: nan - binary_acc: 0.4515 | val_loss: nan - val_binary_acc: 0.3975 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| AdaDelta | epoch: 025 | loss: nan - binary_acc: 0.4515 | val_loss: nan - val_binary_acc: 0.3975 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| AdaDelta | epoch: 026 | loss: nan - binary_acc: 0.4515 | val_loss: nan - val_binary_acc: 0.3975 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.014s\n",
      "| AdaDelta | epoch: 027 | loss: nan - binary_acc: 0.4515 | val_loss: nan - val_binary_acc: 0.3975 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.017s\n",
      "| AdaDelta | epoch: 028 | loss: nan - binary_acc: 0.4515 | val_loss: nan - val_binary_acc: 0.3975 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| AdaDelta | epoch: 029 | loss: nan - binary_acc: 0.4515 | val_loss: nan - val_binary_acc: 0.3975 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| AdaDelta | epoch: 030 | loss: nan - binary_acc: 0.4515 | val_loss: nan - val_binary_acc: 0.3975 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'relu', 1000, [0.45436105404132276]]\n",
      "AdaDelta\n",
      "relu\n",
      "100\n",
      "---------------------------------\n",
      "Run id: 28TRTW\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.125s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 002 | loss: nan - binary_acc: 0.3019 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 003 | loss: nan - binary_acc: 0.4165 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 004 | loss: nan - binary_acc: 0.4356 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 005 | loss: nan - binary_acc: 0.4400 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 006 | loss: nan - binary_acc: 0.4413 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 007 | loss: nan - binary_acc: 0.4417 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 008 | loss: nan - binary_acc: 0.4419 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaDelta | epoch: 009 | loss: nan - binary_acc: 0.4419 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 010 | loss: nan - binary_acc: 0.4419 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 011 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 012 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 013 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 014 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 015 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 016 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 017 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaDelta | epoch: 018 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 019 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 020 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 021 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 022 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 023 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 024 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaDelta | epoch: 025 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 026 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 027 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 028 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaDelta | epoch: 029 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.015s\n",
      "| AdaDelta | epoch: 030 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'relu', 100, [0.45436105404132276]]\n",
      "AdaDelta\n",
      "relu\n",
      "35\n",
      "---------------------------------\n",
      "Run id: Q7DX1C\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.131s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaDelta | epoch: 002 | loss: nan - binary_acc: 0.2956 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 003 | loss: nan - binary_acc: 0.4133 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 004 | loss: nan - binary_acc: 0.4329 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 005 | loss: nan - binary_acc: 0.4374 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 006 | loss: nan - binary_acc: 0.4387 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 007 | loss: nan - binary_acc: 0.4392 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaDelta | epoch: 008 | loss: nan - binary_acc: 0.4393 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaDelta | epoch: 009 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 010 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 011 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaDelta | epoch: 012 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaDelta | epoch: 013 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaDelta | epoch: 014 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaDelta | epoch: 015 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaDelta | epoch: 016 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 017 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 018 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.006s\n",
      "| AdaDelta | epoch: 019 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 020 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaDelta | epoch: 021 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.006s\n",
      "| AdaDelta | epoch: 022 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaDelta | epoch: 023 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 024 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 025 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 026 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 027 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 028 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 029 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaDelta | epoch: 030 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'relu', 35, [0.45436105404132276]]\n",
      "AdaDelta\n",
      "linear\n",
      "1000\n",
      "---------------------------------\n",
      "Run id: GB0904\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.113s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.2557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.017s\n",
      "| AdaDelta | epoch: 002 | loss: 0.00000 - binary_acc: 0.3487 | val_loss: 0.00000 - val_binary_acc: 0.2557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.014s\n",
      "| AdaDelta | epoch: 003 | loss: 0.00000 - binary_acc: 0.2860 | val_loss: 0.00000 - val_binary_acc: 0.2557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.012s\n",
      "| AdaDelta | epoch: 004 | loss: 0.00000 - binary_acc: 0.2755 | val_loss: 0.00000 - val_binary_acc: 0.2557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.012s\n",
      "| AdaDelta | epoch: 005 | loss: 0.00000 - binary_acc: 0.2731 | val_loss: 0.00000 - val_binary_acc: 0.2557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.013s\n",
      "| AdaDelta | epoch: 006 | loss: 0.00000 - binary_acc: 0.3356 | val_loss: 0.00000 - val_binary_acc: 0.2557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.012s\n",
      "| AdaDelta | epoch: 007 | loss: 0.00000 - binary_acc: 0.2975 | val_loss: 0.00000 - val_binary_acc: 0.2557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.011s\n",
      "| AdaDelta | epoch: 008 | loss: 0.00000 - binary_acc: 0.3392 | val_loss: 0.00000 - val_binary_acc: 0.2557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.011s\n",
      "| AdaDelta | epoch: 009 | loss: 0.00000 - binary_acc: 0.3036 | val_loss: 0.00000 - val_binary_acc: 0.2557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.010s\n",
      "| AdaDelta | epoch: 010 | loss: 0.00000 - binary_acc: 0.3401 | val_loss: 0.00000 - val_binary_acc: 0.2557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.013s\n",
      "| AdaDelta | epoch: 011 | loss: 0.00000 - binary_acc: 0.3079 | val_loss: 0.00000 - val_binary_acc: 0.2557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.012s\n",
      "| AdaDelta | epoch: 012 | loss: 0.00000 - binary_acc: 0.3374 | val_loss: 0.00000 - val_binary_acc: 0.2557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.012s\n",
      "| AdaDelta | epoch: 013 | loss: 0.00000 - binary_acc: 0.3094 | val_loss: 0.00000 - val_binary_acc: 0.2557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.012s\n",
      "| AdaDelta | epoch: 014 | loss: 0.00000 - binary_acc: 0.3405 | val_loss: 0.00000 - val_binary_acc: 0.2557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.012s\n",
      "| AdaDelta | epoch: 015 | loss: 0.00000 - binary_acc: 0.3137 | val_loss: 0.00000 - val_binary_acc: 0.2557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.011s\n",
      "| AdaDelta | epoch: 016 | loss: 0.00000 - binary_acc: 0.3338 | val_loss: 0.00000 - val_binary_acc: 0.2557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.011s\n",
      "| AdaDelta | epoch: 017 | loss: 0.00000 - binary_acc: 0.3115 | val_loss: 0.00000 - val_binary_acc: 0.2557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.012s\n",
      "| AdaDelta | epoch: 018 | loss: 0.00000 - binary_acc: 0.3207 | val_loss: 0.00000 - val_binary_acc: 0.2557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.012s\n",
      "| AdaDelta | epoch: 019 | loss: 0.00000 - binary_acc: 0.3045 | val_loss: 0.00000 - val_binary_acc: 0.2557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.015s\n",
      "| AdaDelta | epoch: 020 | loss: 0.00000 - binary_acc: 0.3124 | val_loss: 0.00000 - val_binary_acc: 0.2557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.014s\n",
      "| AdaDelta | epoch: 021 | loss: 0.00000 - binary_acc: 0.2999 | val_loss: 0.00000 - val_binary_acc: 0.2557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.012s\n",
      "| AdaDelta | epoch: 022 | loss: 0.00000 - binary_acc: 0.3128 | val_loss: 0.00000 - val_binary_acc: 0.2557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.013s\n",
      "| AdaDelta | epoch: 023 | loss: 0.00000 - binary_acc: 0.3010 | val_loss: 0.00000 - val_binary_acc: 0.2557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.012s\n",
      "| AdaDelta | epoch: 024 | loss: 0.00000 - binary_acc: 0.3076 | val_loss: 0.00000 - val_binary_acc: 0.2557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.013s\n",
      "| AdaDelta | epoch: 025 | loss: 0.00000 - binary_acc: 0.2979 | val_loss: 0.00000 - val_binary_acc: 0.2557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.012s\n",
      "| AdaDelta | epoch: 026 | loss: 0.00000 - binary_acc: 0.3092 | val_loss: 0.00000 - val_binary_acc: 0.2557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.011s\n",
      "| AdaDelta | epoch: 027 | loss: 0.00000 - binary_acc: 0.2996 | val_loss: 0.00000 - val_binary_acc: 0.2557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.012s\n",
      "| AdaDelta | epoch: 028 | loss: 0.00000 - binary_acc: 0.3113 | val_loss: 0.00000 - val_binary_acc: 0.2557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.019s\n",
      "| AdaDelta | epoch: 029 | loss: 0.00000 - binary_acc: 0.3017 | val_loss: 0.00000 - val_binary_acc: 0.2557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.012s\n",
      "| AdaDelta | epoch: 030 | loss: 0.00000 - binary_acc: 0.3148 | val_loss: 0.00000 - val_binary_acc: 0.2557 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'linear', 1000, [0.27383367091598665]]\n",
      "AdaDelta\n",
      "linear\n",
      "100\n",
      "---------------------------------\n",
      "Run id: VDFXMN\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.108s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.008s\n",
      "| AdaDelta | epoch: 002 | loss: 0.00000 - binary_acc: 0.3042 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.009s\n",
      "| AdaDelta | epoch: 003 | loss: 0.00000 - binary_acc: 0.2727 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.010s\n",
      "| AdaDelta | epoch: 004 | loss: 0.00000 - binary_acc: 0.3526 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.008s\n",
      "| AdaDelta | epoch: 005 | loss: 0.00000 - binary_acc: 0.2924 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.009s\n",
      "| AdaDelta | epoch: 006 | loss: 0.00000 - binary_acc: 0.2752 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.010s\n",
      "| AdaDelta | epoch: 007 | loss: 0.00000 - binary_acc: 0.2695 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.009s\n",
      "| AdaDelta | epoch: 008 | loss: 0.00000 - binary_acc: 0.2674 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.008s\n",
      "| AdaDelta | epoch: 009 | loss: 0.00000 - binary_acc: 0.2665 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.008s\n",
      "| AdaDelta | epoch: 010 | loss: 0.00000 - binary_acc: 0.2661 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.008s\n",
      "| AdaDelta | epoch: 011 | loss: 0.00000 - binary_acc: 0.2659 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.007s\n",
      "| AdaDelta | epoch: 012 | loss: 0.00000 - binary_acc: 0.2658 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.009s\n",
      "| AdaDelta | epoch: 013 | loss: 0.00000 - binary_acc: 0.3117 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.008s\n",
      "| AdaDelta | epoch: 014 | loss: 0.00000 - binary_acc: 0.2929 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.009s\n",
      "| AdaDelta | epoch: 015 | loss: 0.00000 - binary_acc: 0.2822 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.010s\n",
      "| AdaDelta | epoch: 016 | loss: 0.00000 - binary_acc: 0.3138 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.008s\n",
      "| AdaDelta | epoch: 017 | loss: 0.00000 - binary_acc: 0.2965 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.008s\n",
      "| AdaDelta | epoch: 018 | loss: 0.00000 - binary_acc: 0.3269 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.008s\n",
      "| AdaDelta | epoch: 019 | loss: 0.00000 - binary_acc: 0.3065 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.008s\n",
      "| AdaDelta | epoch: 020 | loss: 0.00000 - binary_acc: 0.2934 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.007s\n",
      "| AdaDelta | epoch: 021 | loss: 0.00000 - binary_acc: 0.3037 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.006s\n",
      "| AdaDelta | epoch: 022 | loss: 0.00000 - binary_acc: 0.3086 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.008s\n",
      "| AdaDelta | epoch: 023 | loss: 0.00000 - binary_acc: 0.2962 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.007s\n",
      "| AdaDelta | epoch: 024 | loss: 0.00000 - binary_acc: 0.2876 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.008s\n",
      "| AdaDelta | epoch: 025 | loss: 0.00000 - binary_acc: 0.2816 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.008s\n",
      "| AdaDelta | epoch: 026 | loss: 0.00000 - binary_acc: 0.3048 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.008s\n",
      "| AdaDelta | epoch: 027 | loss: 0.00000 - binary_acc: 0.2947 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.008s\n",
      "| AdaDelta | epoch: 028 | loss: 0.00000 - binary_acc: 0.3124 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.010s\n",
      "| AdaDelta | epoch: 029 | loss: 0.00000 - binary_acc: 0.3010 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.008s\n",
      "| AdaDelta | epoch: 030 | loss: 0.00000 - binary_acc: 0.3216 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'linear', 100, [0.24543610583937917]]\n",
      "AdaDelta\n",
      "linear\n",
      "35\n",
      "---------------------------------\n",
      "Run id: CLPHA2\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.088s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.2987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.008s\n",
      "| AdaDelta | epoch: 002 | loss: 0.00000 - binary_acc: 0.3356 | val_loss: 0.00000 - val_binary_acc: 0.2987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.007s\n",
      "| AdaDelta | epoch: 003 | loss: 0.00000 - binary_acc: 0.2649 | val_loss: 0.00000 - val_binary_acc: 0.2987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.007s\n",
      "| AdaDelta | epoch: 004 | loss: 0.00000 - binary_acc: 0.3273 | val_loss: 0.00000 - val_binary_acc: 0.2987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.009s\n",
      "| AdaDelta | epoch: 005 | loss: 0.00000 - binary_acc: 0.2732 | val_loss: 0.00000 - val_binary_acc: 0.2987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.007s\n",
      "| AdaDelta | epoch: 006 | loss: 0.00000 - binary_acc: 0.2578 | val_loss: 0.00000 - val_binary_acc: 0.2987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.007s\n",
      "| AdaDelta | epoch: 007 | loss: 0.00000 - binary_acc: 0.2526 | val_loss: 0.00000 - val_binary_acc: 0.2987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.008s\n",
      "| AdaDelta | epoch: 008 | loss: 0.00000 - binary_acc: 0.2507 | val_loss: 0.00000 - val_binary_acc: 0.2987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.007s\n",
      "| AdaDelta | epoch: 009 | loss: 0.00000 - binary_acc: 0.2499 | val_loss: 0.00000 - val_binary_acc: 0.2987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.008s\n",
      "| AdaDelta | epoch: 010 | loss: 0.00000 - binary_acc: 0.3142 | val_loss: 0.00000 - val_binary_acc: 0.2987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.008s\n",
      "| AdaDelta | epoch: 011 | loss: 0.00000 - binary_acc: 0.2834 | val_loss: 0.00000 - val_binary_acc: 0.2987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.008s\n",
      "| AdaDelta | epoch: 012 | loss: 0.00000 - binary_acc: 0.2983 | val_loss: 0.00000 - val_binary_acc: 0.2987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.007s\n",
      "| AdaDelta | epoch: 013 | loss: 0.00000 - binary_acc: 0.2772 | val_loss: 0.00000 - val_binary_acc: 0.2987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.007s\n",
      "| AdaDelta | epoch: 014 | loss: 0.00000 - binary_acc: 0.3192 | val_loss: 0.00000 - val_binary_acc: 0.2987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.007s\n",
      "| AdaDelta | epoch: 015 | loss: 0.00000 - binary_acc: 0.2918 | val_loss: 0.00000 - val_binary_acc: 0.2987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.008s\n",
      "| AdaDelta | epoch: 016 | loss: 0.00000 - binary_acc: 0.3068 | val_loss: 0.00000 - val_binary_acc: 0.2987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.007s\n",
      "| AdaDelta | epoch: 017 | loss: 0.00000 - binary_acc: 0.2860 | val_loss: 0.00000 - val_binary_acc: 0.2987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.007s\n",
      "| AdaDelta | epoch: 018 | loss: 0.00000 - binary_acc: 0.3080 | val_loss: 0.00000 - val_binary_acc: 0.2987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.007s\n",
      "| AdaDelta | epoch: 019 | loss: 0.00000 - binary_acc: 0.2884 | val_loss: 0.00000 - val_binary_acc: 0.2987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.008s\n",
      "| AdaDelta | epoch: 020 | loss: 0.00000 - binary_acc: 0.3043 | val_loss: 0.00000 - val_binary_acc: 0.2987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.009s\n",
      "| AdaDelta | epoch: 021 | loss: 0.00000 - binary_acc: 0.2872 | val_loss: 0.00000 - val_binary_acc: 0.2987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.007s\n",
      "| AdaDelta | epoch: 022 | loss: 0.00000 - binary_acc: 0.3028 | val_loss: 0.00000 - val_binary_acc: 0.2987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.009s\n",
      "| AdaDelta | epoch: 023 | loss: 0.00000 - binary_acc: 0.2873 | val_loss: 0.00000 - val_binary_acc: 0.2987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.006s\n",
      "| AdaDelta | epoch: 024 | loss: 0.00000 - binary_acc: 0.2942 | val_loss: 0.00000 - val_binary_acc: 0.2987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.009s\n",
      "| AdaDelta | epoch: 025 | loss: 0.00000 - binary_acc: 0.2819 | val_loss: 0.00000 - val_binary_acc: 0.2987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.007s\n",
      "| AdaDelta | epoch: 026 | loss: 0.00000 - binary_acc: 0.2966 | val_loss: 0.00000 - val_binary_acc: 0.2987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.007s\n",
      "| AdaDelta | epoch: 027 | loss: 0.00000 - binary_acc: 0.2844 | val_loss: 0.00000 - val_binary_acc: 0.2987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.007s\n",
      "| AdaDelta | epoch: 028 | loss: 0.00000 - binary_acc: 0.3095 | val_loss: 0.00000 - val_binary_acc: 0.2987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.007s\n",
      "| AdaDelta | epoch: 029 | loss: 0.00000 - binary_acc: 0.2949 | val_loss: 0.00000 - val_binary_acc: 0.2987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.007s\n",
      "| AdaDelta | epoch: 030 | loss: 0.00000 - binary_acc: 0.3148 | val_loss: 0.00000 - val_binary_acc: 0.2987 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'linear', 35, [0.24543610698794738]]\n",
      "AdaDelta\n",
      "softmax\n",
      "1000\n",
      "---------------------------------\n",
      "Run id: J4FPCU\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.101s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.018s\n",
      "| AdaDelta | epoch: 002 | loss: 0.00000 - binary_acc: 0.2911 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.019s\n",
      "| AdaDelta | epoch: 003 | loss: 0.00000 - binary_acc: 0.3175 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.017s\n",
      "| AdaDelta | epoch: 004 | loss: 0.00000 - binary_acc: 0.3219 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.018s\n",
      "| AdaDelta | epoch: 005 | loss: 0.00000 - binary_acc: 0.3229 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.018s\n",
      "| AdaDelta | epoch: 006 | loss: 0.00000 - binary_acc: 0.3232 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.018s\n",
      "| AdaDelta | epoch: 007 | loss: 0.00000 - binary_acc: 0.3233 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.019s\n",
      "| AdaDelta | epoch: 008 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.018s\n",
      "| AdaDelta | epoch: 009 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.020s\n",
      "| AdaDelta | epoch: 010 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.021s\n",
      "| AdaDelta | epoch: 011 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.017s\n",
      "| AdaDelta | epoch: 012 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.019s\n",
      "| AdaDelta | epoch: 013 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.019s\n",
      "| AdaDelta | epoch: 014 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.019s\n",
      "| AdaDelta | epoch: 015 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.020s\n",
      "| AdaDelta | epoch: 016 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.020s\n",
      "| AdaDelta | epoch: 017 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.021s\n",
      "| AdaDelta | epoch: 018 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.017s\n",
      "| AdaDelta | epoch: 019 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.018s\n",
      "| AdaDelta | epoch: 020 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.017s\n",
      "| AdaDelta | epoch: 021 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.017s\n",
      "| AdaDelta | epoch: 022 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.018s\n",
      "| AdaDelta | epoch: 023 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.018s\n",
      "| AdaDelta | epoch: 024 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.019s\n",
      "| AdaDelta | epoch: 025 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.017s\n",
      "| AdaDelta | epoch: 026 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.017s\n",
      "| AdaDelta | epoch: 027 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.017s\n",
      "| AdaDelta | epoch: 028 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.018s\n",
      "| AdaDelta | epoch: 029 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.017s\n",
      "| AdaDelta | epoch: 030 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'softmax', 1000, [0.3002028369758482]]\n",
      "AdaDelta\n",
      "softmax\n",
      "100\n",
      "---------------------------------\n",
      "Run id: V3I2UJ\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.100s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.008s\n",
      "| AdaDelta | epoch: 002 | loss: 0.00000 - binary_acc: 0.2865 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.008s\n",
      "| AdaDelta | epoch: 003 | loss: 0.00000 - binary_acc: 0.3125 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.011s\n",
      "| AdaDelta | epoch: 004 | loss: 0.00000 - binary_acc: 0.3169 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.009s\n",
      "| AdaDelta | epoch: 005 | loss: 0.00000 - binary_acc: 0.3179 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.010s\n",
      "| AdaDelta | epoch: 006 | loss: 0.00000 - binary_acc: 0.3182 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.010s\n",
      "| AdaDelta | epoch: 007 | loss: 0.00000 - binary_acc: 0.3183 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.009s\n",
      "| AdaDelta | epoch: 008 | loss: 0.00000 - binary_acc: 0.3183 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.011s\n",
      "| AdaDelta | epoch: 009 | loss: 0.00000 - binary_acc: 0.3183 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.009s\n",
      "| AdaDelta | epoch: 010 | loss: 0.00000 - binary_acc: 0.3183 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.009s\n",
      "| AdaDelta | epoch: 011 | loss: 0.00000 - binary_acc: 0.3183 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.011s\n",
      "| AdaDelta | epoch: 012 | loss: 0.00000 - binary_acc: 0.3183 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.008s\n",
      "| AdaDelta | epoch: 013 | loss: 0.00000 - binary_acc: 0.3183 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.009s\n",
      "| AdaDelta | epoch: 014 | loss: 0.00000 - binary_acc: 0.3183 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.008s\n",
      "| AdaDelta | epoch: 015 | loss: 0.00000 - binary_acc: 0.3183 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.010s\n",
      "| AdaDelta | epoch: 016 | loss: 0.00000 - binary_acc: 0.3183 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.009s\n",
      "| AdaDelta | epoch: 017 | loss: 0.00000 - binary_acc: 0.3183 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.009s\n",
      "| AdaDelta | epoch: 018 | loss: 0.00000 - binary_acc: 0.3183 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.008s\n",
      "| AdaDelta | epoch: 019 | loss: 0.00000 - binary_acc: 0.3183 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.010s\n",
      "| AdaDelta | epoch: 020 | loss: 0.00000 - binary_acc: 0.3183 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.009s\n",
      "| AdaDelta | epoch: 021 | loss: 0.00000 - binary_acc: 0.3183 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.010s\n",
      "| AdaDelta | epoch: 022 | loss: 0.00000 - binary_acc: 0.3183 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.008s\n",
      "| AdaDelta | epoch: 023 | loss: 0.00000 - binary_acc: 0.3183 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.009s\n",
      "| AdaDelta | epoch: 024 | loss: 0.00000 - binary_acc: 0.3183 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.008s\n",
      "| AdaDelta | epoch: 025 | loss: 0.00000 - binary_acc: 0.3183 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.009s\n",
      "| AdaDelta | epoch: 026 | loss: 0.00000 - binary_acc: 0.3183 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.010s\n",
      "| AdaDelta | epoch: 027 | loss: 0.00000 - binary_acc: 0.3183 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.009s\n",
      "| AdaDelta | epoch: 028 | loss: 0.00000 - binary_acc: 0.3183 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.010s\n",
      "| AdaDelta | epoch: 029 | loss: 0.00000 - binary_acc: 0.3183 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.009s\n",
      "| AdaDelta | epoch: 030 | loss: 0.00000 - binary_acc: 0.3183 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'softmax', 100, [0.3002028369758482]]\n",
      "AdaDelta\n",
      "softmax\n",
      "35\n",
      "---------------------------------\n",
      "Run id: HWYB2V\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.112s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.008s\n",
      "| AdaDelta | epoch: 002 | loss: 0.00000 - binary_acc: 0.2876 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.008s\n",
      "| AdaDelta | epoch: 003 | loss: 0.00000 - binary_acc: 0.3138 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.008s\n",
      "| AdaDelta | epoch: 004 | loss: 0.00000 - binary_acc: 0.3181 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.012s\n",
      "| AdaDelta | epoch: 005 | loss: 0.00000 - binary_acc: 0.3191 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.008s\n",
      "| AdaDelta | epoch: 006 | loss: 0.00000 - binary_acc: 0.3194 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.008s\n",
      "| AdaDelta | epoch: 007 | loss: 0.00000 - binary_acc: 0.3195 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.008s\n",
      "| AdaDelta | epoch: 008 | loss: 0.00000 - binary_acc: 0.3196 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.008s\n",
      "| AdaDelta | epoch: 009 | loss: 0.00000 - binary_acc: 0.3196 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.008s\n",
      "| AdaDelta | epoch: 010 | loss: 0.00000 - binary_acc: 0.3196 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.008s\n",
      "| AdaDelta | epoch: 011 | loss: 0.00000 - binary_acc: 0.3196 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.011s\n",
      "| AdaDelta | epoch: 012 | loss: 0.00000 - binary_acc: 0.3196 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.009s\n",
      "| AdaDelta | epoch: 013 | loss: 0.00000 - binary_acc: 0.3196 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.010s\n",
      "| AdaDelta | epoch: 014 | loss: 0.00000 - binary_acc: 0.3196 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.008s\n",
      "| AdaDelta | epoch: 015 | loss: 0.00000 - binary_acc: 0.3196 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.008s\n",
      "| AdaDelta | epoch: 016 | loss: 0.00000 - binary_acc: 0.3196 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.008s\n",
      "| AdaDelta | epoch: 017 | loss: 0.00000 - binary_acc: 0.3196 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.008s\n",
      "| AdaDelta | epoch: 018 | loss: 0.00000 - binary_acc: 0.3196 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.008s\n",
      "| AdaDelta | epoch: 019 | loss: 0.00000 - binary_acc: 0.3196 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.008s\n",
      "| AdaDelta | epoch: 020 | loss: 0.00000 - binary_acc: 0.3196 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.008s\n",
      "| AdaDelta | epoch: 021 | loss: 0.00000 - binary_acc: 0.3196 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.009s\n",
      "| AdaDelta | epoch: 022 | loss: 0.00000 - binary_acc: 0.3196 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.007s\n",
      "| AdaDelta | epoch: 023 | loss: 0.00000 - binary_acc: 0.3196 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.007s\n",
      "| AdaDelta | epoch: 024 | loss: 0.00000 - binary_acc: 0.3196 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.009s\n",
      "| AdaDelta | epoch: 025 | loss: 0.00000 - binary_acc: 0.3196 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.008s\n",
      "| AdaDelta | epoch: 026 | loss: 0.00000 - binary_acc: 0.3196 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.007s\n",
      "| AdaDelta | epoch: 027 | loss: 0.00000 - binary_acc: 0.3196 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.007s\n",
      "| AdaDelta | epoch: 028 | loss: 0.00000 - binary_acc: 0.3196 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.008s\n",
      "| AdaDelta | epoch: 029 | loss: 0.00000 - binary_acc: 0.3196 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.009s\n",
      "| AdaDelta | epoch: 030 | loss: 0.00000 - binary_acc: 0.3196 | val_loss: 0.00000 - val_binary_acc: 0.3392 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'softmax', 35, [0.3002028369758482]]\n",
      "AdaDelta\n",
      "sigmoid\n",
      "1000\n",
      "---------------------------------\n",
      "Run id: 0WGNIS\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.124s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.013s\n",
      "| AdaDelta | epoch: 002 | loss: 0.00000 - binary_acc: 0.2893 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.013s\n",
      "| AdaDelta | epoch: 003 | loss: 0.00000 - binary_acc: 0.3157 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.014s\n",
      "| AdaDelta | epoch: 004 | loss: 0.00000 - binary_acc: 0.3200 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.015s\n",
      "| AdaDelta | epoch: 005 | loss: 0.00000 - binary_acc: 0.3210 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.013s\n",
      "| AdaDelta | epoch: 006 | loss: 0.00000 - binary_acc: 0.3213 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.014s\n",
      "| AdaDelta | epoch: 007 | loss: 0.00000 - binary_acc: 0.3214 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.014s\n",
      "| AdaDelta | epoch: 008 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.014s\n",
      "| AdaDelta | epoch: 009 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.014s\n",
      "| AdaDelta | epoch: 010 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.017s\n",
      "| AdaDelta | epoch: 011 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.013s\n",
      "| AdaDelta | epoch: 012 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.014s\n",
      "| AdaDelta | epoch: 013 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.012s\n",
      "| AdaDelta | epoch: 014 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.013s\n",
      "| AdaDelta | epoch: 015 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.013s\n",
      "| AdaDelta | epoch: 016 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.013s\n",
      "| AdaDelta | epoch: 017 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.013s\n",
      "| AdaDelta | epoch: 018 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.014s\n",
      "| AdaDelta | epoch: 019 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.013s\n",
      "| AdaDelta | epoch: 020 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.015s\n",
      "| AdaDelta | epoch: 021 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.014s\n",
      "| AdaDelta | epoch: 022 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.014s\n",
      "| AdaDelta | epoch: 023 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.013s\n",
      "| AdaDelta | epoch: 024 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.016s\n",
      "| AdaDelta | epoch: 025 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.015s\n",
      "| AdaDelta | epoch: 026 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.014s\n",
      "| AdaDelta | epoch: 027 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.014s\n",
      "| AdaDelta | epoch: 028 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.012s\n",
      "| AdaDelta | epoch: 029 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.013s\n",
      "| AdaDelta | epoch: 030 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'sigmoid', 1000, [0.3002028369758482]]\n",
      "AdaDelta\n",
      "sigmoid\n",
      "100\n",
      "---------------------------------\n",
      "Run id: GI9RHG\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.145s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.008s\n",
      "| AdaDelta | epoch: 002 | loss: 0.00000 - binary_acc: 0.2933 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.008s\n",
      "| AdaDelta | epoch: 003 | loss: 0.00000 - binary_acc: 0.3200 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.007s\n",
      "| AdaDelta | epoch: 004 | loss: 0.00000 - binary_acc: 0.3245 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.008s\n",
      "| AdaDelta | epoch: 005 | loss: 0.00000 - binary_acc: 0.3255 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.007s\n",
      "| AdaDelta | epoch: 006 | loss: 0.00000 - binary_acc: 0.3258 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.008s\n",
      "| AdaDelta | epoch: 007 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.009s\n",
      "| AdaDelta | epoch: 008 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.008s\n",
      "| AdaDelta | epoch: 009 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.008s\n",
      "| AdaDelta | epoch: 010 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.009s\n",
      "| AdaDelta | epoch: 011 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.009s\n",
      "| AdaDelta | epoch: 012 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.008s\n",
      "| AdaDelta | epoch: 013 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.009s\n",
      "| AdaDelta | epoch: 014 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.009s\n",
      "| AdaDelta | epoch: 015 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.007s\n",
      "| AdaDelta | epoch: 016 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.008s\n",
      "| AdaDelta | epoch: 017 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.008s\n",
      "| AdaDelta | epoch: 018 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.008s\n",
      "| AdaDelta | epoch: 019 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.008s\n",
      "| AdaDelta | epoch: 020 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.008s\n",
      "| AdaDelta | epoch: 021 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.009s\n",
      "| AdaDelta | epoch: 022 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.008s\n",
      "| AdaDelta | epoch: 023 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.009s\n",
      "| AdaDelta | epoch: 024 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.008s\n",
      "| AdaDelta | epoch: 025 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.009s\n",
      "| AdaDelta | epoch: 026 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.007s\n",
      "| AdaDelta | epoch: 027 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.011s\n",
      "| AdaDelta | epoch: 028 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.008s\n",
      "| AdaDelta | epoch: 029 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.009s\n",
      "| AdaDelta | epoch: 030 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'sigmoid', 100, [0.3002028369758482]]\n",
      "AdaDelta\n",
      "sigmoid\n",
      "35\n",
      "---------------------------------\n",
      "Run id: 8ISNKG\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.118s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.007s\n",
      "| AdaDelta | epoch: 002 | loss: 0.00000 - binary_acc: 0.2836 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.008s\n",
      "| AdaDelta | epoch: 003 | loss: 0.00000 - binary_acc: 0.3094 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.009s\n",
      "| AdaDelta | epoch: 004 | loss: 0.00000 - binary_acc: 0.3137 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.008s\n",
      "| AdaDelta | epoch: 005 | loss: 0.00000 - binary_acc: 0.3147 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.008s\n",
      "| AdaDelta | epoch: 006 | loss: 0.00000 - binary_acc: 0.3150 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.008s\n",
      "| AdaDelta | epoch: 007 | loss: 0.00000 - binary_acc: 0.3151 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.008s\n",
      "| AdaDelta | epoch: 008 | loss: 0.00000 - binary_acc: 0.3151 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.007s\n",
      "| AdaDelta | epoch: 009 | loss: 0.00000 - binary_acc: 0.3151 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.008s\n",
      "| AdaDelta | epoch: 010 | loss: 0.00000 - binary_acc: 0.3151 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.008s\n",
      "| AdaDelta | epoch: 011 | loss: 0.00000 - binary_acc: 0.3152 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.008s\n",
      "| AdaDelta | epoch: 012 | loss: 0.00000 - binary_acc: 0.3152 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.008s\n",
      "| AdaDelta | epoch: 013 | loss: 0.00000 - binary_acc: 0.3152 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.007s\n",
      "| AdaDelta | epoch: 014 | loss: 0.00000 - binary_acc: 0.3152 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.008s\n",
      "| AdaDelta | epoch: 015 | loss: 0.00000 - binary_acc: 0.3152 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.009s\n",
      "| AdaDelta | epoch: 016 | loss: 0.00000 - binary_acc: 0.3152 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.008s\n",
      "| AdaDelta | epoch: 017 | loss: 0.00000 - binary_acc: 0.3152 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.008s\n",
      "| AdaDelta | epoch: 018 | loss: 0.00000 - binary_acc: 0.3152 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.008s\n",
      "| AdaDelta | epoch: 019 | loss: 0.00000 - binary_acc: 0.3152 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.007s\n",
      "| AdaDelta | epoch: 020 | loss: 0.00000 - binary_acc: 0.3152 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.007s\n",
      "| AdaDelta | epoch: 021 | loss: 0.00000 - binary_acc: 0.3152 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.008s\n",
      "| AdaDelta | epoch: 022 | loss: 0.00000 - binary_acc: 0.3152 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.008s\n",
      "| AdaDelta | epoch: 023 | loss: 0.00000 - binary_acc: 0.3152 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.007s\n",
      "| AdaDelta | epoch: 024 | loss: 0.00000 - binary_acc: 0.3152 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.008s\n",
      "| AdaDelta | epoch: 025 | loss: 0.00000 - binary_acc: 0.3152 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.008s\n",
      "| AdaDelta | epoch: 026 | loss: 0.00000 - binary_acc: 0.3152 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.007s\n",
      "| AdaDelta | epoch: 027 | loss: 0.00000 - binary_acc: 0.3152 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.007s\n",
      "| AdaDelta | epoch: 028 | loss: 0.00000 - binary_acc: 0.3152 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.008s\n",
      "| AdaDelta | epoch: 029 | loss: 0.00000 - binary_acc: 0.3152 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.008s\n",
      "| AdaDelta | epoch: 030 | loss: 0.00000 - binary_acc: 0.3152 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'sigmoid', 35, [0.3002028369758482]]\n",
      "AdaDelta\n",
      "tanh\n",
      "1000\n",
      "---------------------------------\n",
      "Run id: 0PZUMU\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.094s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.5038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.011s\n",
      "| AdaDelta | epoch: 002 | loss: 0.00000 - binary_acc: 0.3550 | val_loss: 0.00000 - val_binary_acc: 0.5038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.014s\n",
      "| AdaDelta | epoch: 003 | loss: 0.00000 - binary_acc: 0.4692 | val_loss: 0.00000 - val_binary_acc: 0.5038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.015s\n",
      "| AdaDelta | epoch: 004 | loss: 0.00000 - binary_acc: 0.4003 | val_loss: 0.00000 - val_binary_acc: 0.5038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.016s\n",
      "| AdaDelta | epoch: 005 | loss: 0.00000 - binary_acc: 0.4656 | val_loss: 0.00000 - val_binary_acc: 0.5038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.014s\n",
      "| AdaDelta | epoch: 006 | loss: 0.00000 - binary_acc: 0.4117 | val_loss: 0.00000 - val_binary_acc: 0.5038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.015s\n",
      "| AdaDelta | epoch: 007 | loss: 0.00000 - binary_acc: 0.4614 | val_loss: 0.00000 - val_binary_acc: 0.5038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.012s\n",
      "| AdaDelta | epoch: 008 | loss: 0.00000 - binary_acc: 0.4801 | val_loss: 0.00000 - val_binary_acc: 0.5038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.014s\n",
      "| AdaDelta | epoch: 009 | loss: 0.00000 - binary_acc: 0.4878 | val_loss: 0.00000 - val_binary_acc: 0.5038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.015s\n",
      "| AdaDelta | epoch: 010 | loss: 0.00000 - binary_acc: 0.4433 | val_loss: 0.00000 - val_binary_acc: 0.5038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.013s\n",
      "| AdaDelta | epoch: 011 | loss: 0.00000 - binary_acc: 0.4676 | val_loss: 0.00000 - val_binary_acc: 0.5038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.014s\n",
      "| AdaDelta | epoch: 012 | loss: 0.00000 - binary_acc: 0.4424 | val_loss: 0.00000 - val_binary_acc: 0.5038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.015s\n",
      "| AdaDelta | epoch: 013 | loss: 0.00000 - binary_acc: 0.4648 | val_loss: 0.00000 - val_binary_acc: 0.5038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.012s\n",
      "| AdaDelta | epoch: 014 | loss: 0.00000 - binary_acc: 0.4474 | val_loss: 0.00000 - val_binary_acc: 0.5038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.014s\n",
      "| AdaDelta | epoch: 015 | loss: 0.00000 - binary_acc: 0.4659 | val_loss: 0.00000 - val_binary_acc: 0.5038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.015s\n",
      "| AdaDelta | epoch: 016 | loss: 0.00000 - binary_acc: 0.4614 | val_loss: 0.00000 - val_binary_acc: 0.5038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.013s\n",
      "| AdaDelta | epoch: 017 | loss: 0.00000 - binary_acc: 0.4734 | val_loss: 0.00000 - val_binary_acc: 0.5038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.018s\n",
      "| AdaDelta | epoch: 018 | loss: 0.00000 - binary_acc: 0.4504 | val_loss: 0.00000 - val_binary_acc: 0.5038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.017s\n",
      "| AdaDelta | epoch: 019 | loss: 0.00000 - binary_acc: 0.4652 | val_loss: 0.00000 - val_binary_acc: 0.5038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.017s\n",
      "| AdaDelta | epoch: 020 | loss: 0.00000 - binary_acc: 0.4536 | val_loss: 0.00000 - val_binary_acc: 0.5038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.014s\n",
      "| AdaDelta | epoch: 021 | loss: 0.00000 - binary_acc: 0.4663 | val_loss: 0.00000 - val_binary_acc: 0.5038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.016s\n",
      "| AdaDelta | epoch: 022 | loss: 0.00000 - binary_acc: 0.4549 | val_loss: 0.00000 - val_binary_acc: 0.5038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.015s\n",
      "| AdaDelta | epoch: 023 | loss: 0.00000 - binary_acc: 0.4664 | val_loss: 0.00000 - val_binary_acc: 0.5038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.014s\n",
      "| AdaDelta | epoch: 024 | loss: 0.00000 - binary_acc: 0.4552 | val_loss: 0.00000 - val_binary_acc: 0.5038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.019s\n",
      "| AdaDelta | epoch: 025 | loss: 0.00000 - binary_acc: 0.4660 | val_loss: 0.00000 - val_binary_acc: 0.5038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.016s\n",
      "| AdaDelta | epoch: 026 | loss: 0.00000 - binary_acc: 0.4531 | val_loss: 0.00000 - val_binary_acc: 0.5038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.013s\n",
      "| AdaDelta | epoch: 027 | loss: 0.00000 - binary_acc: 0.4638 | val_loss: 0.00000 - val_binary_acc: 0.5038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.015s\n",
      "| AdaDelta | epoch: 028 | loss: 0.00000 - binary_acc: 0.4536 | val_loss: 0.00000 - val_binary_acc: 0.5038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.015s\n",
      "| AdaDelta | epoch: 029 | loss: 0.00000 - binary_acc: 0.4635 | val_loss: 0.00000 - val_binary_acc: 0.5038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.014s\n",
      "| AdaDelta | epoch: 030 | loss: 0.00000 - binary_acc: 0.4505 | val_loss: 0.00000 - val_binary_acc: 0.5038 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'tanh', 1000, [0.4807302255417706]]\n",
      "AdaDelta\n",
      "tanh\n",
      "100\n",
      "---------------------------------\n",
      "Run id: PAR80M\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.118s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.006s\n",
      "| AdaDelta | epoch: 002 | loss: 0.00000 - binary_acc: 0.3578 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.010s\n",
      "| AdaDelta | epoch: 003 | loss: 0.00000 - binary_acc: 0.4749 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.009s\n",
      "| AdaDelta | epoch: 004 | loss: 0.00000 - binary_acc: 0.4117 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.008s\n",
      "| AdaDelta | epoch: 005 | loss: 0.00000 - binary_acc: 0.4735 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.008s\n",
      "| AdaDelta | epoch: 006 | loss: 0.00000 - binary_acc: 0.4182 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.008s\n",
      "| AdaDelta | epoch: 007 | loss: 0.00000 - binary_acc: 0.4678 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.007s\n",
      "| AdaDelta | epoch: 008 | loss: 0.00000 - binary_acc: 0.4305 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.009s\n",
      "| AdaDelta | epoch: 009 | loss: 0.00000 - binary_acc: 0.4678 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.008s\n",
      "| AdaDelta | epoch: 010 | loss: 0.00000 - binary_acc: 0.4384 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.008s\n",
      "| AdaDelta | epoch: 011 | loss: 0.00000 - binary_acc: 0.4680 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.009s\n",
      "| AdaDelta | epoch: 012 | loss: 0.00000 - binary_acc: 0.4358 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.008s\n",
      "| AdaDelta | epoch: 013 | loss: 0.00000 - binary_acc: 0.4637 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.008s\n",
      "| AdaDelta | epoch: 014 | loss: 0.00000 - binary_acc: 0.4359 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.008s\n",
      "| AdaDelta | epoch: 015 | loss: 0.00000 - binary_acc: 0.4613 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.009s\n",
      "| AdaDelta | epoch: 016 | loss: 0.00000 - binary_acc: 0.4393 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.008s\n",
      "| AdaDelta | epoch: 017 | loss: 0.00000 - binary_acc: 0.4615 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.008s\n",
      "| AdaDelta | epoch: 018 | loss: 0.00000 - binary_acc: 0.4563 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.008s\n",
      "| AdaDelta | epoch: 019 | loss: 0.00000 - binary_acc: 0.4712 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.009s\n",
      "| AdaDelta | epoch: 020 | loss: 0.00000 - binary_acc: 0.4614 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.008s\n",
      "| AdaDelta | epoch: 021 | loss: 0.00000 - binary_acc: 0.4737 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.006s\n",
      "| AdaDelta | epoch: 022 | loss: 0.00000 - binary_acc: 0.4615 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.008s\n",
      "| AdaDelta | epoch: 023 | loss: 0.00000 - binary_acc: 0.4729 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.008s\n",
      "| AdaDelta | epoch: 024 | loss: 0.00000 - binary_acc: 0.4623 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.009s\n",
      "| AdaDelta | epoch: 025 | loss: 0.00000 - binary_acc: 0.4728 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.008s\n",
      "| AdaDelta | epoch: 026 | loss: 0.00000 - binary_acc: 0.4606 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.011s\n",
      "| AdaDelta | epoch: 027 | loss: 0.00000 - binary_acc: 0.4710 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.008s\n",
      "| AdaDelta | epoch: 028 | loss: 0.00000 - binary_acc: 0.4610 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.008s\n",
      "| AdaDelta | epoch: 029 | loss: 0.00000 - binary_acc: 0.4708 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.009s\n",
      "| AdaDelta | epoch: 030 | loss: 0.00000 - binary_acc: 0.4621 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'tanh', 100, [0.5010142015032546]]\n",
      "AdaDelta\n",
      "tanh\n",
      "35\n",
      "---------------------------------\n",
      "Run id: WJG5SQ\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.117s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.006s\n",
      "| AdaDelta | epoch: 002 | loss: 0.00000 - binary_acc: 0.3533 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.007s\n",
      "| AdaDelta | epoch: 003 | loss: 0.00000 - binary_acc: 0.2842 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.008s\n",
      "| AdaDelta | epoch: 004 | loss: 0.00000 - binary_acc: 0.2727 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.007s\n",
      "| AdaDelta | epoch: 005 | loss: 0.00000 - binary_acc: 0.2700 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.008s\n",
      "| AdaDelta | epoch: 006 | loss: 0.00000 - binary_acc: 0.3439 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.008s\n",
      "| AdaDelta | epoch: 007 | loss: 0.00000 - binary_acc: 0.2989 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.008s\n",
      "| AdaDelta | epoch: 008 | loss: 0.00000 - binary_acc: 0.3555 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.007s\n",
      "| AdaDelta | epoch: 009 | loss: 0.00000 - binary_acc: 0.3096 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.008s\n",
      "| AdaDelta | epoch: 010 | loss: 0.00000 - binary_acc: 0.3298 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.007s\n",
      "| AdaDelta | epoch: 011 | loss: 0.00000 - binary_acc: 0.3009 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.007s\n",
      "| AdaDelta | epoch: 012 | loss: 0.00000 - binary_acc: 0.3208 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.007s\n",
      "| AdaDelta | epoch: 013 | loss: 0.00000 - binary_acc: 0.2985 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.008s\n",
      "| AdaDelta | epoch: 014 | loss: 0.00000 - binary_acc: 0.2864 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.008s\n",
      "| AdaDelta | epoch: 015 | loss: 0.00000 - binary_acc: 0.2795 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.007s\n",
      "| AdaDelta | epoch: 016 | loss: 0.00000 - binary_acc: 0.2995 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.007s\n",
      "| AdaDelta | epoch: 017 | loss: 0.00000 - binary_acc: 0.2885 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.007s\n",
      "| AdaDelta | epoch: 018 | loss: 0.00000 - binary_acc: 0.3127 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.007s\n",
      "| AdaDelta | epoch: 019 | loss: 0.00000 - binary_acc: 0.2981 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.008s\n",
      "| AdaDelta | epoch: 020 | loss: 0.00000 - binary_acc: 0.3135 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.008s\n",
      "| AdaDelta | epoch: 021 | loss: 0.00000 - binary_acc: 0.2997 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.008s\n",
      "| AdaDelta | epoch: 022 | loss: 0.00000 - binary_acc: 0.3106 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.007s\n",
      "| AdaDelta | epoch: 023 | loss: 0.00000 - binary_acc: 0.2985 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.008s\n",
      "| AdaDelta | epoch: 024 | loss: 0.00000 - binary_acc: 0.3083 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.007s\n",
      "| AdaDelta | epoch: 025 | loss: 0.00000 - binary_acc: 0.2976 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.007s\n",
      "| AdaDelta | epoch: 026 | loss: 0.00000 - binary_acc: 0.3093 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.008s\n",
      "| AdaDelta | epoch: 027 | loss: 0.00000 - binary_acc: 0.2989 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.008s\n",
      "| AdaDelta | epoch: 028 | loss: 0.00000 - binary_acc: 0.3093 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.007s\n",
      "| AdaDelta | epoch: 029 | loss: 0.00000 - binary_acc: 0.2995 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.007s\n",
      "| AdaDelta | epoch: 030 | loss: 0.00000 - binary_acc: 0.3090 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'tanh', 35, [0.27180527449863195]]\n",
      "AdaDelta\n",
      "prelu\n",
      "1000\n",
      "---------------------------------\n",
      "Run id: 4U2IC9\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.163s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.025s\n",
      "| AdaDelta | epoch: 002 | loss: nan - binary_acc: 0.3915 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.028s\n",
      "| AdaDelta | epoch: 003 | loss: nan - binary_acc: 0.4333 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.025s\n",
      "| AdaDelta | epoch: 004 | loss: nan - binary_acc: 0.4403 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.026s\n",
      "| AdaDelta | epoch: 005 | loss: nan - binary_acc: 0.4419 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.031s\n",
      "| AdaDelta | epoch: 006 | loss: nan - binary_acc: 0.4424 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.025s\n",
      "| AdaDelta | epoch: 007 | loss: nan - binary_acc: 0.4425 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.026s\n",
      "| AdaDelta | epoch: 008 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.031s\n",
      "| AdaDelta | epoch: 009 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.026s\n",
      "| AdaDelta | epoch: 010 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.031s\n",
      "| AdaDelta | epoch: 011 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.025s\n",
      "| AdaDelta | epoch: 012 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.033s\n",
      "| AdaDelta | epoch: 013 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.026s\n",
      "| AdaDelta | epoch: 014 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.027s\n",
      "| AdaDelta | epoch: 015 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.029s\n",
      "| AdaDelta | epoch: 016 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.026s\n",
      "| AdaDelta | epoch: 017 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.025s\n",
      "| AdaDelta | epoch: 018 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.029s\n",
      "| AdaDelta | epoch: 019 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.027s\n",
      "| AdaDelta | epoch: 020 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.030s\n",
      "| AdaDelta | epoch: 021 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.026s\n",
      "| AdaDelta | epoch: 022 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.029s\n",
      "| AdaDelta | epoch: 023 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.028s\n",
      "| AdaDelta | epoch: 024 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.028s\n",
      "| AdaDelta | epoch: 025 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.035s\n",
      "| AdaDelta | epoch: 026 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.029s\n",
      "| AdaDelta | epoch: 027 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.030s\n",
      "| AdaDelta | epoch: 028 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.031s\n",
      "| AdaDelta | epoch: 029 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.028s\n",
      "| AdaDelta | epoch: 030 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'prelu', 1000, [0.45436105404132276]]\n",
      "AdaDelta\n",
      "prelu\n",
      "100\n",
      "---------------------------------\n",
      "Run id: TM9OMT\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.133s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.3848 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 002 | loss: nan - binary_acc: 0.3641 | val_loss: nan - val_binary_acc: 0.3848 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 003 | loss: nan - binary_acc: 0.4382 | val_loss: nan - val_binary_acc: 0.3848 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 004 | loss: nan - binary_acc: 0.4505 | val_loss: nan - val_binary_acc: 0.3848 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 005 | loss: nan - binary_acc: 0.4534 | val_loss: nan - val_binary_acc: 0.3848 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.014s\n",
      "| AdaDelta | epoch: 006 | loss: nan - binary_acc: 0.4542 | val_loss: nan - val_binary_acc: 0.3848 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 007 | loss: nan - binary_acc: 0.4545 | val_loss: nan - val_binary_acc: 0.3848 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| AdaDelta | epoch: 008 | loss: nan - binary_acc: 0.4546 | val_loss: nan - val_binary_acc: 0.3848 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 009 | loss: nan - binary_acc: 0.4546 | val_loss: nan - val_binary_acc: 0.3848 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 010 | loss: nan - binary_acc: 0.4546 | val_loss: nan - val_binary_acc: 0.3848 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 011 | loss: nan - binary_acc: 0.4547 | val_loss: nan - val_binary_acc: 0.3848 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 012 | loss: nan - binary_acc: 0.4547 | val_loss: nan - val_binary_acc: 0.3848 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 013 | loss: nan - binary_acc: 0.4547 | val_loss: nan - val_binary_acc: 0.3848 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 014 | loss: nan - binary_acc: 0.4547 | val_loss: nan - val_binary_acc: 0.3848 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 015 | loss: nan - binary_acc: 0.4547 | val_loss: nan - val_binary_acc: 0.3848 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 016 | loss: nan - binary_acc: 0.4547 | val_loss: nan - val_binary_acc: 0.3848 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 017 | loss: nan - binary_acc: 0.4547 | val_loss: nan - val_binary_acc: 0.3848 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 018 | loss: nan - binary_acc: 0.4547 | val_loss: nan - val_binary_acc: 0.3848 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 019 | loss: nan - binary_acc: 0.4547 | val_loss: nan - val_binary_acc: 0.3848 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 020 | loss: nan - binary_acc: 0.4547 | val_loss: nan - val_binary_acc: 0.3848 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 021 | loss: nan - binary_acc: 0.4547 | val_loss: nan - val_binary_acc: 0.3848 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 022 | loss: nan - binary_acc: 0.4547 | val_loss: nan - val_binary_acc: 0.3848 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| AdaDelta | epoch: 023 | loss: nan - binary_acc: 0.4547 | val_loss: nan - val_binary_acc: 0.3848 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaDelta | epoch: 024 | loss: nan - binary_acc: 0.4547 | val_loss: nan - val_binary_acc: 0.3848 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 025 | loss: nan - binary_acc: 0.4547 | val_loss: nan - val_binary_acc: 0.3848 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 026 | loss: nan - binary_acc: 0.4547 | val_loss: nan - val_binary_acc: 0.3848 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 027 | loss: nan - binary_acc: 0.4547 | val_loss: nan - val_binary_acc: 0.3848 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 028 | loss: nan - binary_acc: 0.4547 | val_loss: nan - val_binary_acc: 0.3848 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 029 | loss: nan - binary_acc: 0.4547 | val_loss: nan - val_binary_acc: 0.3848 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 030 | loss: nan - binary_acc: 0.4547 | val_loss: nan - val_binary_acc: 0.3848 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'prelu', 100, [0.45436105404132276]]\n",
      "AdaDelta\n",
      "prelu\n",
      "35\n",
      "---------------------------------\n",
      "Run id: 4021PR\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.118s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaDelta | epoch: 002 | loss: nan - binary_acc: 0.3384 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 003 | loss: nan - binary_acc: 0.4195 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 004 | loss: nan - binary_acc: 0.4330 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 005 | loss: nan - binary_acc: 0.4362 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 006 | loss: nan - binary_acc: 0.4370 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 007 | loss: nan - binary_acc: 0.4373 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 008 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 009 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 010 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 011 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 012 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 013 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 014 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 015 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 016 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaDelta | epoch: 017 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 018 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 019 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaDelta | epoch: 020 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 021 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 022 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 023 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 024 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 025 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 026 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 027 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 028 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 029 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 030 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'prelu', 35, [0.45436105404132276]]\n",
      "RMSProp\n",
      "relu\n",
      "1000\n",
      "---------------------------------\n",
      "Run id: 8BCRW3\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.255s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.012s\n",
      "| RMSProp | epoch: 002 | loss: 0.00000 - binary_acc: 0.2939 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.013s\n",
      "| RMSProp | epoch: 003 | loss: 0.00000 - binary_acc: 0.3206 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.013s\n",
      "| RMSProp | epoch: 004 | loss: 0.00000 - binary_acc: 0.3251 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.015s\n",
      "| RMSProp | epoch: 005 | loss: 0.00000 - binary_acc: 0.3261 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.014s\n",
      "| RMSProp | epoch: 006 | loss: 0.00000 - binary_acc: 0.3264 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.013s\n",
      "| RMSProp | epoch: 007 | loss: 0.00000 - binary_acc: 0.3265 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.012s\n",
      "| RMSProp | epoch: 008 | loss: 0.00000 - binary_acc: 0.3265 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.015s\n",
      "| RMSProp | epoch: 009 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.013s\n",
      "| RMSProp | epoch: 010 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.013s\n",
      "| RMSProp | epoch: 011 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.014s\n",
      "| RMSProp | epoch: 012 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.016s\n",
      "| RMSProp | epoch: 013 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.013s\n",
      "| RMSProp | epoch: 014 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.013s\n",
      "| RMSProp | epoch: 015 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.013s\n",
      "| RMSProp | epoch: 016 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.012s\n",
      "| RMSProp | epoch: 017 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.015s\n",
      "| RMSProp | epoch: 018 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.013s\n",
      "| RMSProp | epoch: 019 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.013s\n",
      "| RMSProp | epoch: 020 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.015s\n",
      "| RMSProp | epoch: 021 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.012s\n",
      "| RMSProp | epoch: 022 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.014s\n",
      "| RMSProp | epoch: 023 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.012s\n",
      "| RMSProp | epoch: 024 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.013s\n",
      "| RMSProp | epoch: 025 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.013s\n",
      "| RMSProp | epoch: 026 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.012s\n",
      "| RMSProp | epoch: 027 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.015s\n",
      "| RMSProp | epoch: 028 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.013s\n",
      "| RMSProp | epoch: 029 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.013s\n",
      "| RMSProp | epoch: 030 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'relu', 1000, [0.3002028369758482]]\n",
      "RMSProp\n",
      "relu\n",
      "100\n",
      "---------------------------------\n",
      "Run id: R3JPDZ\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.091s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.006s\n",
      "| RMSProp | epoch: 002 | loss: nan - binary_acc: 0.2916 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| RMSProp | epoch: 003 | loss: nan - binary_acc: 0.4146 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 004 | loss: nan - binary_acc: 0.4351 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 005 | loss: nan - binary_acc: 0.4399 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 006 | loss: nan - binary_acc: 0.4412 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 007 | loss: nan - binary_acc: 0.4417 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 008 | loss: nan - binary_acc: 0.4418 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 009 | loss: nan - binary_acc: 0.4419 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 010 | loss: nan - binary_acc: 0.4419 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 011 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 012 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 013 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 014 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 015 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 016 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 017 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 018 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 019 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 020 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 021 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| RMSProp | epoch: 022 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 023 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 024 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 025 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 026 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 027 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 028 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| RMSProp | epoch: 029 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 030 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'relu', 100, [0.45436105404132276]]\n",
      "RMSProp\n",
      "relu\n",
      "35\n",
      "---------------------------------\n",
      "Run id: TM80PP\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.098s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.006s\n",
      "| RMSProp | epoch: 002 | loss: nan - binary_acc: 0.3236 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| RMSProp | epoch: 003 | loss: nan - binary_acc: 0.4179 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 004 | loss: nan - binary_acc: 0.4336 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 005 | loss: nan - binary_acc: 0.4372 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 006 | loss: nan - binary_acc: 0.4382 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 007 | loss: nan - binary_acc: 0.4386 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 008 | loss: nan - binary_acc: 0.4387 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| RMSProp | epoch: 009 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 010 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| RMSProp | epoch: 011 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 012 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 013 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 014 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| RMSProp | epoch: 015 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 016 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 017 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 018 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 019 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 020 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 021 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 022 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 023 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 024 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.006s\n",
      "| RMSProp | epoch: 025 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 026 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 027 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| RMSProp | epoch: 028 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 029 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| RMSProp | epoch: 030 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'relu', 35, [0.45436105404132276]]\n",
      "RMSProp\n",
      "linear\n",
      "1000\n",
      "---------------------------------\n",
      "Run id: EIGO66\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.098s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.010s\n",
      "| RMSProp | epoch: 002 | loss: 0.00000 - binary_acc: 0.3350 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.011s\n",
      "| RMSProp | epoch: 003 | loss: 0.00000 - binary_acc: 0.2778 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.012s\n",
      "| RMSProp | epoch: 004 | loss: 0.00000 - binary_acc: 0.3401 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.013s\n",
      "| RMSProp | epoch: 005 | loss: 0.00000 - binary_acc: 0.2881 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.011s\n",
      "| RMSProp | epoch: 006 | loss: 0.00000 - binary_acc: 0.3389 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.012s\n",
      "| RMSProp | epoch: 007 | loss: 0.00000 - binary_acc: 0.2946 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.011s\n",
      "| RMSProp | epoch: 008 | loss: 0.00000 - binary_acc: 0.2780 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.011s\n",
      "| RMSProp | epoch: 009 | loss: 0.00000 - binary_acc: 0.3299 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.012s\n",
      "| RMSProp | epoch: 010 | loss: 0.00000 - binary_acc: 0.3406 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.012s\n",
      "| RMSProp | epoch: 011 | loss: 0.00000 - binary_acc: 0.3048 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.013s\n",
      "| RMSProp | epoch: 012 | loss: 0.00000 - binary_acc: 0.3312 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.012s\n",
      "| RMSProp | epoch: 013 | loss: 0.00000 - binary_acc: 0.3028 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.011s\n",
      "| RMSProp | epoch: 014 | loss: 0.00000 - binary_acc: 0.3380 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.012s\n",
      "| RMSProp | epoch: 015 | loss: 0.00000 - binary_acc: 0.3094 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.012s\n",
      "| RMSProp | epoch: 016 | loss: 0.00000 - binary_acc: 0.3237 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.011s\n",
      "| RMSProp | epoch: 017 | loss: 0.00000 - binary_acc: 0.3026 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.011s\n",
      "| RMSProp | epoch: 018 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.012s\n",
      "| RMSProp | epoch: 019 | loss: 0.00000 - binary_acc: 0.3040 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.012s\n",
      "| RMSProp | epoch: 020 | loss: 0.00000 - binary_acc: 0.2915 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.012s\n",
      "| RMSProp | epoch: 021 | loss: 0.00000 - binary_acc: 0.2833 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.012s\n",
      "| RMSProp | epoch: 022 | loss: 0.00000 - binary_acc: 0.3039 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.011s\n",
      "| RMSProp | epoch: 023 | loss: 0.00000 - binary_acc: 0.2926 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.012s\n",
      "| RMSProp | epoch: 024 | loss: 0.00000 - binary_acc: 0.3130 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.011s\n",
      "| RMSProp | epoch: 025 | loss: 0.00000 - binary_acc: 0.2999 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.013s\n",
      "| RMSProp | epoch: 026 | loss: 0.00000 - binary_acc: 0.3179 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.012s\n",
      "| RMSProp | epoch: 027 | loss: 0.00000 - binary_acc: 0.3043 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.011s\n",
      "| RMSProp | epoch: 028 | loss: 0.00000 - binary_acc: 0.3180 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.011s\n",
      "| RMSProp | epoch: 029 | loss: 0.00000 - binary_acc: 0.3051 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.011s\n",
      "| RMSProp | epoch: 030 | loss: 0.00000 - binary_acc: 0.3192 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'linear', 1000, [0.26369168308637203]]\n",
      "RMSProp\n",
      "linear\n",
      "100\n",
      "---------------------------------\n",
      "Run id: NA7ICS\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.096s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3873 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.008s\n",
      "| RMSProp | epoch: 002 | loss: 0.00000 - binary_acc: 0.3601 | val_loss: 0.00000 - val_binary_acc: 0.3873 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.008s\n",
      "| RMSProp | epoch: 003 | loss: 0.00000 - binary_acc: 0.4095 | val_loss: 0.00000 - val_binary_acc: 0.3873 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.009s\n",
      "| RMSProp | epoch: 004 | loss: 0.00000 - binary_acc: 0.4086 | val_loss: 0.00000 - val_binary_acc: 0.3873 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.008s\n",
      "| RMSProp | epoch: 005 | loss: 0.00000 - binary_acc: 0.4168 | val_loss: 0.00000 - val_binary_acc: 0.3873 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.008s\n",
      "| RMSProp | epoch: 006 | loss: 0.00000 - binary_acc: 0.4110 | val_loss: 0.00000 - val_binary_acc: 0.3873 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.009s\n",
      "| RMSProp | epoch: 007 | loss: 0.00000 - binary_acc: 0.4166 | val_loss: 0.00000 - val_binary_acc: 0.3873 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.008s\n",
      "| RMSProp | epoch: 008 | loss: 0.00000 - binary_acc: 0.4020 | val_loss: 0.00000 - val_binary_acc: 0.3873 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.008s\n",
      "| RMSProp | epoch: 009 | loss: 0.00000 - binary_acc: 0.4118 | val_loss: 0.00000 - val_binary_acc: 0.3873 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.008s\n",
      "| RMSProp | epoch: 010 | loss: 0.00000 - binary_acc: 0.3980 | val_loss: 0.00000 - val_binary_acc: 0.3873 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.008s\n",
      "| RMSProp | epoch: 011 | loss: 0.00000 - binary_acc: 0.4086 | val_loss: 0.00000 - val_binary_acc: 0.3873 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.008s\n",
      "| RMSProp | epoch: 012 | loss: 0.00000 - binary_acc: 0.4048 | val_loss: 0.00000 - val_binary_acc: 0.3873 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.010s\n",
      "| RMSProp | epoch: 013 | loss: 0.00000 - binary_acc: 0.4115 | val_loss: 0.00000 - val_binary_acc: 0.3873 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.008s\n",
      "| RMSProp | epoch: 014 | loss: 0.00000 - binary_acc: 0.4004 | val_loss: 0.00000 - val_binary_acc: 0.3873 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.008s\n",
      "| RMSProp | epoch: 015 | loss: 0.00000 - binary_acc: 0.4082 | val_loss: 0.00000 - val_binary_acc: 0.3873 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.009s\n",
      "| RMSProp | epoch: 016 | loss: 0.00000 - binary_acc: 0.3980 | val_loss: 0.00000 - val_binary_acc: 0.3873 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.009s\n",
      "| RMSProp | epoch: 017 | loss: 0.00000 - binary_acc: 0.4061 | val_loss: 0.00000 - val_binary_acc: 0.3873 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.009s\n",
      "| RMSProp | epoch: 018 | loss: 0.00000 - binary_acc: 0.4060 | val_loss: 0.00000 - val_binary_acc: 0.3873 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.009s\n",
      "| RMSProp | epoch: 019 | loss: 0.00000 - binary_acc: 0.4108 | val_loss: 0.00000 - val_binary_acc: 0.3873 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.007s\n",
      "| RMSProp | epoch: 020 | loss: 0.00000 - binary_acc: 0.4062 | val_loss: 0.00000 - val_binary_acc: 0.3873 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.008s\n",
      "| RMSProp | epoch: 021 | loss: 0.00000 - binary_acc: 0.4106 | val_loss: 0.00000 - val_binary_acc: 0.3873 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.008s\n",
      "| RMSProp | epoch: 022 | loss: 0.00000 - binary_acc: 0.4036 | val_loss: 0.00000 - val_binary_acc: 0.3873 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.007s\n",
      "| RMSProp | epoch: 023 | loss: 0.00000 - binary_acc: 0.4085 | val_loss: 0.00000 - val_binary_acc: 0.3873 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.008s\n",
      "| RMSProp | epoch: 024 | loss: 0.00000 - binary_acc: 0.4062 | val_loss: 0.00000 - val_binary_acc: 0.3873 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.009s\n",
      "| RMSProp | epoch: 025 | loss: 0.00000 - binary_acc: 0.4100 | val_loss: 0.00000 - val_binary_acc: 0.3873 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.009s\n",
      "| RMSProp | epoch: 026 | loss: 0.00000 - binary_acc: 0.4034 | val_loss: 0.00000 - val_binary_acc: 0.3873 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.008s\n",
      "| RMSProp | epoch: 027 | loss: 0.00000 - binary_acc: 0.4078 | val_loss: 0.00000 - val_binary_acc: 0.3873 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.009s\n",
      "| RMSProp | epoch: 028 | loss: 0.00000 - binary_acc: 0.4005 | val_loss: 0.00000 - val_binary_acc: 0.3873 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.007s\n",
      "| RMSProp | epoch: 029 | loss: 0.00000 - binary_acc: 0.4053 | val_loss: 0.00000 - val_binary_acc: 0.3873 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.009s\n",
      "| RMSProp | epoch: 030 | loss: 0.00000 - binary_acc: 0.4050 | val_loss: 0.00000 - val_binary_acc: 0.3873 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'linear', 100, [0.43002028524512936]]\n",
      "RMSProp\n",
      "linear\n",
      "35\n",
      "---------------------------------\n",
      "Run id: VPC8MH\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.114s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3722 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.006s\n",
      "| RMSProp | epoch: 002 | loss: 0.00000 - binary_acc: 0.3504 | val_loss: 0.00000 - val_binary_acc: 0.3722 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.008s\n",
      "| RMSProp | epoch: 003 | loss: 0.00000 - binary_acc: 0.3413 | val_loss: 0.00000 - val_binary_acc: 0.3722 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.008s\n",
      "| RMSProp | epoch: 004 | loss: 0.00000 - binary_acc: 0.3531 | val_loss: 0.00000 - val_binary_acc: 0.3722 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.007s\n",
      "| RMSProp | epoch: 005 | loss: 0.00000 - binary_acc: 0.3435 | val_loss: 0.00000 - val_binary_acc: 0.3722 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.008s\n",
      "| RMSProp | epoch: 006 | loss: 0.00000 - binary_acc: 0.3762 | val_loss: 0.00000 - val_binary_acc: 0.3722 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.010s\n",
      "| RMSProp | epoch: 007 | loss: 0.00000 - binary_acc: 0.3540 | val_loss: 0.00000 - val_binary_acc: 0.3722 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.009s\n",
      "| RMSProp | epoch: 008 | loss: 0.00000 - binary_acc: 0.3593 | val_loss: 0.00000 - val_binary_acc: 0.3722 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.007s\n",
      "| RMSProp | epoch: 009 | loss: 0.00000 - binary_acc: 0.3487 | val_loss: 0.00000 - val_binary_acc: 0.3722 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.007s\n",
      "| RMSProp | epoch: 010 | loss: 0.00000 - binary_acc: 0.3598 | val_loss: 0.00000 - val_binary_acc: 0.3722 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.007s\n",
      "| RMSProp | epoch: 011 | loss: 0.00000 - binary_acc: 0.3501 | val_loss: 0.00000 - val_binary_acc: 0.3722 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.007s\n",
      "| RMSProp | epoch: 012 | loss: 0.00000 - binary_acc: 0.3692 | val_loss: 0.00000 - val_binary_acc: 0.3722 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.007s\n",
      "| RMSProp | epoch: 013 | loss: 0.00000 - binary_acc: 0.3564 | val_loss: 0.00000 - val_binary_acc: 0.3722 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.007s\n",
      "| RMSProp | epoch: 014 | loss: 0.00000 - binary_acc: 0.3494 | val_loss: 0.00000 - val_binary_acc: 0.3722 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.007s\n",
      "| RMSProp | epoch: 015 | loss: 0.00000 - binary_acc: 0.3454 | val_loss: 0.00000 - val_binary_acc: 0.3722 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.008s\n",
      "| RMSProp | epoch: 016 | loss: 0.00000 - binary_acc: 0.3431 | val_loss: 0.00000 - val_binary_acc: 0.3722 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.007s\n",
      "| RMSProp | epoch: 017 | loss: 0.00000 - binary_acc: 0.3511 | val_loss: 0.00000 - val_binary_acc: 0.3722 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.008s\n",
      "| RMSProp | epoch: 018 | loss: 0.00000 - binary_acc: 0.3470 | val_loss: 0.00000 - val_binary_acc: 0.3722 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.007s\n",
      "| RMSProp | epoch: 019 | loss: 0.00000 - binary_acc: 0.3444 | val_loss: 0.00000 - val_binary_acc: 0.3722 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.007s\n",
      "| RMSProp | epoch: 020 | loss: 0.00000 - binary_acc: 0.3523 | val_loss: 0.00000 - val_binary_acc: 0.3722 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.007s\n",
      "| RMSProp | epoch: 021 | loss: 0.00000 - binary_acc: 0.3483 | val_loss: 0.00000 - val_binary_acc: 0.3722 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.009s\n",
      "| RMSProp | epoch: 022 | loss: 0.00000 - binary_acc: 0.3547 | val_loss: 0.00000 - val_binary_acc: 0.3722 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.008s\n",
      "| RMSProp | epoch: 023 | loss: 0.00000 - binary_acc: 0.3502 | val_loss: 0.00000 - val_binary_acc: 0.3722 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.007s\n",
      "| RMSProp | epoch: 024 | loss: 0.00000 - binary_acc: 0.3544 | val_loss: 0.00000 - val_binary_acc: 0.3722 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.007s\n",
      "| RMSProp | epoch: 025 | loss: 0.00000 - binary_acc: 0.3503 | val_loss: 0.00000 - val_binary_acc: 0.3722 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.006s\n",
      "| RMSProp | epoch: 026 | loss: 0.00000 - binary_acc: 0.3568 | val_loss: 0.00000 - val_binary_acc: 0.3722 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.008s\n",
      "| RMSProp | epoch: 027 | loss: 0.00000 - binary_acc: 0.3523 | val_loss: 0.00000 - val_binary_acc: 0.3722 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.007s\n",
      "| RMSProp | epoch: 028 | loss: 0.00000 - binary_acc: 0.3561 | val_loss: 0.00000 - val_binary_acc: 0.3722 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.008s\n",
      "| RMSProp | epoch: 029 | loss: 0.00000 - binary_acc: 0.3520 | val_loss: 0.00000 - val_binary_acc: 0.3722 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.007s\n",
      "| RMSProp | epoch: 030 | loss: 0.00000 - binary_acc: 0.3561 | val_loss: 0.00000 - val_binary_acc: 0.3722 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'linear', 35, [0.3164300220975044]]\n",
      "RMSProp\n",
      "softmax\n",
      "1000\n",
      "---------------------------------\n",
      "Run id: 9L373N\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.144s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.017s\n",
      "| RMSProp | epoch: 002 | loss: 0.00000 - binary_acc: 0.2933 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.018s\n",
      "| RMSProp | epoch: 003 | loss: 0.00000 - binary_acc: 0.3200 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.019s\n",
      "| RMSProp | epoch: 004 | loss: 0.00000 - binary_acc: 0.3245 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.020s\n",
      "| RMSProp | epoch: 005 | loss: 0.00000 - binary_acc: 0.3255 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.017s\n",
      "| RMSProp | epoch: 006 | loss: 0.00000 - binary_acc: 0.3258 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.017s\n",
      "| RMSProp | epoch: 007 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.018s\n",
      "| RMSProp | epoch: 008 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.018s\n",
      "| RMSProp | epoch: 009 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.018s\n",
      "| RMSProp | epoch: 010 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.016s\n",
      "| RMSProp | epoch: 011 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.018s\n",
      "| RMSProp | epoch: 012 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.017s\n",
      "| RMSProp | epoch: 013 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.018s\n",
      "| RMSProp | epoch: 014 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.025s\n",
      "| RMSProp | epoch: 015 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.017s\n",
      "| RMSProp | epoch: 016 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.017s\n",
      "| RMSProp | epoch: 017 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.021s\n",
      "| RMSProp | epoch: 018 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.018s\n",
      "| RMSProp | epoch: 019 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.018s\n",
      "| RMSProp | epoch: 020 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.021s\n",
      "| RMSProp | epoch: 021 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.018s\n",
      "| RMSProp | epoch: 022 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.018s\n",
      "| RMSProp | epoch: 023 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.017s\n",
      "| RMSProp | epoch: 024 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.020s\n",
      "| RMSProp | epoch: 025 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.017s\n",
      "| RMSProp | epoch: 026 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.034s\n",
      "| RMSProp | epoch: 027 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.049s\n",
      "| RMSProp | epoch: 028 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.020s\n",
      "| RMSProp | epoch: 029 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.018s\n",
      "| RMSProp | epoch: 030 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'softmax', 1000, [0.3002028369758482]]\n",
      "RMSProp\n",
      "softmax\n",
      "100\n",
      "---------------------------------\n",
      "Run id: E16SSW\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.122s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.008s\n",
      "| RMSProp | epoch: 002 | loss: 0.00000 - binary_acc: 0.2854 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.009s\n",
      "| RMSProp | epoch: 003 | loss: 0.00000 - binary_acc: 0.3113 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.009s\n",
      "| RMSProp | epoch: 004 | loss: 0.00000 - binary_acc: 0.3156 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.009s\n",
      "| RMSProp | epoch: 005 | loss: 0.00000 - binary_acc: 0.3166 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.009s\n",
      "| RMSProp | epoch: 006 | loss: 0.00000 - binary_acc: 0.3169 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.008s\n",
      "| RMSProp | epoch: 007 | loss: 0.00000 - binary_acc: 0.3170 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.009s\n",
      "| RMSProp | epoch: 008 | loss: 0.00000 - binary_acc: 0.3170 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.010s\n",
      "| RMSProp | epoch: 009 | loss: 0.00000 - binary_acc: 0.3170 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.011s\n",
      "| RMSProp | epoch: 010 | loss: 0.00000 - binary_acc: 0.3171 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.010s\n",
      "| RMSProp | epoch: 011 | loss: 0.00000 - binary_acc: 0.3171 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.009s\n",
      "| RMSProp | epoch: 012 | loss: 0.00000 - binary_acc: 0.3171 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.008s\n",
      "| RMSProp | epoch: 013 | loss: 0.00000 - binary_acc: 0.3171 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.009s\n",
      "| RMSProp | epoch: 014 | loss: 0.00000 - binary_acc: 0.3171 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.009s\n",
      "| RMSProp | epoch: 015 | loss: 0.00000 - binary_acc: 0.3171 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.008s\n",
      "| RMSProp | epoch: 016 | loss: 0.00000 - binary_acc: 0.3171 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.010s\n",
      "| RMSProp | epoch: 017 | loss: 0.00000 - binary_acc: 0.3171 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.008s\n",
      "| RMSProp | epoch: 018 | loss: 0.00000 - binary_acc: 0.3171 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.007s\n",
      "| RMSProp | epoch: 019 | loss: 0.00000 - binary_acc: 0.3171 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.010s\n",
      "| RMSProp | epoch: 020 | loss: 0.00000 - binary_acc: 0.3171 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.009s\n",
      "| RMSProp | epoch: 021 | loss: 0.00000 - binary_acc: 0.3171 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.009s\n",
      "| RMSProp | epoch: 022 | loss: 0.00000 - binary_acc: 0.3171 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.011s\n",
      "| RMSProp | epoch: 023 | loss: 0.00000 - binary_acc: 0.3171 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.008s\n",
      "| RMSProp | epoch: 024 | loss: 0.00000 - binary_acc: 0.3171 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.009s\n",
      "| RMSProp | epoch: 025 | loss: 0.00000 - binary_acc: 0.3171 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.009s\n",
      "| RMSProp | epoch: 026 | loss: 0.00000 - binary_acc: 0.3171 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.008s\n",
      "| RMSProp | epoch: 027 | loss: 0.00000 - binary_acc: 0.3171 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.009s\n",
      "| RMSProp | epoch: 028 | loss: 0.00000 - binary_acc: 0.3171 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.009s\n",
      "| RMSProp | epoch: 029 | loss: 0.00000 - binary_acc: 0.3171 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.009s\n",
      "| RMSProp | epoch: 030 | loss: 0.00000 - binary_acc: 0.3171 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'softmax', 100, [0.3002028369758482]]\n",
      "RMSProp\n",
      "softmax\n",
      "35\n",
      "---------------------------------\n",
      "Run id: ROXDHA\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.113s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.008s\n",
      "| RMSProp | epoch: 002 | loss: 0.00000 - binary_acc: 0.3002 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.008s\n",
      "| RMSProp | epoch: 003 | loss: 0.00000 - binary_acc: 0.3275 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.008s\n",
      "| RMSProp | epoch: 004 | loss: 0.00000 - binary_acc: 0.3320 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.008s\n",
      "| RMSProp | epoch: 005 | loss: 0.00000 - binary_acc: 0.3331 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.008s\n",
      "| RMSProp | epoch: 006 | loss: 0.00000 - binary_acc: 0.3334 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.008s\n",
      "| RMSProp | epoch: 007 | loss: 0.00000 - binary_acc: 0.3335 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.009s\n",
      "| RMSProp | epoch: 008 | loss: 0.00000 - binary_acc: 0.3335 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.008s\n",
      "| RMSProp | epoch: 009 | loss: 0.00000 - binary_acc: 0.3335 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.008s\n",
      "| RMSProp | epoch: 010 | loss: 0.00000 - binary_acc: 0.3335 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.008s\n",
      "| RMSProp | epoch: 011 | loss: 0.00000 - binary_acc: 0.3335 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.008s\n",
      "| RMSProp | epoch: 012 | loss: 0.00000 - binary_acc: 0.3335 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.007s\n",
      "| RMSProp | epoch: 013 | loss: 0.00000 - binary_acc: 0.3335 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.008s\n",
      "| RMSProp | epoch: 014 | loss: 0.00000 - binary_acc: 0.3335 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.008s\n",
      "| RMSProp | epoch: 015 | loss: 0.00000 - binary_acc: 0.3335 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.008s\n",
      "| RMSProp | epoch: 016 | loss: 0.00000 - binary_acc: 0.3335 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.007s\n",
      "| RMSProp | epoch: 017 | loss: 0.00000 - binary_acc: 0.3335 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.009s\n",
      "| RMSProp | epoch: 018 | loss: 0.00000 - binary_acc: 0.3335 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.010s\n",
      "| RMSProp | epoch: 019 | loss: 0.00000 - binary_acc: 0.3335 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.008s\n",
      "| RMSProp | epoch: 020 | loss: 0.00000 - binary_acc: 0.3335 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.008s\n",
      "| RMSProp | epoch: 021 | loss: 0.00000 - binary_acc: 0.3335 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.008s\n",
      "| RMSProp | epoch: 022 | loss: 0.00000 - binary_acc: 0.3335 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.007s\n",
      "| RMSProp | epoch: 023 | loss: 0.00000 - binary_acc: 0.3335 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.009s\n",
      "| RMSProp | epoch: 024 | loss: 0.00000 - binary_acc: 0.3335 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.008s\n",
      "| RMSProp | epoch: 025 | loss: 0.00000 - binary_acc: 0.3335 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.009s\n",
      "| RMSProp | epoch: 026 | loss: 0.00000 - binary_acc: 0.3335 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.008s\n",
      "| RMSProp | epoch: 027 | loss: 0.00000 - binary_acc: 0.3335 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.007s\n",
      "| RMSProp | epoch: 028 | loss: 0.00000 - binary_acc: 0.3335 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.008s\n",
      "| RMSProp | epoch: 029 | loss: 0.00000 - binary_acc: 0.3335 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.008s\n",
      "| RMSProp | epoch: 030 | loss: 0.00000 - binary_acc: 0.3335 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'softmax', 35, [0.3002028369758482]]\n",
      "RMSProp\n",
      "sigmoid\n",
      "1000\n",
      "---------------------------------\n",
      "Run id: TSECQY\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.117s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.012s\n",
      "| RMSProp | epoch: 002 | loss: 0.00000 - binary_acc: 0.2842 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.013s\n",
      "| RMSProp | epoch: 003 | loss: 0.00000 - binary_acc: 0.3100 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.024s\n",
      "| RMSProp | epoch: 004 | loss: 0.00000 - binary_acc: 0.3144 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.013s\n",
      "| RMSProp | epoch: 005 | loss: 0.00000 - binary_acc: 0.3153 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.014s\n",
      "| RMSProp | epoch: 006 | loss: 0.00000 - binary_acc: 0.3156 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.013s\n",
      "| RMSProp | epoch: 007 | loss: 0.00000 - binary_acc: 0.3157 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.015s\n",
      "| RMSProp | epoch: 008 | loss: 0.00000 - binary_acc: 0.3158 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.012s\n",
      "| RMSProp | epoch: 009 | loss: 0.00000 - binary_acc: 0.3158 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.013s\n",
      "| RMSProp | epoch: 010 | loss: 0.00000 - binary_acc: 0.3158 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.013s\n",
      "| RMSProp | epoch: 011 | loss: 0.00000 - binary_acc: 0.3158 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.014s\n",
      "| RMSProp | epoch: 012 | loss: 0.00000 - binary_acc: 0.3158 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.013s\n",
      "| RMSProp | epoch: 013 | loss: 0.00000 - binary_acc: 0.3158 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.013s\n",
      "| RMSProp | epoch: 014 | loss: 0.00000 - binary_acc: 0.3158 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.013s\n",
      "| RMSProp | epoch: 015 | loss: 0.00000 - binary_acc: 0.3158 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.015s\n",
      "| RMSProp | epoch: 016 | loss: 0.00000 - binary_acc: 0.3158 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.013s\n",
      "| RMSProp | epoch: 017 | loss: 0.00000 - binary_acc: 0.3158 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.014s\n",
      "| RMSProp | epoch: 018 | loss: 0.00000 - binary_acc: 0.3158 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.014s\n",
      "| RMSProp | epoch: 019 | loss: 0.00000 - binary_acc: 0.3158 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.013s\n",
      "| RMSProp | epoch: 020 | loss: 0.00000 - binary_acc: 0.3158 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.014s\n",
      "| RMSProp | epoch: 021 | loss: 0.00000 - binary_acc: 0.3158 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.014s\n",
      "| RMSProp | epoch: 022 | loss: 0.00000 - binary_acc: 0.3158 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.014s\n",
      "| RMSProp | epoch: 023 | loss: 0.00000 - binary_acc: 0.3158 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.013s\n",
      "| RMSProp | epoch: 024 | loss: 0.00000 - binary_acc: 0.3158 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.016s\n",
      "| RMSProp | epoch: 025 | loss: 0.00000 - binary_acc: 0.3158 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.013s\n",
      "| RMSProp | epoch: 026 | loss: 0.00000 - binary_acc: 0.3158 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.014s\n",
      "| RMSProp | epoch: 027 | loss: 0.00000 - binary_acc: 0.3158 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.014s\n",
      "| RMSProp | epoch: 028 | loss: 0.00000 - binary_acc: 0.3158 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.014s\n",
      "| RMSProp | epoch: 029 | loss: 0.00000 - binary_acc: 0.3158 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.015s\n",
      "| RMSProp | epoch: 030 | loss: 0.00000 - binary_acc: 0.3158 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'sigmoid', 1000, [0.3002028369758482]]\n",
      "RMSProp\n",
      "sigmoid\n",
      "100\n",
      "---------------------------------\n",
      "Run id: 7Z0WCB\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.102s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.006s\n",
      "| RMSProp | epoch: 002 | loss: 0.00000 - binary_acc: 0.2922 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.008s\n",
      "| RMSProp | epoch: 003 | loss: 0.00000 - binary_acc: 0.3188 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.008s\n",
      "| RMSProp | epoch: 004 | loss: 0.00000 - binary_acc: 0.3232 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.008s\n",
      "| RMSProp | epoch: 005 | loss: 0.00000 - binary_acc: 0.3242 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.008s\n",
      "| RMSProp | epoch: 006 | loss: 0.00000 - binary_acc: 0.3245 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.008s\n",
      "| RMSProp | epoch: 007 | loss: 0.00000 - binary_acc: 0.3246 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.008s\n",
      "| RMSProp | epoch: 008 | loss: 0.00000 - binary_acc: 0.3246 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.009s\n",
      "| RMSProp | epoch: 009 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.011s\n",
      "| RMSProp | epoch: 010 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.007s\n",
      "| RMSProp | epoch: 011 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.007s\n",
      "| RMSProp | epoch: 012 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.008s\n",
      "| RMSProp | epoch: 013 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.008s\n",
      "| RMSProp | epoch: 014 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.008s\n",
      "| RMSProp | epoch: 015 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.008s\n",
      "| RMSProp | epoch: 016 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.008s\n",
      "| RMSProp | epoch: 017 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.008s\n",
      "| RMSProp | epoch: 018 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.009s\n",
      "| RMSProp | epoch: 019 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.007s\n",
      "| RMSProp | epoch: 020 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.008s\n",
      "| RMSProp | epoch: 021 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.007s\n",
      "| RMSProp | epoch: 022 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.009s\n",
      "| RMSProp | epoch: 023 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.009s\n",
      "| RMSProp | epoch: 024 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.008s\n",
      "| RMSProp | epoch: 025 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.009s\n",
      "| RMSProp | epoch: 026 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.008s\n",
      "| RMSProp | epoch: 027 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.009s\n",
      "| RMSProp | epoch: 028 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.007s\n",
      "| RMSProp | epoch: 029 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.008s\n",
      "| RMSProp | epoch: 030 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'sigmoid', 100, [0.3002028369758482]]\n",
      "RMSProp\n",
      "sigmoid\n",
      "35\n",
      "---------------------------------\n",
      "Run id: Q78T9Q\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.129s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3519 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.007s\n",
      "| RMSProp | epoch: 002 | loss: 0.00000 - binary_acc: 0.2848 | val_loss: 0.00000 - val_binary_acc: 0.3519 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.008s\n",
      "| RMSProp | epoch: 003 | loss: 0.00000 - binary_acc: 0.3107 | val_loss: 0.00000 - val_binary_acc: 0.3519 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.009s\n",
      "| RMSProp | epoch: 004 | loss: 0.00000 - binary_acc: 0.3150 | val_loss: 0.00000 - val_binary_acc: 0.3519 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.008s\n",
      "| RMSProp | epoch: 005 | loss: 0.00000 - binary_acc: 0.3160 | val_loss: 0.00000 - val_binary_acc: 0.3519 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.007s\n",
      "| RMSProp | epoch: 006 | loss: 0.00000 - binary_acc: 0.3163 | val_loss: 0.00000 - val_binary_acc: 0.3519 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.007s\n",
      "| RMSProp | epoch: 007 | loss: 0.00000 - binary_acc: 0.3164 | val_loss: 0.00000 - val_binary_acc: 0.3519 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.008s\n",
      "| RMSProp | epoch: 008 | loss: 0.00000 - binary_acc: 0.3164 | val_loss: 0.00000 - val_binary_acc: 0.3519 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.008s\n",
      "| RMSProp | epoch: 009 | loss: 0.00000 - binary_acc: 0.3164 | val_loss: 0.00000 - val_binary_acc: 0.3519 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.006s\n",
      "| RMSProp | epoch: 010 | loss: 0.00000 - binary_acc: 0.3164 | val_loss: 0.00000 - val_binary_acc: 0.3519 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.009s\n",
      "| RMSProp | epoch: 011 | loss: 0.00000 - binary_acc: 0.3164 | val_loss: 0.00000 - val_binary_acc: 0.3519 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.008s\n",
      "| RMSProp | epoch: 012 | loss: 0.00000 - binary_acc: 0.3164 | val_loss: 0.00000 - val_binary_acc: 0.3519 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.008s\n",
      "| RMSProp | epoch: 013 | loss: 0.00000 - binary_acc: 0.3164 | val_loss: 0.00000 - val_binary_acc: 0.3519 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.007s\n",
      "| RMSProp | epoch: 014 | loss: 0.00000 - binary_acc: 0.3164 | val_loss: 0.00000 - val_binary_acc: 0.3519 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.009s\n",
      "| RMSProp | epoch: 015 | loss: 0.00000 - binary_acc: 0.3164 | val_loss: 0.00000 - val_binary_acc: 0.3519 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.006s\n",
      "| RMSProp | epoch: 016 | loss: 0.00000 - binary_acc: 0.3164 | val_loss: 0.00000 - val_binary_acc: 0.3519 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.008s\n",
      "| RMSProp | epoch: 017 | loss: 0.00000 - binary_acc: 0.3164 | val_loss: 0.00000 - val_binary_acc: 0.3519 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.010s\n",
      "| RMSProp | epoch: 018 | loss: 0.00000 - binary_acc: 0.3164 | val_loss: 0.00000 - val_binary_acc: 0.3519 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.008s\n",
      "| RMSProp | epoch: 019 | loss: 0.00000 - binary_acc: 0.3164 | val_loss: 0.00000 - val_binary_acc: 0.3519 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.007s\n",
      "| RMSProp | epoch: 020 | loss: 0.00000 - binary_acc: 0.3164 | val_loss: 0.00000 - val_binary_acc: 0.3519 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.007s\n",
      "| RMSProp | epoch: 021 | loss: 0.00000 - binary_acc: 0.3164 | val_loss: 0.00000 - val_binary_acc: 0.3519 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.007s\n",
      "| RMSProp | epoch: 022 | loss: 0.00000 - binary_acc: 0.3164 | val_loss: 0.00000 - val_binary_acc: 0.3519 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.007s\n",
      "| RMSProp | epoch: 023 | loss: 0.00000 - binary_acc: 0.3164 | val_loss: 0.00000 - val_binary_acc: 0.3519 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.007s\n",
      "| RMSProp | epoch: 024 | loss: 0.00000 - binary_acc: 0.3164 | val_loss: 0.00000 - val_binary_acc: 0.3519 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.008s\n",
      "| RMSProp | epoch: 025 | loss: 0.00000 - binary_acc: 0.3164 | val_loss: 0.00000 - val_binary_acc: 0.3519 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.008s\n",
      "| RMSProp | epoch: 026 | loss: 0.00000 - binary_acc: 0.3164 | val_loss: 0.00000 - val_binary_acc: 0.3519 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.008s\n",
      "| RMSProp | epoch: 027 | loss: 0.00000 - binary_acc: 0.3164 | val_loss: 0.00000 - val_binary_acc: 0.3519 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.008s\n",
      "| RMSProp | epoch: 028 | loss: 0.00000 - binary_acc: 0.3164 | val_loss: 0.00000 - val_binary_acc: 0.3519 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.007s\n",
      "| RMSProp | epoch: 029 | loss: 0.00000 - binary_acc: 0.3164 | val_loss: 0.00000 - val_binary_acc: 0.3519 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.008s\n",
      "| RMSProp | epoch: 030 | loss: 0.00000 - binary_acc: 0.3164 | val_loss: 0.00000 - val_binary_acc: 0.3519 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'sigmoid', 35, [0.3002028369758482]]\n",
      "RMSProp\n",
      "tanh\n",
      "1000\n",
      "---------------------------------\n",
      "Run id: UMG9MS\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.108s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.4987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.012s\n",
      "| RMSProp | epoch: 002 | loss: 0.00000 - binary_acc: 0.3732 | val_loss: 0.00000 - val_binary_acc: 0.4987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.014s\n",
      "| RMSProp | epoch: 003 | loss: 0.00000 - binary_acc: 0.4808 | val_loss: 0.00000 - val_binary_acc: 0.4987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.016s\n",
      "| RMSProp | epoch: 004 | loss: 0.00000 - binary_acc: 0.4127 | val_loss: 0.00000 - val_binary_acc: 0.4987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.026s\n",
      "| RMSProp | epoch: 005 | loss: 0.00000 - binary_acc: 0.4764 | val_loss: 0.00000 - val_binary_acc: 0.4987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.015s\n",
      "| RMSProp | epoch: 006 | loss: 0.00000 - binary_acc: 0.4262 | val_loss: 0.00000 - val_binary_acc: 0.4987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.014s\n",
      "| RMSProp | epoch: 007 | loss: 0.00000 - binary_acc: 0.4733 | val_loss: 0.00000 - val_binary_acc: 0.4987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.014s\n",
      "| RMSProp | epoch: 008 | loss: 0.00000 - binary_acc: 0.4268 | val_loss: 0.00000 - val_binary_acc: 0.4987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.013s\n",
      "| RMSProp | epoch: 009 | loss: 0.00000 - binary_acc: 0.4681 | val_loss: 0.00000 - val_binary_acc: 0.4987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.014s\n",
      "| RMSProp | epoch: 010 | loss: 0.00000 - binary_acc: 0.4335 | val_loss: 0.00000 - val_binary_acc: 0.4987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.013s\n",
      "| RMSProp | epoch: 011 | loss: 0.00000 - binary_acc: 0.4672 | val_loss: 0.00000 - val_binary_acc: 0.4987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.016s\n",
      "| RMSProp | epoch: 012 | loss: 0.00000 - binary_acc: 0.4841 | val_loss: 0.00000 - val_binary_acc: 0.4987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.015s\n",
      "| RMSProp | epoch: 013 | loss: 0.00000 - binary_acc: 0.4930 | val_loss: 0.00000 - val_binary_acc: 0.4987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.015s\n",
      "| RMSProp | epoch: 014 | loss: 0.00000 - binary_acc: 0.4760 | val_loss: 0.00000 - val_binary_acc: 0.4987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.013s\n",
      "| RMSProp | epoch: 015 | loss: 0.00000 - binary_acc: 0.4873 | val_loss: 0.00000 - val_binary_acc: 0.4987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.013s\n",
      "| RMSProp | epoch: 016 | loss: 0.00000 - binary_acc: 0.4688 | val_loss: 0.00000 - val_binary_acc: 0.4987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.015s\n",
      "| RMSProp | epoch: 017 | loss: 0.00000 - binary_acc: 0.4818 | val_loss: 0.00000 - val_binary_acc: 0.4987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.015s\n",
      "| RMSProp | epoch: 018 | loss: 0.00000 - binary_acc: 0.4614 | val_loss: 0.00000 - val_binary_acc: 0.4987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.015s\n",
      "| RMSProp | epoch: 019 | loss: 0.00000 - binary_acc: 0.4759 | val_loss: 0.00000 - val_binary_acc: 0.4987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.015s\n",
      "| RMSProp | epoch: 020 | loss: 0.00000 - binary_acc: 0.4666 | val_loss: 0.00000 - val_binary_acc: 0.4987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.013s\n",
      "| RMSProp | epoch: 021 | loss: 0.00000 - binary_acc: 0.4784 | val_loss: 0.00000 - val_binary_acc: 0.4987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.014s\n",
      "| RMSProp | epoch: 022 | loss: 0.00000 - binary_acc: 0.4704 | val_loss: 0.00000 - val_binary_acc: 0.4987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.014s\n",
      "| RMSProp | epoch: 023 | loss: 0.00000 - binary_acc: 0.4803 | val_loss: 0.00000 - val_binary_acc: 0.4987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.014s\n",
      "| RMSProp | epoch: 024 | loss: 0.00000 - binary_acc: 0.4710 | val_loss: 0.00000 - val_binary_acc: 0.4987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.013s\n",
      "| RMSProp | epoch: 025 | loss: 0.00000 - binary_acc: 0.4802 | val_loss: 0.00000 - val_binary_acc: 0.4987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.014s\n",
      "| RMSProp | epoch: 026 | loss: 0.00000 - binary_acc: 0.4682 | val_loss: 0.00000 - val_binary_acc: 0.4987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.013s\n",
      "| RMSProp | epoch: 027 | loss: 0.00000 - binary_acc: 0.4776 | val_loss: 0.00000 - val_binary_acc: 0.4987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.013s\n",
      "| RMSProp | epoch: 028 | loss: 0.00000 - binary_acc: 0.4709 | val_loss: 0.00000 - val_binary_acc: 0.4987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.012s\n",
      "| RMSProp | epoch: 029 | loss: 0.00000 - binary_acc: 0.4792 | val_loss: 0.00000 - val_binary_acc: 0.4987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.014s\n",
      "| RMSProp | epoch: 030 | loss: 0.00000 - binary_acc: 0.4719 | val_loss: 0.00000 - val_binary_acc: 0.4987 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'tanh', 1000, [0.5050709954865322]]\n",
      "RMSProp\n",
      "tanh\n",
      "100\n",
      "---------------------------------\n",
      "Run id: EX2E7I\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.099s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.006s\n",
      "| RMSProp | epoch: 002 | loss: 0.00000 - binary_acc: 0.3242 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.008s\n",
      "| RMSProp | epoch: 003 | loss: 0.00000 - binary_acc: 0.2857 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.008s\n",
      "| RMSProp | epoch: 004 | loss: 0.00000 - binary_acc: 0.3563 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.008s\n",
      "| RMSProp | epoch: 005 | loss: 0.00000 - binary_acc: 0.3015 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.008s\n",
      "| RMSProp | epoch: 006 | loss: 0.00000 - binary_acc: 0.3470 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.009s\n",
      "| RMSProp | epoch: 007 | loss: 0.00000 - binary_acc: 0.3050 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.009s\n",
      "| RMSProp | epoch: 008 | loss: 0.00000 - binary_acc: 0.3371 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.008s\n",
      "| RMSProp | epoch: 009 | loss: 0.00000 - binary_acc: 0.3054 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.008s\n",
      "| RMSProp | epoch: 010 | loss: 0.00000 - binary_acc: 0.3451 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.008s\n",
      "| RMSProp | epoch: 011 | loss: 0.00000 - binary_acc: 0.3129 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.008s\n",
      "| RMSProp | epoch: 012 | loss: 0.00000 - binary_acc: 0.3325 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.008s\n",
      "| RMSProp | epoch: 013 | loss: 0.00000 - binary_acc: 0.3087 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.008s\n",
      "| RMSProp | epoch: 014 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.008s\n",
      "| RMSProp | epoch: 015 | loss: 0.00000 - binary_acc: 0.3103 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.009s\n",
      "| RMSProp | epoch: 016 | loss: 0.00000 - binary_acc: 0.3254 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.008s\n",
      "| RMSProp | epoch: 017 | loss: 0.00000 - binary_acc: 0.3080 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.008s\n",
      "| RMSProp | epoch: 018 | loss: 0.00000 - binary_acc: 0.3329 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.008s\n",
      "| RMSProp | epoch: 019 | loss: 0.00000 - binary_acc: 0.3143 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.009s\n",
      "| RMSProp | epoch: 020 | loss: 0.00000 - binary_acc: 0.3327 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.008s\n",
      "| RMSProp | epoch: 021 | loss: 0.00000 - binary_acc: 0.3155 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.008s\n",
      "| RMSProp | epoch: 022 | loss: 0.00000 - binary_acc: 0.3243 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.009s\n",
      "| RMSProp | epoch: 023 | loss: 0.00000 - binary_acc: 0.3106 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.008s\n",
      "| RMSProp | epoch: 024 | loss: 0.00000 - binary_acc: 0.3181 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.009s\n",
      "| RMSProp | epoch: 025 | loss: 0.00000 - binary_acc: 0.3069 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.008s\n",
      "| RMSProp | epoch: 026 | loss: 0.00000 - binary_acc: 0.3210 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.008s\n",
      "| RMSProp | epoch: 027 | loss: 0.00000 - binary_acc: 0.3097 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.009s\n",
      "| RMSProp | epoch: 028 | loss: 0.00000 - binary_acc: 0.3166 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.008s\n",
      "| RMSProp | epoch: 029 | loss: 0.00000 - binary_acc: 0.3070 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.009s\n",
      "| RMSProp | epoch: 030 | loss: 0.00000 - binary_acc: 0.3148 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'tanh', 100, [0.275862070779046]]\n",
      "RMSProp\n",
      "tanh\n",
      "35\n",
      "---------------------------------\n",
      "Run id: JT25QH\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.100s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.006s\n",
      "| RMSProp | epoch: 002 | loss: 0.00000 - binary_acc: 0.3150 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.007s\n",
      "| RMSProp | epoch: 003 | loss: 0.00000 - binary_acc: 0.2726 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.008s\n",
      "| RMSProp | epoch: 004 | loss: 0.00000 - binary_acc: 0.2655 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.008s\n",
      "| RMSProp | epoch: 005 | loss: 0.00000 - binary_acc: 0.2639 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.008s\n",
      "| RMSProp | epoch: 006 | loss: 0.00000 - binary_acc: 0.2634 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.008s\n",
      "| RMSProp | epoch: 007 | loss: 0.00000 - binary_acc: 0.2633 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.007s\n",
      "| RMSProp | epoch: 008 | loss: 0.00000 - binary_acc: 0.3292 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.007s\n",
      "| RMSProp | epoch: 009 | loss: 0.00000 - binary_acc: 0.2942 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.008s\n",
      "| RMSProp | epoch: 010 | loss: 0.00000 - binary_acc: 0.3212 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.007s\n",
      "| RMSProp | epoch: 011 | loss: 0.00000 - binary_acc: 0.2937 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.008s\n",
      "| RMSProp | epoch: 012 | loss: 0.00000 - binary_acc: 0.3347 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.008s\n",
      "| RMSProp | epoch: 013 | loss: 0.00000 - binary_acc: 0.3041 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.007s\n",
      "| RMSProp | epoch: 014 | loss: 0.00000 - binary_acc: 0.3307 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.007s\n",
      "| RMSProp | epoch: 015 | loss: 0.00000 - binary_acc: 0.3042 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.008s\n",
      "| RMSProp | epoch: 016 | loss: 0.00000 - binary_acc: 0.2888 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.008s\n",
      "| RMSProp | epoch: 017 | loss: 0.00000 - binary_acc: 0.3154 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.007s\n",
      "| RMSProp | epoch: 018 | loss: 0.00000 - binary_acc: 0.3276 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.008s\n",
      "| RMSProp | epoch: 019 | loss: 0.00000 - binary_acc: 0.3061 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.007s\n",
      "| RMSProp | epoch: 020 | loss: 0.00000 - binary_acc: 0.3158 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.008s\n",
      "| RMSProp | epoch: 021 | loss: 0.00000 - binary_acc: 0.2994 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.008s\n",
      "| RMSProp | epoch: 022 | loss: 0.00000 - binary_acc: 0.3173 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.008s\n",
      "| RMSProp | epoch: 023 | loss: 0.00000 - binary_acc: 0.3016 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.008s\n",
      "| RMSProp | epoch: 024 | loss: 0.00000 - binary_acc: 0.3127 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.008s\n",
      "| RMSProp | epoch: 025 | loss: 0.00000 - binary_acc: 0.2992 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.008s\n",
      "| RMSProp | epoch: 026 | loss: 0.00000 - binary_acc: 0.3068 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.009s\n",
      "| RMSProp | epoch: 027 | loss: 0.00000 - binary_acc: 0.2956 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.007s\n",
      "| RMSProp | epoch: 028 | loss: 0.00000 - binary_acc: 0.3100 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.008s\n",
      "| RMSProp | epoch: 029 | loss: 0.00000 - binary_acc: 0.2986 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.008s\n",
      "| RMSProp | epoch: 030 | loss: 0.00000 - binary_acc: 0.3049 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'tanh', 35, [0.24949290326836143]]\n",
      "RMSProp\n",
      "prelu\n",
      "1000\n",
      "---------------------------------\n",
      "Run id: KFH17H\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.157s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.027s\n",
      "| RMSProp | epoch: 002 | loss: nan - binary_acc: 0.4069 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.028s\n",
      "| RMSProp | epoch: 003 | loss: nan - binary_acc: 0.4408 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.025s\n",
      "| RMSProp | epoch: 004 | loss: nan - binary_acc: 0.4464 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.027s\n",
      "| RMSProp | epoch: 005 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.032s\n",
      "| RMSProp | epoch: 006 | loss: nan - binary_acc: 0.4481 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.025s\n",
      "| RMSProp | epoch: 007 | loss: nan - binary_acc: 0.4482 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.025s\n",
      "| RMSProp | epoch: 008 | loss: nan - binary_acc: 0.4483 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.029s\n",
      "| RMSProp | epoch: 009 | loss: nan - binary_acc: 0.4483 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.025s\n",
      "| RMSProp | epoch: 010 | loss: nan - binary_acc: 0.4483 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.026s\n",
      "| RMSProp | epoch: 011 | loss: nan - binary_acc: 0.4483 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.026s\n",
      "| RMSProp | epoch: 012 | loss: nan - binary_acc: 0.4483 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.026s\n",
      "| RMSProp | epoch: 013 | loss: nan - binary_acc: 0.4483 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.033s\n",
      "| RMSProp | epoch: 014 | loss: nan - binary_acc: 0.4483 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.032s\n",
      "| RMSProp | epoch: 015 | loss: nan - binary_acc: 0.4483 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.028s\n",
      "| RMSProp | epoch: 016 | loss: nan - binary_acc: 0.4483 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.029s\n",
      "| RMSProp | epoch: 017 | loss: nan - binary_acc: 0.4483 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.028s\n",
      "| RMSProp | epoch: 018 | loss: nan - binary_acc: 0.4483 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.027s\n",
      "| RMSProp | epoch: 019 | loss: nan - binary_acc: 0.4483 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.026s\n",
      "| RMSProp | epoch: 020 | loss: nan - binary_acc: 0.4483 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.029s\n",
      "| RMSProp | epoch: 021 | loss: nan - binary_acc: 0.4483 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.030s\n",
      "| RMSProp | epoch: 022 | loss: nan - binary_acc: 0.4483 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.025s\n",
      "| RMSProp | epoch: 023 | loss: nan - binary_acc: 0.4483 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.026s\n",
      "| RMSProp | epoch: 024 | loss: nan - binary_acc: 0.4483 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.029s\n",
      "| RMSProp | epoch: 025 | loss: nan - binary_acc: 0.4483 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.039s\n",
      "| RMSProp | epoch: 026 | loss: nan - binary_acc: 0.4483 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.025s\n",
      "| RMSProp | epoch: 027 | loss: nan - binary_acc: 0.4483 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.026s\n",
      "| RMSProp | epoch: 028 | loss: nan - binary_acc: 0.4483 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.029s\n",
      "| RMSProp | epoch: 029 | loss: nan - binary_acc: 0.4483 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.030s\n",
      "| RMSProp | epoch: 030 | loss: nan - binary_acc: 0.4483 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'prelu', 1000, [0.45436105404132276]]\n",
      "RMSProp\n",
      "prelu\n",
      "100\n",
      "---------------------------------\n",
      "Run id: G39CE6\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.161s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 002 | loss: nan - binary_acc: 0.3293 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 003 | loss: nan - binary_acc: 0.4147 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 004 | loss: nan - binary_acc: 0.4290 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 005 | loss: nan - binary_acc: 0.4323 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 006 | loss: nan - binary_acc: 0.4332 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 007 | loss: nan - binary_acc: 0.4335 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 008 | loss: nan - binary_acc: 0.4336 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 009 | loss: nan - binary_acc: 0.4337 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 010 | loss: nan - binary_acc: 0.4337 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 011 | loss: nan - binary_acc: 0.4337 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 012 | loss: nan - binary_acc: 0.4337 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 013 | loss: nan - binary_acc: 0.4337 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 014 | loss: nan - binary_acc: 0.4337 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 015 | loss: nan - binary_acc: 0.4337 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 016 | loss: nan - binary_acc: 0.4337 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 017 | loss: nan - binary_acc: 0.4337 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 018 | loss: nan - binary_acc: 0.4337 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 019 | loss: nan - binary_acc: 0.4337 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 020 | loss: nan - binary_acc: 0.4337 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 021 | loss: nan - binary_acc: 0.4337 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 022 | loss: nan - binary_acc: 0.4337 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 023 | loss: nan - binary_acc: 0.4337 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 024 | loss: nan - binary_acc: 0.4337 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 025 | loss: nan - binary_acc: 0.4337 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 026 | loss: nan - binary_acc: 0.4337 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 027 | loss: nan - binary_acc: 0.4337 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 028 | loss: nan - binary_acc: 0.4337 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 029 | loss: nan - binary_acc: 0.4337 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 030 | loss: nan - binary_acc: 0.4337 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'prelu', 100, [0.45436105404132276]]\n",
      "RMSProp\n",
      "prelu\n",
      "35\n",
      "---------------------------------\n",
      "Run id: QMBN83\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.130s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| RMSProp | epoch: 002 | loss: nan - binary_acc: 0.4029 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 003 | loss: nan - binary_acc: 0.4395 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 004 | loss: nan - binary_acc: 0.4457 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 005 | loss: nan - binary_acc: 0.4471 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 006 | loss: nan - binary_acc: 0.4475 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 007 | loss: nan - binary_acc: 0.4476 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 008 | loss: nan - binary_acc: 0.4476 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 009 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 010 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 011 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 012 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 013 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 014 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 015 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 016 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 017 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 018 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 019 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 020 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 021 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| RMSProp | epoch: 022 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 023 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 024 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 025 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 026 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 027 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 028 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| RMSProp | epoch: 029 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 030 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'prelu', 35, [0.45436105404132276]]\n",
      "AdaGrad\n",
      "relu\n",
      "1000\n",
      "---------------------------------\n",
      "Run id: W1RGXT\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.136s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaGrad | epoch: 002 | loss: nan - binary_acc: 0.2973 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| AdaGrad | epoch: 003 | loss: nan - binary_acc: 0.4115 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| AdaGrad | epoch: 004 | loss: nan - binary_acc: 0.4306 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.014s\n",
      "| AdaGrad | epoch: 005 | loss: nan - binary_acc: 0.4350 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| AdaGrad | epoch: 006 | loss: nan - binary_acc: 0.4362 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| AdaGrad | epoch: 007 | loss: nan - binary_acc: 0.4366 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| AdaGrad | epoch: 008 | loss: nan - binary_acc: 0.4368 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.014s\n",
      "| AdaGrad | epoch: 009 | loss: nan - binary_acc: 0.4368 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.014s\n",
      "| AdaGrad | epoch: 010 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| AdaGrad | epoch: 011 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| AdaGrad | epoch: 012 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.015s\n",
      "| AdaGrad | epoch: 013 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| AdaGrad | epoch: 014 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.014s\n",
      "| AdaGrad | epoch: 015 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| AdaGrad | epoch: 016 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.015s\n",
      "| AdaGrad | epoch: 017 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.014s\n",
      "| AdaGrad | epoch: 018 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.015s\n",
      "| AdaGrad | epoch: 019 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| AdaGrad | epoch: 020 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| AdaGrad | epoch: 021 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| AdaGrad | epoch: 022 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| AdaGrad | epoch: 023 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| AdaGrad | epoch: 024 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.015s\n",
      "| AdaGrad | epoch: 025 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| AdaGrad | epoch: 026 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.014s\n",
      "| AdaGrad | epoch: 027 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| AdaGrad | epoch: 028 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| AdaGrad | epoch: 029 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| AdaGrad | epoch: 030 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'relu', 1000, [0.45436105404132276]]\n",
      "AdaGrad\n",
      "relu\n",
      "100\n",
      "---------------------------------\n",
      "Run id: UTXN19\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.111s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.006s\n",
      "| AdaGrad | epoch: 002 | loss: nan - binary_acc: 0.3464 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 003 | loss: nan - binary_acc: 0.4225 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 004 | loss: nan - binary_acc: 0.4352 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 005 | loss: nan - binary_acc: 0.4381 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 006 | loss: nan - binary_acc: 0.4390 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 007 | loss: nan - binary_acc: 0.4393 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 008 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 009 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 010 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 011 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 012 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 013 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 014 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 015 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 016 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 017 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 018 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 019 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 020 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 021 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 022 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 023 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 024 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 025 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 026 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 027 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 028 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 029 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 030 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'relu', 100, [0.45436105404132276]]\n",
      "AdaGrad\n",
      "relu\n",
      "35\n",
      "---------------------------------\n",
      "Run id: QR06M5\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.102s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaGrad | epoch: 002 | loss: nan - binary_acc: 0.3379 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaGrad | epoch: 003 | loss: nan - binary_acc: 0.4236 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaGrad | epoch: 004 | loss: nan - binary_acc: 0.4379 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 005 | loss: nan - binary_acc: 0.4411 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 006 | loss: nan - binary_acc: 0.4421 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 007 | loss: nan - binary_acc: 0.4424 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 008 | loss: nan - binary_acc: 0.4425 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 009 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaGrad | epoch: 010 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 011 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 012 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 013 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 014 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 015 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 016 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 017 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaGrad | epoch: 018 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 019 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 020 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 021 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.006s\n",
      "| AdaGrad | epoch: 022 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 023 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 024 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaGrad | epoch: 025 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaGrad | epoch: 026 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaGrad | epoch: 027 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaGrad | epoch: 028 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 029 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaGrad | epoch: 030 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'relu', 35, [0.45436105404132276]]\n",
      "AdaGrad\n",
      "linear\n",
      "1000\n",
      "---------------------------------\n",
      "Run id: 7U6M3O\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.135s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.010s\n",
      "| AdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.2431 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.012s\n",
      "| AdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.2652 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.012s\n",
      "| AdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3436 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.010s\n",
      "| AdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.2927 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.011s\n",
      "| AdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3398 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.012s\n",
      "| AdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.2980 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.011s\n",
      "| AdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3298 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.012s\n",
      "| AdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.2982 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.012s\n",
      "| AdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3241 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.013s\n",
      "| AdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.2985 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.011s\n",
      "| AdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3191 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.011s\n",
      "| AdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.2981 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.013s\n",
      "| AdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3113 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.012s\n",
      "| AdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.2952 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.011s\n",
      "| AdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.2858 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.010s\n",
      "| AdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.2802 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.012s\n",
      "| AdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.2978 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.011s\n",
      "| AdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.2886 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.013s\n",
      "| AdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3022 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.012s\n",
      "| AdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.2922 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.012s\n",
      "| AdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3041 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.013s\n",
      "| AdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.2942 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.011s\n",
      "| AdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3069 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.011s\n",
      "| AdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.2969 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.011s\n",
      "| AdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3076 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.012s\n",
      "| AdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.2979 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.011s\n",
      "| AdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3045 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.011s\n",
      "| AdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.2961 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.011s\n",
      "| AdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3032 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'linear', 1000, [0.2677484782182179]]\n",
      "AdaGrad\n",
      "linear\n",
      "100\n",
      "---------------------------------\n",
      "Run id: V08LRV\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.096s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.006s\n",
      "| AdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.3470 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.008s\n",
      "| AdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.2815 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.008s\n",
      "| AdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3514 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.007s\n",
      "| AdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.2930 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.007s\n",
      "| AdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3386 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.007s\n",
      "| AdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.2956 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.008s\n",
      "| AdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3373 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.008s\n",
      "| AdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.3001 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.008s\n",
      "| AdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3466 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.008s\n",
      "| AdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.3089 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.007s\n",
      "| AdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3351 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.008s\n",
      "| AdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.3059 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.009s\n",
      "| AdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3385 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.010s\n",
      "| AdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.3105 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.008s\n",
      "| AdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.2942 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.009s\n",
      "| AdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.2844 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.008s\n",
      "| AdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.2999 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.008s\n",
      "| AdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.2889 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.009s\n",
      "| AdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3051 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.008s\n",
      "| AdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.2933 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.008s\n",
      "| AdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3023 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.008s\n",
      "| AdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.2920 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.008s\n",
      "| AdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3101 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.008s\n",
      "| AdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.2984 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.010s\n",
      "| AdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3095 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.009s\n",
      "| AdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.2986 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.008s\n",
      "| AdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3084 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.008s\n",
      "| AdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.2983 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.008s\n",
      "| AdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3013 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'linear', 100, [0.26369168308637203]]\n",
      "AdaGrad\n",
      "linear\n",
      "35\n",
      "---------------------------------\n",
      "Run id: GB8GT4\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.105s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.4810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.006s\n",
      "| AdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.4001 | val_loss: 0.00000 - val_binary_acc: 0.4810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.007s\n",
      "| AdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.4857 | val_loss: 0.00000 - val_binary_acc: 0.4810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.007s\n",
      "| AdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.4191 | val_loss: 0.00000 - val_binary_acc: 0.4810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.007s\n",
      "| AdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.4784 | val_loss: 0.00000 - val_binary_acc: 0.4810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.008s\n",
      "| AdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.4252 | val_loss: 0.00000 - val_binary_acc: 0.4810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.007s\n",
      "| AdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.4729 | val_loss: 0.00000 - val_binary_acc: 0.4810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.008s\n",
      "| AdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.4320 | val_loss: 0.00000 - val_binary_acc: 0.4810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.009s\n",
      "| AdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.4705 | val_loss: 0.00000 - val_binary_acc: 0.4810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.006s\n",
      "| AdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.4486 | val_loss: 0.00000 - val_binary_acc: 0.4810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.008s\n",
      "| AdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.4752 | val_loss: 0.00000 - val_binary_acc: 0.4810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.008s\n",
      "| AdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.4520 | val_loss: 0.00000 - val_binary_acc: 0.4810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.008s\n",
      "| AdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.4746 | val_loss: 0.00000 - val_binary_acc: 0.4810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.008s\n",
      "| AdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.4532 | val_loss: 0.00000 - val_binary_acc: 0.4810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.007s\n",
      "| AdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.4734 | val_loss: 0.00000 - val_binary_acc: 0.4810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.007s\n",
      "| AdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.4854 | val_loss: 0.00000 - val_binary_acc: 0.4810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.008s\n",
      "| AdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.4926 | val_loss: 0.00000 - val_binary_acc: 0.4835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.007s\n",
      "| AdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.4595 | val_loss: 0.00000 - val_binary_acc: 0.4835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.008s\n",
      "| AdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.4756 | val_loss: 0.00000 - val_binary_acc: 0.4835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.008s\n",
      "| AdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.4860 | val_loss: 0.00000 - val_binary_acc: 0.4835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.007s\n",
      "| AdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.4552 | val_loss: 0.00000 - val_binary_acc: 0.4835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.007s\n",
      "| AdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.4387 | val_loss: 0.00000 - val_binary_acc: 0.4835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.007s\n",
      "| AdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.4588 | val_loss: 0.00000 - val_binary_acc: 0.4835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.008s\n",
      "| AdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.4528 | val_loss: 0.00000 - val_binary_acc: 0.4835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.007s\n",
      "| AdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.4678 | val_loss: 0.00000 - val_binary_acc: 0.4835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.007s\n",
      "| AdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.4539 | val_loss: 0.00000 - val_binary_acc: 0.4835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.007s\n",
      "| AdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.4678 | val_loss: 0.00000 - val_binary_acc: 0.4835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.007s\n",
      "| AdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.4454 | val_loss: 0.00000 - val_binary_acc: 0.4835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.008s\n",
      "| AdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.4606 | val_loss: 0.00000 - val_binary_acc: 0.4835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.007s\n",
      "| AdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.4454 | val_loss: 0.00000 - val_binary_acc: 0.4835 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'linear', 35, [0.49087221022793537]]\n",
      "AdaGrad\n",
      "softmax\n",
      "1000\n",
      "---------------------------------\n",
      "Run id: V9TED5\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.121s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.015s\n",
      "| AdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.2939 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.017s\n",
      "| AdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.3206 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.018s\n",
      "| AdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3251 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.018s\n",
      "| AdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.3261 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.019s\n",
      "| AdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3264 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.018s\n",
      "| AdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.3265 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.021s\n",
      "| AdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3265 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.019s\n",
      "| AdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.017s\n",
      "| AdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.018s\n",
      "| AdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.017s\n",
      "| AdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.017s\n",
      "| AdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.019s\n",
      "| AdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.017s\n",
      "| AdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.021s\n",
      "| AdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.018s\n",
      "| AdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.020s\n",
      "| AdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.018s\n",
      "| AdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.018s\n",
      "| AdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.018s\n",
      "| AdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.019s\n",
      "| AdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.019s\n",
      "| AdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.021s\n",
      "| AdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.018s\n",
      "| AdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.022s\n",
      "| AdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.018s\n",
      "| AdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.019s\n",
      "| AdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.019s\n",
      "| AdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.018s\n",
      "| AdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3266 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'softmax', 1000, [0.3002028369758482]]\n",
      "AdaGrad\n",
      "softmax\n",
      "100\n",
      "---------------------------------\n",
      "Run id: 9WNB5L\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.128s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.006s\n",
      "| AdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.2905 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.009s\n",
      "| AdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.3169 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.008s\n",
      "| AdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3213 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.008s\n",
      "| AdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.3223 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.009s\n",
      "| AdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3226 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.008s\n",
      "| AdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.3227 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.010s\n",
      "| AdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3227 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.011s\n",
      "| AdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.010s\n",
      "| AdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.009s\n",
      "| AdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.010s\n",
      "| AdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.010s\n",
      "| AdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.009s\n",
      "| AdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.010s\n",
      "| AdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.008s\n",
      "| AdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.009s\n",
      "| AdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.010s\n",
      "| AdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.009s\n",
      "| AdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.008s\n",
      "| AdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.008s\n",
      "| AdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.010s\n",
      "| AdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.009s\n",
      "| AdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.011s\n",
      "| AdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.010s\n",
      "| AdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.010s\n",
      "| AdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.009s\n",
      "| AdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.008s\n",
      "| AdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.010s\n",
      "| AdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.010s\n",
      "| AdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'softmax', 100, [0.3002028369758482]]\n",
      "AdaGrad\n",
      "softmax\n",
      "35\n",
      "---------------------------------\n",
      "Run id: RGLVGX\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.090s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.007s\n",
      "| AdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.2928 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.009s\n",
      "| AdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.3194 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.008s\n",
      "| AdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3238 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.008s\n",
      "| AdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.3248 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.009s\n",
      "| AdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3251 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.008s\n",
      "| AdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.3252 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.008s\n",
      "| AdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.008s\n",
      "| AdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.008s\n",
      "| AdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.009s\n",
      "| AdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.010s\n",
      "| AdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.008s\n",
      "| AdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.009s\n",
      "| AdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.007s\n",
      "| AdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.010s\n",
      "| AdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.010s\n",
      "| AdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.010s\n",
      "| AdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.009s\n",
      "| AdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.009s\n",
      "| AdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.009s\n",
      "| AdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.009s\n",
      "| AdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.010s\n",
      "| AdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.008s\n",
      "| AdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.008s\n",
      "| AdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.009s\n",
      "| AdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.010s\n",
      "| AdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.010s\n",
      "| AdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.008s\n",
      "| AdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.009s\n",
      "| AdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'softmax', 35, [0.3002028369758482]]\n",
      "AdaGrad\n",
      "sigmoid\n",
      "1000\n",
      "---------------------------------\n",
      "Run id: BC0CU2\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.108s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.014s\n",
      "| AdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.2985 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.016s\n",
      "| AdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.3256 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.014s\n",
      "| AdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3301 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.014s\n",
      "| AdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.3312 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.012s\n",
      "| AdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3315 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.014s\n",
      "| AdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.016s\n",
      "| AdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.014s\n",
      "| AdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.015s\n",
      "| AdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.015s\n",
      "| AdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.014s\n",
      "| AdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.013s\n",
      "| AdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.015s\n",
      "| AdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.013s\n",
      "| AdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.013s\n",
      "| AdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.013s\n",
      "| AdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.014s\n",
      "| AdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.013s\n",
      "| AdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.013s\n",
      "| AdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.015s\n",
      "| AdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.014s\n",
      "| AdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.013s\n",
      "| AdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.013s\n",
      "| AdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.013s\n",
      "| AdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.012s\n",
      "| AdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.014s\n",
      "| AdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.014s\n",
      "| AdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.016s\n",
      "| AdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.016s\n",
      "| AdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'sigmoid', 1000, [0.3002028369758482]]\n",
      "AdaGrad\n",
      "sigmoid\n",
      "100\n",
      "---------------------------------\n",
      "Run id: NUVSYU\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.111s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.006s\n",
      "| AdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.2985 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.008s\n",
      "| AdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.3256 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.008s\n",
      "| AdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3301 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.008s\n",
      "| AdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.3312 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.009s\n",
      "| AdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3315 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.008s\n",
      "| AdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.008s\n",
      "| AdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.008s\n",
      "| AdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.008s\n",
      "| AdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.008s\n",
      "| AdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.009s\n",
      "| AdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.009s\n",
      "| AdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.008s\n",
      "| AdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.009s\n",
      "| AdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.008s\n",
      "| AdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.009s\n",
      "| AdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.008s\n",
      "| AdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.009s\n",
      "| AdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.008s\n",
      "| AdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.008s\n",
      "| AdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.009s\n",
      "| AdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.008s\n",
      "| AdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.008s\n",
      "| AdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.008s\n",
      "| AdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.008s\n",
      "| AdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.008s\n",
      "| AdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.009s\n",
      "| AdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.008s\n",
      "| AdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.008s\n",
      "| AdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'sigmoid', 100, [0.3002028369758482]]\n",
      "AdaGrad\n",
      "sigmoid\n",
      "35\n",
      "---------------------------------\n",
      "Run id: K6F3RE\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.103s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3646 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.007s\n",
      "| AdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.2819 | val_loss: 0.00000 - val_binary_acc: 0.3646 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.007s\n",
      "| AdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.3076 | val_loss: 0.00000 - val_binary_acc: 0.3646 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.008s\n",
      "| AdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3118 | val_loss: 0.00000 - val_binary_acc: 0.3646 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.008s\n",
      "| AdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.3128 | val_loss: 0.00000 - val_binary_acc: 0.3646 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.008s\n",
      "| AdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3131 | val_loss: 0.00000 - val_binary_acc: 0.3646 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.008s\n",
      "| AdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.3132 | val_loss: 0.00000 - val_binary_acc: 0.3646 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.007s\n",
      "| AdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3132 | val_loss: 0.00000 - val_binary_acc: 0.3646 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.007s\n",
      "| AdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.3132 | val_loss: 0.00000 - val_binary_acc: 0.3646 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.007s\n",
      "| AdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3132 | val_loss: 0.00000 - val_binary_acc: 0.3646 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.009s\n",
      "| AdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.3132 | val_loss: 0.00000 - val_binary_acc: 0.3646 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.007s\n",
      "| AdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3133 | val_loss: 0.00000 - val_binary_acc: 0.3646 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.007s\n",
      "| AdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.3133 | val_loss: 0.00000 - val_binary_acc: 0.3646 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.007s\n",
      "| AdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3133 | val_loss: 0.00000 - val_binary_acc: 0.3646 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.007s\n",
      "| AdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.3133 | val_loss: 0.00000 - val_binary_acc: 0.3646 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.006s\n",
      "| AdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3133 | val_loss: 0.00000 - val_binary_acc: 0.3646 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.008s\n",
      "| AdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.3133 | val_loss: 0.00000 - val_binary_acc: 0.3646 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.008s\n",
      "| AdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3133 | val_loss: 0.00000 - val_binary_acc: 0.3646 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.008s\n",
      "| AdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.3133 | val_loss: 0.00000 - val_binary_acc: 0.3646 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.009s\n",
      "| AdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3133 | val_loss: 0.00000 - val_binary_acc: 0.3646 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.008s\n",
      "| AdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.3133 | val_loss: 0.00000 - val_binary_acc: 0.3646 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.008s\n",
      "| AdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3133 | val_loss: 0.00000 - val_binary_acc: 0.3646 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.007s\n",
      "| AdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.3133 | val_loss: 0.00000 - val_binary_acc: 0.3646 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.008s\n",
      "| AdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3133 | val_loss: 0.00000 - val_binary_acc: 0.3646 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.007s\n",
      "| AdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3133 | val_loss: 0.00000 - val_binary_acc: 0.3646 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.008s\n",
      "| AdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3133 | val_loss: 0.00000 - val_binary_acc: 0.3646 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.007s\n",
      "| AdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.3133 | val_loss: 0.00000 - val_binary_acc: 0.3646 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.008s\n",
      "| AdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3133 | val_loss: 0.00000 - val_binary_acc: 0.3646 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.013s\n",
      "| AdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.3133 | val_loss: 0.00000 - val_binary_acc: 0.3646 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.007s\n",
      "| AdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3133 | val_loss: 0.00000 - val_binary_acc: 0.3646 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'sigmoid', 35, [0.3002028369758482]]\n",
      "AdaGrad\n",
      "tanh\n",
      "1000\n",
      "---------------------------------\n",
      "Run id: ZMBSP8\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.124s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.014s\n",
      "| AdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.015s\n",
      "| AdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.2661 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.016s\n",
      "| AdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.2563 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.013s\n",
      "| AdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.2540 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.016s\n",
      "| AdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3202 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.013s\n",
      "| AdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.2799 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.016s\n",
      "| AdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3354 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.014s\n",
      "| AdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.2918 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.015s\n",
      "| AdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3136 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.013s\n",
      "| AdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.2849 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.015s\n",
      "| AdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.2706 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.012s\n",
      "| AdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.2630 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.013s\n",
      "| AdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.2953 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.013s\n",
      "| AdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.2787 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.015s\n",
      "| AdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3002 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.014s\n",
      "| AdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.2832 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.014s\n",
      "| AdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3079 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.017s\n",
      "| AdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.2896 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.015s\n",
      "| AdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3021 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.014s\n",
      "| AdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.2869 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.016s\n",
      "| AdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3115 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.013s\n",
      "| AdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.2945 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.015s\n",
      "| AdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3142 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.014s\n",
      "| AdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.2975 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.014s\n",
      "| AdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3069 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.014s\n",
      "| AdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.2930 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.013s\n",
      "| AdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3052 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.014s\n",
      "| AdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.2925 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.014s\n",
      "| AdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3043 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'tanh', 1000, [0.25152130083428437]]\n",
      "AdaGrad\n",
      "tanh\n",
      "100\n",
      "---------------------------------\n",
      "Run id: 4PUTIG\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.110s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.007s\n",
      "| AdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.4377 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.008s\n",
      "| AdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.4775 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.009s\n",
      "| AdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.4033 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.008s\n",
      "| AdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.4608 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.009s\n",
      "| AdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.4206 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.009s\n",
      "| AdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.4601 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.008s\n",
      "| AdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.4042 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.007s\n",
      "| AdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.4477 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.008s\n",
      "| AdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.4670 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.009s\n",
      "| AdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.4221 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.007s\n",
      "| AdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.4134 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.008s\n",
      "| AdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.4447 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.007s\n",
      "| AdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.4264 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.008s\n",
      "| AdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.4499 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.008s\n",
      "| AdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.4269 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.008s\n",
      "| AdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.4483 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.009s\n",
      "| AdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.4273 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.008s\n",
      "| AdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.4470 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.009s\n",
      "| AdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.4380 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.009s\n",
      "| AdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.4530 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.010s\n",
      "| AdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.4373 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.010s\n",
      "| AdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.4516 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.008s\n",
      "| AdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.4478 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.008s\n",
      "| AdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.4583 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.008s\n",
      "| AdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.4498 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.009s\n",
      "| AdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.4592 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.010s\n",
      "| AdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.4503 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.010s\n",
      "| AdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.4591 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.009s\n",
      "| AdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.4511 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'tanh', 100, [0.4807302201011843]]\n",
      "AdaGrad\n",
      "tanh\n",
      "35\n",
      "---------------------------------\n",
      "Run id: 3VMJCM\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.130s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.006s\n",
      "| AdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.3053 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.008s\n",
      "| AdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.2750 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.008s\n",
      "| AdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3436 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.007s\n",
      "| AdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.2914 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.007s\n",
      "| AdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.2989 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.008s\n",
      "| AdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.2805 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.007s\n",
      "| AdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.2736 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.007s\n",
      "| AdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.2708 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.007s\n",
      "| AdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.2904 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.006s\n",
      "| AdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.2799 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.007s\n",
      "| AdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3055 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.008s\n",
      "| AdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.2895 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.008s\n",
      "| AdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.008s\n",
      "| AdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.2964 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.007s\n",
      "| AdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3286 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.008s\n",
      "| AdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.3069 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.008s\n",
      "| AdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.2935 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.007s\n",
      "| AdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.2851 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.008s\n",
      "| AdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3015 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.008s\n",
      "| AdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.2912 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.008s\n",
      "| AdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3113 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.007s\n",
      "| AdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.2988 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.008s\n",
      "| AdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3189 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.008s\n",
      "| AdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3051 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.008s\n",
      "| AdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.2953 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.008s\n",
      "| AdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.3136 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.008s\n",
      "| AdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3210 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.008s\n",
      "| AdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.3082 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.007s\n",
      "| AdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3196 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'tanh', 35, [0.2758620684819096]]\n",
      "AdaGrad\n",
      "prelu\n",
      "1000\n",
      "---------------------------------\n",
      "Run id: SH3KIC\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.153s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.023s\n",
      "| AdaGrad | epoch: 002 | loss: nan - binary_acc: 0.3139 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.046s\n",
      "| AdaGrad | epoch: 003 | loss: nan - binary_acc: 0.4192 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.030s\n",
      "| AdaGrad | epoch: 004 | loss: nan - binary_acc: 0.4368 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.024s\n",
      "| AdaGrad | epoch: 005 | loss: nan - binary_acc: 0.4408 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.025s\n",
      "| AdaGrad | epoch: 006 | loss: nan - binary_acc: 0.4420 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.025s\n",
      "| AdaGrad | epoch: 007 | loss: nan - binary_acc: 0.4424 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.025s\n",
      "| AdaGrad | epoch: 008 | loss: nan - binary_acc: 0.4425 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.029s\n",
      "| AdaGrad | epoch: 009 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.024s\n",
      "| AdaGrad | epoch: 010 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.026s\n",
      "| AdaGrad | epoch: 011 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.029s\n",
      "| AdaGrad | epoch: 012 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.026s\n",
      "| AdaGrad | epoch: 013 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.025s\n",
      "| AdaGrad | epoch: 014 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.030s\n",
      "| AdaGrad | epoch: 015 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.041s\n",
      "| AdaGrad | epoch: 016 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.025s\n",
      "| AdaGrad | epoch: 017 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.025s\n",
      "| AdaGrad | epoch: 018 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.030s\n",
      "| AdaGrad | epoch: 019 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.029s\n",
      "| AdaGrad | epoch: 020 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.030s\n",
      "| AdaGrad | epoch: 021 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.026s\n",
      "| AdaGrad | epoch: 022 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.029s\n",
      "| AdaGrad | epoch: 023 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.027s\n",
      "| AdaGrad | epoch: 024 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.027s\n",
      "| AdaGrad | epoch: 025 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.029s\n",
      "| AdaGrad | epoch: 026 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.030s\n",
      "| AdaGrad | epoch: 027 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.028s\n",
      "| AdaGrad | epoch: 028 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.029s\n",
      "| AdaGrad | epoch: 029 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.028s\n",
      "| AdaGrad | epoch: 030 | loss: nan - binary_acc: 0.4426 | val_loss: nan - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'prelu', 1000, [0.45436105404132276]]\n",
      "AdaGrad\n",
      "prelu\n",
      "100\n",
      "---------------------------------\n",
      "Run id: UWX720\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.128s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 002 | loss: nan - binary_acc: 0.2391 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 003 | loss: nan - binary_acc: 0.4020 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 004 | loss: nan - binary_acc: 0.4291 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| AdaGrad | epoch: 005 | loss: nan - binary_acc: 0.4354 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 006 | loss: nan - binary_acc: 0.4372 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 007 | loss: nan - binary_acc: 0.4378 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 008 | loss: nan - binary_acc: 0.4380 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 009 | loss: nan - binary_acc: 0.4381 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 010 | loss: nan - binary_acc: 0.4381 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 011 | loss: nan - binary_acc: 0.4382 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 012 | loss: nan - binary_acc: 0.4382 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 013 | loss: nan - binary_acc: 0.4382 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 014 | loss: nan - binary_acc: 0.4382 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 015 | loss: nan - binary_acc: 0.4382 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaGrad | epoch: 016 | loss: nan - binary_acc: 0.4382 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 017 | loss: nan - binary_acc: 0.4382 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 018 | loss: nan - binary_acc: 0.4382 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 019 | loss: nan - binary_acc: 0.4382 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaGrad | epoch: 020 | loss: nan - binary_acc: 0.4382 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 021 | loss: nan - binary_acc: 0.4382 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 022 | loss: nan - binary_acc: 0.4382 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 023 | loss: nan - binary_acc: 0.4382 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 024 | loss: nan - binary_acc: 0.4382 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 025 | loss: nan - binary_acc: 0.4382 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| AdaGrad | epoch: 026 | loss: nan - binary_acc: 0.4382 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 027 | loss: nan - binary_acc: 0.4382 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 028 | loss: nan - binary_acc: 0.4382 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 029 | loss: nan - binary_acc: 0.4382 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 030 | loss: nan - binary_acc: 0.4382 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'prelu', 100, [0.45436105404132276]]\n",
      "AdaGrad\n",
      "prelu\n",
      "35\n",
      "---------------------------------\n",
      "Run id: HH6XN6\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.130s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.006s\n",
      "| AdaGrad | epoch: 002 | loss: nan - binary_acc: 0.3938 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 003 | loss: nan - binary_acc: 0.4291 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 004 | loss: nan - binary_acc: 0.4349 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaGrad | epoch: 005 | loss: nan - binary_acc: 0.4363 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaGrad | epoch: 006 | loss: nan - binary_acc: 0.4367 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaGrad | epoch: 007 | loss: nan - binary_acc: 0.4368 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 008 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 009 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 010 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 011 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 012 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 013 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 014 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaGrad | epoch: 015 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 016 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 017 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 018 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 019 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 020 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 021 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 022 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 023 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 024 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 025 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 026 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 027 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 028 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 029 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 030 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'prelu', 35, [0.45436105404132276]]\n",
      "ProximalAdaGrad\n",
      "relu\n",
      "1000\n",
      "---------------------------------\n",
      "Run id: 10P9N8\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.088s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: nan - binary_acc: 0.3898 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.015s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: nan - binary_acc: 0.4315 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.014s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: nan - binary_acc: 0.4384 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: nan - binary_acc: 0.4400 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.014s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: nan - binary_acc: 0.4405 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: nan - binary_acc: 0.4406 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.014s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.014s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.014s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.014s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.014s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.015s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.015s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'relu', 1000, [0.45436105404132276]]\n",
      "ProximalAdaGrad\n",
      "relu\n",
      "100\n",
      "---------------------------------\n",
      "Run id: S17HOT\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.108s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: nan - binary_acc: 0.3453 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: nan - binary_acc: 0.4218 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: nan - binary_acc: 0.4346 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: nan - binary_acc: 0.4375 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: nan - binary_acc: 0.4383 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: nan - binary_acc: 0.4386 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: nan - binary_acc: 0.4387 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.006s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'relu', 100, [0.45436105404132276]]\n",
      "ProximalAdaGrad\n",
      "relu\n",
      "35\n",
      "---------------------------------\n",
      "Run id: YBKV84\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.110s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.006s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: nan - binary_acc: 0.3538 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: nan - binary_acc: 0.4234 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: nan - binary_acc: 0.4349 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: nan - binary_acc: 0.4376 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: nan - binary_acc: 0.4384 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: nan - binary_acc: 0.4386 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: nan - binary_acc: 0.4387 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.006s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'relu', 35, [0.45436105404132276]]\n",
      "ProximalAdaGrad\n",
      "linear\n",
      "1000\n",
      "---------------------------------\n",
      "Run id: 0QB69T\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.093s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.5089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.3504 | val_loss: 0.00000 - val_binary_acc: 0.5089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.4648 | val_loss: 0.00000 - val_binary_acc: 0.5089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.4106 | val_loss: 0.00000 - val_binary_acc: 0.5089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.4657 | val_loss: 0.00000 - val_binary_acc: 0.5089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.4121 | val_loss: 0.00000 - val_binary_acc: 0.5089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.4590 | val_loss: 0.00000 - val_binary_acc: 0.5089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.013s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.4280 | val_loss: 0.00000 - val_binary_acc: 0.5089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.4609 | val_loss: 0.00000 - val_binary_acc: 0.5089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.013s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.4267 | val_loss: 0.00000 - val_binary_acc: 0.5089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.4568 | val_loss: 0.00000 - val_binary_acc: 0.5089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.4299 | val_loss: 0.00000 - val_binary_acc: 0.5089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.4557 | val_loss: 0.00000 - val_binary_acc: 0.5089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.4234 | val_loss: 0.00000 - val_binary_acc: 0.5089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.4495 | val_loss: 0.00000 - val_binary_acc: 0.5089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.4476 | val_loss: 0.00000 - val_binary_acc: 0.5089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.4629 | val_loss: 0.00000 - val_binary_acc: 0.5089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.4583 | val_loss: 0.00000 - val_binary_acc: 0.5089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.4689 | val_loss: 0.00000 - val_binary_acc: 0.5089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.4644 | val_loss: 0.00000 - val_binary_acc: 0.5089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.4724 | val_loss: 0.00000 - val_binary_acc: 0.5089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.4652 | val_loss: 0.00000 - val_binary_acc: 0.5089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.4724 | val_loss: 0.00000 - val_binary_acc: 0.5089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.013s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.4664 | val_loss: 0.00000 - val_binary_acc: 0.5089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.4728 | val_loss: 0.00000 - val_binary_acc: 0.5089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.4618 | val_loss: 0.00000 - val_binary_acc: 0.5089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.4691 | val_loss: 0.00000 - val_binary_acc: 0.5089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.013s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.4601 | val_loss: 0.00000 - val_binary_acc: 0.5089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.4674 | val_loss: 0.00000 - val_binary_acc: 0.5089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.4594 | val_loss: 0.00000 - val_binary_acc: 0.5089 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'linear', 1000, [0.4665314382882921]]\n",
      "ProximalAdaGrad\n",
      "linear\n",
      "100\n",
      "---------------------------------\n",
      "Run id: UP6TW2\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.083s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.3447 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.006s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.3169 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3123 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.3639 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3798 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.3384 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3810 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.3438 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3678 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.3408 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3584 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.3382 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3332 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.3246 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3382 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3384 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.3294 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3403 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.3313 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3434 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.3341 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3437 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3349 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3434 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.3352 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3427 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.3351 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3401 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'linear', 100, [0.3225152144930184]]\n",
      "ProximalAdaGrad\n",
      "linear\n",
      "35\n",
      "---------------------------------\n",
      "Run id: HLIM75\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.104s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.006s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.3607 | val_loss: 0.00000 - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.4786 | val_loss: 0.00000 - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.006s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.4982 | val_loss: 0.00000 - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.006s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.5027 | val_loss: 0.00000 - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.4331 | val_loss: 0.00000 - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.4761 | val_loss: 0.00000 - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.4252 | val_loss: 0.00000 - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.4673 | val_loss: 0.00000 - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.4860 | val_loss: 0.00000 - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.4949 | val_loss: 0.00000 - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.4431 | val_loss: 0.00000 - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.4695 | val_loss: 0.00000 - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.4489 | val_loss: 0.00000 - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.4708 | val_loss: 0.00000 - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.4835 | val_loss: 0.00000 - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.4912 | val_loss: 0.00000 - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.4581 | val_loss: 0.00000 - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.4737 | val_loss: 0.00000 - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.4535 | val_loss: 0.00000 - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.4694 | val_loss: 0.00000 - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.4636 | val_loss: 0.00000 - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.4756 | val_loss: 0.00000 - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.4643 | val_loss: 0.00000 - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.4754 | val_loss: 0.00000 - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.4640 | val_loss: 0.00000 - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.4745 | val_loss: 0.00000 - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.4727 | val_loss: 0.00000 - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.4805 | val_loss: 0.00000 - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.4744 | val_loss: 0.00000 - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'linear', 35, [0.4807302201011843]]\n",
      "ProximalAdaGrad\n",
      "softmax\n",
      "1000\n",
      "---------------------------------\n",
      "Run id: F85XEA\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.138s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.017s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.2928 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.017s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.3194 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.020s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3238 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.018s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.3248 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.018s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3251 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.016s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.3252 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.018s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.019s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.018s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.018s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.017s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.017s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.018s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.017s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.018s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.018s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.018s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.018s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.020s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.020s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.018s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.019s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.017s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.017s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.017s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.017s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.018s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.017s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.018s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'softmax', 1000, [0.3002028369758482]]\n",
      "ProximalAdaGrad\n",
      "softmax\n",
      "100\n",
      "---------------------------------\n",
      "Run id: 20536C\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.139s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.2962 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.3231 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3276 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.3286 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3289 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.3290 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3291 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.3291 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3291 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.3291 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3291 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.3291 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3291 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.3291 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3291 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.3291 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3291 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.3291 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3291 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.3291 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3291 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.3291 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3291 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3291 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3291 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.3291 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3291 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.3291 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3291 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'softmax', 100, [0.3002028369758482]]\n",
      "ProximalAdaGrad\n",
      "softmax\n",
      "35\n",
      "---------------------------------\n",
      "Run id: BXIE84\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.100s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.2831 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.3088 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3131 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.3141 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3144 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.006s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'softmax', 35, [0.3002028369758482]]\n",
      "ProximalAdaGrad\n",
      "sigmoid\n",
      "1000\n",
      "---------------------------------\n",
      "Run id: VHTK8O\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.107s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.015s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.2911 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.013s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.3175 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.014s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3219 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.014s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.3229 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.014s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3232 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.014s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.3233 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.014s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.017s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.013s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.013s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.014s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.014s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.013s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.014s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.014s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.014s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.014s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.013s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.013s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.016s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.014s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.014s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.014s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.014s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.013s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'sigmoid', 1000, [0.3002028369758482]]\n",
      "ProximalAdaGrad\n",
      "sigmoid\n",
      "100\n",
      "---------------------------------\n",
      "Run id: S2NEAA\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.108s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.2962 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.3231 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3276 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.3286 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3289 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.3290 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3291 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.3291 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3291 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.3291 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3291 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.3291 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3291 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.3291 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3291 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.3291 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3291 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.3291 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3291 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.3291 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3291 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.3291 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3291 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3291 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3291 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.3291 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3291 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.3291 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3291 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'sigmoid', 100, [0.3002028369758482]]\n",
      "ProximalAdaGrad\n",
      "sigmoid\n",
      "35\n",
      "---------------------------------\n",
      "Run id: JUH6X1\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.099s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.006s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.2911 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.3175 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.006s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3219 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.3229 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3232 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.3233 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.013s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'sigmoid', 35, [0.3002028369758482]]\n",
      "ProximalAdaGrad\n",
      "tanh\n",
      "1000\n",
      "---------------------------------\n",
      "Run id: 2WAPBG\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.100s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.017s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.3613 | val_loss: 0.00000 - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.015s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.4807 | val_loss: 0.00000 - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.014s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.5007 | val_loss: 0.00000 - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.014s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.5052 | val_loss: 0.00000 - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.013s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.5066 | val_loss: 0.00000 - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.014s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.5070 | val_loss: 0.00000 - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.016s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.4562 | val_loss: 0.00000 - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.014s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.4832 | val_loss: 0.00000 - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.015s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.4490 | val_loss: 0.00000 - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.014s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.4766 | val_loss: 0.00000 - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.014s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.4516 | val_loss: 0.00000 - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.014s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.4755 | val_loss: 0.00000 - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.014s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.4714 | val_loss: 0.00000 - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.013s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.4854 | val_loss: 0.00000 - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.014s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.4829 | val_loss: 0.00000 - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.013s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.4917 | val_loss: 0.00000 - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.013s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.4686 | val_loss: 0.00000 - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.014s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.4815 | val_loss: 0.00000 - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.013s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.4659 | val_loss: 0.00000 - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.015s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.4788 | val_loss: 0.00000 - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.014s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.4624 | val_loss: 0.00000 - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.013s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.4754 | val_loss: 0.00000 - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.014s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.4639 | val_loss: 0.00000 - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.013s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.4757 | val_loss: 0.00000 - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.014s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.4644 | val_loss: 0.00000 - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.014s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.4755 | val_loss: 0.00000 - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.014s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.4657 | val_loss: 0.00000 - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.015s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.4758 | val_loss: 0.00000 - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.016s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.4682 | val_loss: 0.00000 - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'tanh', 1000, [0.49087221022793537]]\n",
      "ProximalAdaGrad\n",
      "tanh\n",
      "100\n",
      "---------------------------------\n",
      "Run id: 27K5RC\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.107s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.3379 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.2731 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3265 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.2796 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3090 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.2788 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.2932 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.2749 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.2808 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.2703 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.2896 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.2764 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3143 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.2926 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.2799 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.2723 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.2676 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.2646 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3051 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.2907 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3169 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.3000 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3201 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3034 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3206 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.3047 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3081 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.2961 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3062 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'tanh', 100, [0.255578090525544]]\n",
      "ProximalAdaGrad\n",
      "tanh\n",
      "35\n",
      "---------------------------------\n",
      "Run id: 0U5FI7\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.102s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.3173 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.2730 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3341 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.2850 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3411 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.2943 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3396 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.2991 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3369 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.3020 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.2987 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3267 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.006s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.3018 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3135 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.2954 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3077 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.006s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.2929 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3127 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.2973 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3070 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.2943 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3048 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.2934 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3017 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.2918 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3030 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.2933 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3004 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'tanh', 35, [0.24340770942202447]]\n",
      "ProximalAdaGrad\n",
      "prelu\n",
      "1000\n",
      "---------------------------------\n",
      "Run id: 4N8S44\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.143s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.023s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: nan - binary_acc: 0.3344 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.024s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: nan - binary_acc: 0.4240 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.026s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: nan - binary_acc: 0.4389 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.024s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: nan - binary_acc: 0.4424 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.027s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: nan - binary_acc: 0.4433 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.025s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: nan - binary_acc: 0.4437 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.028s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: nan - binary_acc: 0.4438 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.026s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: nan - binary_acc: 0.4438 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.025s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.029s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.025s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.027s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.026s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.025s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.026s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.025s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.026s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.046s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.029s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.025s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.025s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.025s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.028s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.028s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.027s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.025s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.024s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.026s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.026s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'prelu', 1000, [0.45436105404132276]]\n",
      "ProximalAdaGrad\n",
      "prelu\n",
      "100\n",
      "---------------------------------\n",
      "Run id: WZWHVF\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.127s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: nan - binary_acc: 0.3185 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: nan - binary_acc: 0.4138 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: nan - binary_acc: 0.4297 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: nan - binary_acc: 0.4334 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: nan - binary_acc: 0.4344 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: nan - binary_acc: 0.4348 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: nan - binary_acc: 0.4349 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: nan - binary_acc: 0.4350 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: nan - binary_acc: 0.4350 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: nan - binary_acc: 0.4350 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: nan - binary_acc: 0.4350 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: nan - binary_acc: 0.4350 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: nan - binary_acc: 0.4350 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: nan - binary_acc: 0.4350 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: nan - binary_acc: 0.4350 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: nan - binary_acc: 0.4350 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: nan - binary_acc: 0.4350 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: nan - binary_acc: 0.4350 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: nan - binary_acc: 0.4350 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: nan - binary_acc: 0.4350 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: nan - binary_acc: 0.4350 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: nan - binary_acc: 0.4350 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: nan - binary_acc: 0.4350 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: nan - binary_acc: 0.4350 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: nan - binary_acc: 0.4350 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: nan - binary_acc: 0.4350 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: nan - binary_acc: 0.4350 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: nan - binary_acc: 0.4350 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: nan - binary_acc: 0.4350 | val_loss: nan - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'prelu', 100, [0.45436105404132276]]\n",
      "ProximalAdaGrad\n",
      "prelu\n",
      "35\n",
      "---------------------------------\n",
      "Run id: HKAJNF\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.135s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: nan - binary_acc: 0.3658 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: nan - binary_acc: 0.4271 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: nan - binary_acc: 0.4373 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: nan - binary_acc: 0.4397 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: nan - binary_acc: 0.4403 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: nan - binary_acc: 0.4406 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: nan - binary_acc: 0.4406 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'prelu', 35, [0.45436105404132276]]\n"
     ]
    }
   ],
   "source": [
    "#\"ProximalAdaGrad\",\"sgd\",'RMSProp','AdaGrad',\"ProximalAdaGrad\" \"momentum\",\"momentum\",'RMSProp' \" \"momentum\"\n",
    "optimizadores=[\"AdaDelta\",'RMSProp','AdaGrad',\"ProximalAdaGrad\"]\n",
    "#\n",
    "tf.reset_default_graph()\n",
    "activator=[  \"relu\", \"linear\" ,\"softmax\" ,'sigmoid','tanh','prelu']\n",
    "tamanio=[[1000,1000,1],[100,100],[35,35]]\n",
    "#t#amanio=[[64,64,30,10]]\n",
    "#sgd = tflearn.SGD(learning_rate=0.01,lr_decay=0.96 , decay_step=500)\n",
    "resultados=[]\n",
    "for o in optimizadores:\n",
    "    for a in activator:\n",
    "        for t in tamanio:\n",
    "            \n",
    "            print(o)\n",
    "            print(a)\n",
    "            print(str(t[0]))\n",
    "            tf.reset_default_graph()\n",
    "            net = tflearn.input_data(shape=[None, 6])\n",
    "            net = tflearn.fully_connected(net,t[0], activation=a,regularizer=\"L2\", weights_init='normal', weight_decay=0.001)\n",
    "            #net = tflearn.fully_connected(net,t[1], activation=a,regularizer=\"L2\", weights_init='normal', weight_decay=0.001)\n",
    "\n",
    "            net = tflearn.fully_connected(net,1, activation=a,regularizer=\"L2\", weights_init='normal', weight_decay=0.001)\n",
    "            net = tflearn.regression(net, optimizer=o,loss=\"categorical_crossentropy\",metric=\"accuracy\")\n",
    "            model = tflearn.DNN(net)\n",
    "            model.fit(entrenamiento, entrenamiento_lbl,show_metric=True,validation_set=0.2,n_epoch=30,batch_size=len(entrenamiento))\n",
    "            accu=model.evaluate(validacion, validacion_lbl)\n",
    "            \n",
    "            #print(accu)\n",
    "            config=[o,a,t[0],accu]\n",
    "            print(config)\n",
    "            resultados.append(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados=pd.DataFrame(resultados)\n",
    "a=resultados[3]\n",
    "accu=[i[0] for i in a]\n",
    "resultados[\"accu\"]=accu\n",
    "\n",
    "resultados=resultados.sort_values(by=\"accu\",ascending=False)\n",
    "resultados.to_csv(\"resultados_rna_ECI_b.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RNA a tres pacas pocas neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaDelta\n",
      "relu\n",
      "10\n",
      "---------------------------------\n",
      "Run id: AAK656\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.585s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaDelta | epoch: 002 | loss: nan - binary_acc: 0.2928 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 003 | loss: nan - binary_acc: 0.4159 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 004 | loss: nan - binary_acc: 0.4364 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaDelta | epoch: 005 | loss: nan - binary_acc: 0.4411 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 006 | loss: nan - binary_acc: 0.4425 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 007 | loss: nan - binary_acc: 0.4429 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 008 | loss: nan - binary_acc: 0.4431 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 009 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaDelta | epoch: 010 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 011 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 012 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 013 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 014 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 015 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 016 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 017 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 018 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 019 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 020 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 021 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 022 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 023 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 024 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 025 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 026 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 027 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 028 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 029 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 030 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'relu', 10, [0.45436105404132276]]\n",
      "AdaDelta\n",
      "relu\n",
      "5\n",
      "---------------------------------\n",
      "Run id: QZKPZS\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.126s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.006s\n",
      "| AdaDelta | epoch: 002 | loss: nan - binary_acc: 0.2916 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 003 | loss: nan - binary_acc: 0.4141 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaDelta | epoch: 004 | loss: nan - binary_acc: 0.4345 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaDelta | epoch: 005 | loss: nan - binary_acc: 0.4393 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 006 | loss: nan - binary_acc: 0.4406 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 007 | loss: nan - binary_acc: 0.4410 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 008 | loss: nan - binary_acc: 0.4412 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 009 | loss: nan - binary_acc: 0.4413 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 010 | loss: nan - binary_acc: 0.4413 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 011 | loss: nan - binary_acc: 0.4413 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 012 | loss: nan - binary_acc: 0.4413 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 013 | loss: nan - binary_acc: 0.4413 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 014 | loss: nan - binary_acc: 0.4413 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaDelta | epoch: 015 | loss: nan - binary_acc: 0.4413 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 016 | loss: nan - binary_acc: 0.4413 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 017 | loss: nan - binary_acc: 0.4413 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 018 | loss: nan - binary_acc: 0.4413 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaDelta | epoch: 019 | loss: nan - binary_acc: 0.4413 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 020 | loss: nan - binary_acc: 0.4413 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaDelta | epoch: 021 | loss: nan - binary_acc: 0.4413 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaDelta | epoch: 022 | loss: nan - binary_acc: 0.4413 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 023 | loss: nan - binary_acc: 0.4413 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 024 | loss: nan - binary_acc: 0.4413 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaDelta | epoch: 025 | loss: nan - binary_acc: 0.4413 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 026 | loss: nan - binary_acc: 0.4413 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaDelta | epoch: 027 | loss: nan - binary_acc: 0.4413 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 028 | loss: nan - binary_acc: 0.4413 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.006s\n",
      "| AdaDelta | epoch: 029 | loss: nan - binary_acc: 0.4413 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 030 | loss: nan - binary_acc: 0.4413 | val_loss: nan - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'relu', 5, [0.45436105404132276]]\n",
      "AdaDelta\n",
      "relu\n",
      "35\n",
      "---------------------------------\n",
      "Run id: PY3O18\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.130s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 002 | loss: nan - binary_acc: 0.2905 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 003 | loss: nan - binary_acc: 0.4155 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 004 | loss: nan - binary_acc: 0.4363 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 005 | loss: nan - binary_acc: 0.4411 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 006 | loss: nan - binary_acc: 0.4425 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 007 | loss: nan - binary_acc: 0.4429 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 008 | loss: nan - binary_acc: 0.4431 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 009 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 010 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaDelta | epoch: 011 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 012 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 013 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 014 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 015 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 016 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 017 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 018 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 019 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 020 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 021 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 022 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 023 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 024 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 025 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 026 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 027 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 028 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 029 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| AdaDelta | epoch: 030 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'relu', 35, [0.45436105404132276]]\n",
      "AdaDelta\n",
      "linear\n",
      "10\n",
      "---------------------------------\n",
      "Run id: FKBG70\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.103s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.4785 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.007s\n",
      "| AdaDelta | epoch: 002 | loss: 0.00000 - binary_acc: 0.3555 | val_loss: 0.00000 - val_binary_acc: 0.4810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.008s\n",
      "| AdaDelta | epoch: 003 | loss: 0.00000 - binary_acc: 0.4745 | val_loss: 0.00000 - val_binary_acc: 0.4759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.008s\n",
      "| AdaDelta | epoch: 004 | loss: 0.00000 - binary_acc: 0.4225 | val_loss: 0.00000 - val_binary_acc: 0.4759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.009s\n",
      "| AdaDelta | epoch: 005 | loss: 0.00000 - binary_acc: 0.4751 | val_loss: 0.00000 - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.008s\n",
      "| AdaDelta | epoch: 006 | loss: 0.00000 - binary_acc: 0.4232 | val_loss: 0.00000 - val_binary_acc: 0.4759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.007s\n",
      "| AdaDelta | epoch: 007 | loss: 0.00000 - binary_acc: 0.4683 | val_loss: 0.00000 - val_binary_acc: 0.4759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.007s\n",
      "| AdaDelta | epoch: 008 | loss: 0.00000 - binary_acc: 0.4275 | val_loss: 0.00000 - val_binary_acc: 0.4785 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.008s\n",
      "| AdaDelta | epoch: 009 | loss: 0.00000 - binary_acc: 0.4657 | val_loss: 0.00000 - val_binary_acc: 0.4759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.008s\n",
      "| AdaDelta | epoch: 010 | loss: 0.00000 - binary_acc: 0.4212 | val_loss: 0.00000 - val_binary_acc: 0.4759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.007s\n",
      "| AdaDelta | epoch: 011 | loss: 0.00000 - binary_acc: 0.4596 | val_loss: 0.00000 - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.006s\n",
      "| AdaDelta | epoch: 012 | loss: 0.00000 - binary_acc: 0.4297 | val_loss: 0.00000 - val_binary_acc: 0.4759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.008s\n",
      "| AdaDelta | epoch: 013 | loss: 0.00000 - binary_acc: 0.4616 | val_loss: 0.00000 - val_binary_acc: 0.4759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.008s\n",
      "| AdaDelta | epoch: 014 | loss: 0.00000 - binary_acc: 0.4318 | val_loss: 0.00000 - val_binary_acc: 0.4785 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.007s\n",
      "| AdaDelta | epoch: 015 | loss: 0.00000 - binary_acc: 0.4591 | val_loss: 0.00000 - val_binary_acc: 0.4810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.008s\n",
      "| AdaDelta | epoch: 016 | loss: 0.00000 - binary_acc: 0.4534 | val_loss: 0.00000 - val_binary_acc: 0.4759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.008s\n",
      "| AdaDelta | epoch: 017 | loss: 0.00000 - binary_acc: 0.4701 | val_loss: 0.00000 - val_binary_acc: 0.4785 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.008s\n",
      "| AdaDelta | epoch: 018 | loss: 0.00000 - binary_acc: 0.4527 | val_loss: 0.00000 - val_binary_acc: 0.4861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.007s\n",
      "| AdaDelta | epoch: 019 | loss: 0.00000 - binary_acc: 0.4677 | val_loss: 0.00000 - val_binary_acc: 0.4785 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.008s\n",
      "| AdaDelta | epoch: 020 | loss: 0.00000 - binary_acc: 0.4503 | val_loss: 0.00000 - val_binary_acc: 0.4785 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.008s\n",
      "| AdaDelta | epoch: 021 | loss: 0.00000 - binary_acc: 0.4660 | val_loss: 0.00000 - val_binary_acc: 0.4810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.007s\n",
      "| AdaDelta | epoch: 022 | loss: 0.00000 - binary_acc: 0.4565 | val_loss: 0.00000 - val_binary_acc: 0.4835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.008s\n",
      "| AdaDelta | epoch: 023 | loss: 0.00000 - binary_acc: 0.4687 | val_loss: 0.00000 - val_binary_acc: 0.4937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.008s\n",
      "| AdaDelta | epoch: 024 | loss: 0.00000 - binary_acc: 0.4613 | val_loss: 0.00000 - val_binary_acc: 0.4937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.008s\n",
      "| AdaDelta | epoch: 025 | loss: 0.00000 - binary_acc: 0.4713 | val_loss: 0.00000 - val_binary_acc: 0.4937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.007s\n",
      "| AdaDelta | epoch: 026 | loss: 0.00000 - binary_acc: 0.4593 | val_loss: 0.00000 - val_binary_acc: 0.4886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.008s\n",
      "| AdaDelta | epoch: 027 | loss: 0.00000 - binary_acc: 0.4692 | val_loss: 0.00000 - val_binary_acc: 0.4937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.008s\n",
      "| AdaDelta | epoch: 028 | loss: 0.00000 - binary_acc: 0.4607 | val_loss: 0.00000 - val_binary_acc: 0.4810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.007s\n",
      "| AdaDelta | epoch: 029 | loss: 0.00000 - binary_acc: 0.4697 | val_loss: 0.00000 - val_binary_acc: 0.4861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.007s\n",
      "| AdaDelta | epoch: 030 | loss: 0.00000 - binary_acc: 0.4646 | val_loss: 0.00000 - val_binary_acc: 0.4861 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'linear', 10, [0.4827586231076935]]\n",
      "AdaDelta\n",
      "linear\n",
      "5\n",
      "---------------------------------\n",
      "Run id: QMLPI9\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.111s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.2684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.006s\n",
      "| AdaDelta | epoch: 002 | loss: 0.00000 - binary_acc: 0.3082 | val_loss: 0.00000 - val_binary_acc: 0.2987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.007s\n",
      "| AdaDelta | epoch: 003 | loss: 0.00000 - binary_acc: 0.2931 | val_loss: 0.00000 - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.008s\n",
      "| AdaDelta | epoch: 004 | loss: 0.00000 - binary_acc: 0.2730 | val_loss: 0.00000 - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.007s\n",
      "| AdaDelta | epoch: 005 | loss: 0.00000 - binary_acc: 0.3755 | val_loss: 0.00000 - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.007s\n",
      "| AdaDelta | epoch: 006 | loss: 0.00000 - binary_acc: 0.3983 | val_loss: 0.00000 - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.008s\n",
      "| AdaDelta | epoch: 007 | loss: 0.00000 - binary_acc: 0.4123 | val_loss: 0.00000 - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.007s\n",
      "| AdaDelta | epoch: 008 | loss: 0.00000 - binary_acc: 0.4276 | val_loss: 0.00000 - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.007s\n",
      "| AdaDelta | epoch: 009 | loss: 0.00000 - binary_acc: 0.4349 | val_loss: 0.00000 - val_binary_acc: 0.4051 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.007s\n",
      "| AdaDelta | epoch: 010 | loss: 0.00000 - binary_acc: 0.4375 | val_loss: 0.00000 - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.007s\n",
      "| AdaDelta | epoch: 011 | loss: 0.00000 - binary_acc: 0.4234 | val_loss: 0.00000 - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.008s\n",
      "| AdaDelta | epoch: 012 | loss: 0.00000 - binary_acc: 0.4318 | val_loss: 0.00000 - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.008s\n",
      "| AdaDelta | epoch: 013 | loss: 0.00000 - binary_acc: 0.4361 | val_loss: 0.00000 - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.007s\n",
      "| AdaDelta | epoch: 014 | loss: 0.00000 - binary_acc: 0.4385 | val_loss: 0.00000 - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.008s\n",
      "| AdaDelta | epoch: 015 | loss: 0.00000 - binary_acc: 0.4399 | val_loss: 0.00000 - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.007s\n",
      "| AdaDelta | epoch: 016 | loss: 0.00000 - binary_acc: 0.4407 | val_loss: 0.00000 - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.007s\n",
      "| AdaDelta | epoch: 017 | loss: 0.00000 - binary_acc: 0.4411 | val_loss: 0.00000 - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.007s\n",
      "| AdaDelta | epoch: 018 | loss: 0.00000 - binary_acc: 0.4416 | val_loss: 0.00000 - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.006s\n",
      "| AdaDelta | epoch: 019 | loss: 0.00000 - binary_acc: 0.4418 | val_loss: 0.00000 - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.008s\n",
      "| AdaDelta | epoch: 020 | loss: 0.00000 - binary_acc: 0.4418 | val_loss: 0.00000 - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.007s\n",
      "| AdaDelta | epoch: 021 | loss: 0.00000 - binary_acc: 0.4419 | val_loss: 0.00000 - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.007s\n",
      "| AdaDelta | epoch: 022 | loss: 0.00000 - binary_acc: 0.4419 | val_loss: 0.00000 - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.007s\n",
      "| AdaDelta | epoch: 023 | loss: 0.00000 - binary_acc: 0.4419 | val_loss: 0.00000 - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.007s\n",
      "| AdaDelta | epoch: 024 | loss: 0.00000 - binary_acc: 0.4419 | val_loss: 0.00000 - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.008s\n",
      "| AdaDelta | epoch: 025 | loss: 0.00000 - binary_acc: 0.4420 | val_loss: 0.00000 - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.011s\n",
      "| AdaDelta | epoch: 026 | loss: 0.00000 - binary_acc: 0.4420 | val_loss: 0.00000 - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.007s\n",
      "| AdaDelta | epoch: 027 | loss: 0.00000 - binary_acc: 0.4420 | val_loss: 0.00000 - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.008s\n",
      "| AdaDelta | epoch: 028 | loss: 0.00000 - binary_acc: 0.4420 | val_loss: 0.00000 - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.008s\n",
      "| AdaDelta | epoch: 029 | loss: 0.00000 - binary_acc: 0.4420 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.007s\n",
      "| AdaDelta | epoch: 030 | loss: 0.00000 - binary_acc: 0.4415 | val_loss: 0.00000 - val_binary_acc: 0.4304 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'linear', 5, [0.45436105404132276]]\n",
      "AdaDelta\n",
      "linear\n",
      "35\n",
      "---------------------------------\n",
      "Run id: RBM1G1\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.111s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.4835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.008s\n",
      "| AdaDelta | epoch: 002 | loss: 0.00000 - binary_acc: 0.3607 | val_loss: 0.00000 - val_binary_acc: 0.4835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.009s\n",
      "| AdaDelta | epoch: 003 | loss: 0.00000 - binary_acc: 0.4744 | val_loss: 0.00000 - val_binary_acc: 0.4861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.009s\n",
      "| AdaDelta | epoch: 004 | loss: 0.00000 - binary_acc: 0.4173 | val_loss: 0.00000 - val_binary_acc: 0.4886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.009s\n",
      "| AdaDelta | epoch: 005 | loss: 0.00000 - binary_acc: 0.4743 | val_loss: 0.00000 - val_binary_acc: 0.4886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.010s\n",
      "| AdaDelta | epoch: 006 | loss: 0.00000 - binary_acc: 0.4258 | val_loss: 0.00000 - val_binary_acc: 0.4886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.008s\n",
      "| AdaDelta | epoch: 007 | loss: 0.00000 - binary_acc: 0.4698 | val_loss: 0.00000 - val_binary_acc: 0.4861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.009s\n",
      "| AdaDelta | epoch: 008 | loss: 0.00000 - binary_acc: 0.4862 | val_loss: 0.00000 - val_binary_acc: 0.4861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.009s\n",
      "| AdaDelta | epoch: 009 | loss: 0.00000 - binary_acc: 0.4386 | val_loss: 0.00000 - val_binary_acc: 0.4861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.009s\n",
      "| AdaDelta | epoch: 010 | loss: 0.00000 - binary_acc: 0.4219 | val_loss: 0.00000 - val_binary_acc: 0.4861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.009s\n",
      "| AdaDelta | epoch: 011 | loss: 0.00000 - binary_acc: 0.4573 | val_loss: 0.00000 - val_binary_acc: 0.4861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.008s\n",
      "| AdaDelta | epoch: 012 | loss: 0.00000 - binary_acc: 0.4310 | val_loss: 0.00000 - val_binary_acc: 0.4886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.010s\n",
      "| AdaDelta | epoch: 013 | loss: 0.00000 - binary_acc: 0.4593 | val_loss: 0.00000 - val_binary_acc: 0.4861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.009s\n",
      "| AdaDelta | epoch: 014 | loss: 0.00000 - binary_acc: 0.4756 | val_loss: 0.00000 - val_binary_acc: 0.4886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.011s\n",
      "| AdaDelta | epoch: 015 | loss: 0.00000 - binary_acc: 0.4838 | val_loss: 0.00000 - val_binary_acc: 0.4861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.008s\n",
      "| AdaDelta | epoch: 016 | loss: 0.00000 - binary_acc: 0.4443 | val_loss: 0.00000 - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.008s\n",
      "| AdaDelta | epoch: 017 | loss: 0.00000 - binary_acc: 0.4633 | val_loss: 0.00000 - val_binary_acc: 0.4886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.008s\n",
      "| AdaDelta | epoch: 018 | loss: 0.00000 - binary_acc: 0.4753 | val_loss: 0.00000 - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.008s\n",
      "| AdaDelta | epoch: 019 | loss: 0.00000 - binary_acc: 0.4828 | val_loss: 0.00000 - val_binary_acc: 0.4886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.009s\n",
      "| AdaDelta | epoch: 020 | loss: 0.00000 - binary_acc: 0.4605 | val_loss: 0.00000 - val_binary_acc: 0.4886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.009s\n",
      "| AdaDelta | epoch: 021 | loss: 0.00000 - binary_acc: 0.4721 | val_loss: 0.00000 - val_binary_acc: 0.4886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.010s\n",
      "| AdaDelta | epoch: 022 | loss: 0.00000 - binary_acc: 0.4526 | val_loss: 0.00000 - val_binary_acc: 0.4861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.009s\n",
      "| AdaDelta | epoch: 023 | loss: 0.00000 - binary_acc: 0.4659 | val_loss: 0.00000 - val_binary_acc: 0.4886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.009s\n",
      "| AdaDelta | epoch: 024 | loss: 0.00000 - binary_acc: 0.4549 | val_loss: 0.00000 - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.009s\n",
      "| AdaDelta | epoch: 025 | loss: 0.00000 - binary_acc: 0.4666 | val_loss: 0.00000 - val_binary_acc: 0.4861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.009s\n",
      "| AdaDelta | epoch: 026 | loss: 0.00000 - binary_acc: 0.4581 | val_loss: 0.00000 - val_binary_acc: 0.4861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.008s\n",
      "| AdaDelta | epoch: 027 | loss: 0.00000 - binary_acc: 0.4684 | val_loss: 0.00000 - val_binary_acc: 0.4861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.008s\n",
      "| AdaDelta | epoch: 028 | loss: 0.00000 - binary_acc: 0.4606 | val_loss: 0.00000 - val_binary_acc: 0.4861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.009s\n",
      "| AdaDelta | epoch: 029 | loss: 0.00000 - binary_acc: 0.4698 | val_loss: 0.00000 - val_binary_acc: 0.4861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.008s\n",
      "| AdaDelta | epoch: 030 | loss: 0.00000 - binary_acc: 0.4557 | val_loss: 0.00000 - val_binary_acc: 0.4861 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'linear', 35, [0.48681541823953933]]\n",
      "AdaDelta\n",
      "softmax\n",
      "10\n",
      "---------------------------------\n",
      "Run id: ZVISOU\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.112s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.007s\n",
      "| AdaDelta | epoch: 002 | loss: 0.00000 - binary_acc: 0.2951 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.009s\n",
      "| AdaDelta | epoch: 003 | loss: 0.00000 - binary_acc: 0.3219 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.008s\n",
      "| AdaDelta | epoch: 004 | loss: 0.00000 - binary_acc: 0.3263 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.009s\n",
      "| AdaDelta | epoch: 005 | loss: 0.00000 - binary_acc: 0.3274 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.009s\n",
      "| AdaDelta | epoch: 006 | loss: 0.00000 - binary_acc: 0.3277 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.009s\n",
      "| AdaDelta | epoch: 007 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.010s\n",
      "| AdaDelta | epoch: 008 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.011s\n",
      "| AdaDelta | epoch: 009 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.009s\n",
      "| AdaDelta | epoch: 010 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.010s\n",
      "| AdaDelta | epoch: 011 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.010s\n",
      "| AdaDelta | epoch: 012 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.008s\n",
      "| AdaDelta | epoch: 013 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.009s\n",
      "| AdaDelta | epoch: 014 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.010s\n",
      "| AdaDelta | epoch: 015 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.009s\n",
      "| AdaDelta | epoch: 016 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.010s\n",
      "| AdaDelta | epoch: 017 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.008s\n",
      "| AdaDelta | epoch: 018 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.008s\n",
      "| AdaDelta | epoch: 019 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.009s\n",
      "| AdaDelta | epoch: 020 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.009s\n",
      "| AdaDelta | epoch: 021 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.007s\n",
      "| AdaDelta | epoch: 022 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.008s\n",
      "| AdaDelta | epoch: 023 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.009s\n",
      "| AdaDelta | epoch: 024 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.008s\n",
      "| AdaDelta | epoch: 025 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.008s\n",
      "| AdaDelta | epoch: 026 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.010s\n",
      "| AdaDelta | epoch: 027 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.008s\n",
      "| AdaDelta | epoch: 028 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.009s\n",
      "| AdaDelta | epoch: 029 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.010s\n",
      "| AdaDelta | epoch: 030 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'softmax', 10, [0.3002028369758482]]\n",
      "AdaDelta\n",
      "softmax\n",
      "5\n",
      "---------------------------------\n",
      "Run id: 8OPB1T\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.113s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.007s\n",
      "| AdaDelta | epoch: 002 | loss: 0.00000 - binary_acc: 0.2905 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.009s\n",
      "| AdaDelta | epoch: 003 | loss: 0.00000 - binary_acc: 0.3169 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.009s\n",
      "| AdaDelta | epoch: 004 | loss: 0.00000 - binary_acc: 0.3213 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.009s\n",
      "| AdaDelta | epoch: 005 | loss: 0.00000 - binary_acc: 0.3223 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.008s\n",
      "| AdaDelta | epoch: 006 | loss: 0.00000 - binary_acc: 0.3226 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.009s\n",
      "| AdaDelta | epoch: 007 | loss: 0.00000 - binary_acc: 0.3227 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.009s\n",
      "| AdaDelta | epoch: 008 | loss: 0.00000 - binary_acc: 0.3227 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.009s\n",
      "| AdaDelta | epoch: 009 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.008s\n",
      "| AdaDelta | epoch: 010 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.010s\n",
      "| AdaDelta | epoch: 011 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.009s\n",
      "| AdaDelta | epoch: 012 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.009s\n",
      "| AdaDelta | epoch: 013 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.009s\n",
      "| AdaDelta | epoch: 014 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.009s\n",
      "| AdaDelta | epoch: 015 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.010s\n",
      "| AdaDelta | epoch: 016 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.008s\n",
      "| AdaDelta | epoch: 017 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.008s\n",
      "| AdaDelta | epoch: 018 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.009s\n",
      "| AdaDelta | epoch: 019 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.009s\n",
      "| AdaDelta | epoch: 020 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.009s\n",
      "| AdaDelta | epoch: 021 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.008s\n",
      "| AdaDelta | epoch: 022 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.007s\n",
      "| AdaDelta | epoch: 023 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.008s\n",
      "| AdaDelta | epoch: 024 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.009s\n",
      "| AdaDelta | epoch: 025 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.009s\n",
      "| AdaDelta | epoch: 026 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.008s\n",
      "| AdaDelta | epoch: 027 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.009s\n",
      "| AdaDelta | epoch: 028 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.008s\n",
      "| AdaDelta | epoch: 029 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.008s\n",
      "| AdaDelta | epoch: 030 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'softmax', 5, [0.3002028369758482]]\n",
      "AdaDelta\n",
      "softmax\n",
      "35\n",
      "---------------------------------\n",
      "Run id: P0G66F\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.150s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.010s\n",
      "| AdaDelta | epoch: 002 | loss: 0.00000 - binary_acc: 0.2945 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.010s\n",
      "| AdaDelta | epoch: 003 | loss: 0.00000 - binary_acc: 0.3213 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.010s\n",
      "| AdaDelta | epoch: 004 | loss: 0.00000 - binary_acc: 0.3257 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.010s\n",
      "| AdaDelta | epoch: 005 | loss: 0.00000 - binary_acc: 0.3267 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.011s\n",
      "| AdaDelta | epoch: 006 | loss: 0.00000 - binary_acc: 0.3270 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.011s\n",
      "| AdaDelta | epoch: 007 | loss: 0.00000 - binary_acc: 0.3271 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.011s\n",
      "| AdaDelta | epoch: 008 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.010s\n",
      "| AdaDelta | epoch: 009 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.010s\n",
      "| AdaDelta | epoch: 010 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.010s\n",
      "| AdaDelta | epoch: 011 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.010s\n",
      "| AdaDelta | epoch: 012 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.010s\n",
      "| AdaDelta | epoch: 013 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.010s\n",
      "| AdaDelta | epoch: 014 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.008s\n",
      "| AdaDelta | epoch: 015 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.011s\n",
      "| AdaDelta | epoch: 016 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.013s\n",
      "| AdaDelta | epoch: 017 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.012s\n",
      "| AdaDelta | epoch: 018 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.010s\n",
      "| AdaDelta | epoch: 019 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.011s\n",
      "| AdaDelta | epoch: 020 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.010s\n",
      "| AdaDelta | epoch: 021 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.011s\n",
      "| AdaDelta | epoch: 022 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.012s\n",
      "| AdaDelta | epoch: 023 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.011s\n",
      "| AdaDelta | epoch: 024 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.010s\n",
      "| AdaDelta | epoch: 025 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.010s\n",
      "| AdaDelta | epoch: 026 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.013s\n",
      "| AdaDelta | epoch: 027 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.012s\n",
      "| AdaDelta | epoch: 028 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.011s\n",
      "| AdaDelta | epoch: 029 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.013s\n",
      "| AdaDelta | epoch: 030 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'softmax', 35, [0.3002028369758482]]\n",
      "AdaDelta\n",
      "sigmoid\n",
      "10\n",
      "---------------------------------\n",
      "Run id: NA6UIL\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.172s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.2886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.006s\n",
      "| AdaDelta | epoch: 002 | loss: 0.00000 - binary_acc: 0.2990 | val_loss: 0.00000 - val_binary_acc: 0.2886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.009s\n",
      "| AdaDelta | epoch: 003 | loss: 0.00000 - binary_acc: 0.3262 | val_loss: 0.00000 - val_binary_acc: 0.2886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.008s\n",
      "| AdaDelta | epoch: 004 | loss: 0.00000 - binary_acc: 0.3308 | val_loss: 0.00000 - val_binary_acc: 0.2886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.008s\n",
      "| AdaDelta | epoch: 005 | loss: 0.00000 - binary_acc: 0.3318 | val_loss: 0.00000 - val_binary_acc: 0.2886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.008s\n",
      "| AdaDelta | epoch: 006 | loss: 0.00000 - binary_acc: 0.3321 | val_loss: 0.00000 - val_binary_acc: 0.2886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.008s\n",
      "| AdaDelta | epoch: 007 | loss: 0.00000 - binary_acc: 0.3322 | val_loss: 0.00000 - val_binary_acc: 0.2886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.008s\n",
      "| AdaDelta | epoch: 008 | loss: 0.00000 - binary_acc: 0.3322 | val_loss: 0.00000 - val_binary_acc: 0.2886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.007s\n",
      "| AdaDelta | epoch: 009 | loss: 0.00000 - binary_acc: 0.3323 | val_loss: 0.00000 - val_binary_acc: 0.2886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.008s\n",
      "| AdaDelta | epoch: 010 | loss: 0.00000 - binary_acc: 0.3323 | val_loss: 0.00000 - val_binary_acc: 0.2886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.007s\n",
      "| AdaDelta | epoch: 011 | loss: 0.00000 - binary_acc: 0.3323 | val_loss: 0.00000 - val_binary_acc: 0.2886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.008s\n",
      "| AdaDelta | epoch: 012 | loss: 0.00000 - binary_acc: 0.3323 | val_loss: 0.00000 - val_binary_acc: 0.2886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.009s\n",
      "| AdaDelta | epoch: 013 | loss: 0.00000 - binary_acc: 0.3323 | val_loss: 0.00000 - val_binary_acc: 0.2886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.007s\n",
      "| AdaDelta | epoch: 014 | loss: 0.00000 - binary_acc: 0.3323 | val_loss: 0.00000 - val_binary_acc: 0.2886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.008s\n",
      "| AdaDelta | epoch: 015 | loss: 0.00000 - binary_acc: 0.3323 | val_loss: 0.00000 - val_binary_acc: 0.2886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.009s\n",
      "| AdaDelta | epoch: 016 | loss: 0.00000 - binary_acc: 0.3323 | val_loss: 0.00000 - val_binary_acc: 0.2886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.009s\n",
      "| AdaDelta | epoch: 017 | loss: 0.00000 - binary_acc: 0.3323 | val_loss: 0.00000 - val_binary_acc: 0.2886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.006s\n",
      "| AdaDelta | epoch: 018 | loss: 0.00000 - binary_acc: 0.3323 | val_loss: 0.00000 - val_binary_acc: 0.2886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.007s\n",
      "| AdaDelta | epoch: 019 | loss: 0.00000 - binary_acc: 0.3323 | val_loss: 0.00000 - val_binary_acc: 0.2886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.007s\n",
      "| AdaDelta | epoch: 020 | loss: 0.00000 - binary_acc: 0.3323 | val_loss: 0.00000 - val_binary_acc: 0.2886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.009s\n",
      "| AdaDelta | epoch: 021 | loss: 0.00000 - binary_acc: 0.3323 | val_loss: 0.00000 - val_binary_acc: 0.2886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.008s\n",
      "| AdaDelta | epoch: 022 | loss: 0.00000 - binary_acc: 0.3323 | val_loss: 0.00000 - val_binary_acc: 0.2886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.007s\n",
      "| AdaDelta | epoch: 023 | loss: 0.00000 - binary_acc: 0.3323 | val_loss: 0.00000 - val_binary_acc: 0.2886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.007s\n",
      "| AdaDelta | epoch: 024 | loss: 0.00000 - binary_acc: 0.3323 | val_loss: 0.00000 - val_binary_acc: 0.2886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.009s\n",
      "| AdaDelta | epoch: 025 | loss: 0.00000 - binary_acc: 0.3323 | val_loss: 0.00000 - val_binary_acc: 0.2886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.008s\n",
      "| AdaDelta | epoch: 026 | loss: 0.00000 - binary_acc: 0.3323 | val_loss: 0.00000 - val_binary_acc: 0.2886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.007s\n",
      "| AdaDelta | epoch: 027 | loss: 0.00000 - binary_acc: 0.3323 | val_loss: 0.00000 - val_binary_acc: 0.2886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.007s\n",
      "| AdaDelta | epoch: 028 | loss: 0.00000 - binary_acc: 0.3323 | val_loss: 0.00000 - val_binary_acc: 0.2886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.008s\n",
      "| AdaDelta | epoch: 029 | loss: 0.00000 - binary_acc: 0.3323 | val_loss: 0.00000 - val_binary_acc: 0.2886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.007s\n",
      "| AdaDelta | epoch: 030 | loss: 0.00000 - binary_acc: 0.3323 | val_loss: 0.00000 - val_binary_acc: 0.2886 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'sigmoid', 10, [0.3002028369758482]]\n",
      "AdaDelta\n",
      "sigmoid\n",
      "5\n",
      "---------------------------------\n",
      "Run id: V9JTB7\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.237s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.007s\n",
      "| AdaDelta | epoch: 002 | loss: 0.00000 - binary_acc: 0.2871 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.006s\n",
      "| AdaDelta | epoch: 003 | loss: 0.00000 - binary_acc: 0.3132 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.007s\n",
      "| AdaDelta | epoch: 004 | loss: 0.00000 - binary_acc: 0.3175 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.010s\n",
      "| AdaDelta | epoch: 005 | loss: 0.00000 - binary_acc: 0.3185 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.008s\n",
      "| AdaDelta | epoch: 006 | loss: 0.00000 - binary_acc: 0.3188 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.008s\n",
      "| AdaDelta | epoch: 007 | loss: 0.00000 - binary_acc: 0.3189 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.007s\n",
      "| AdaDelta | epoch: 008 | loss: 0.00000 - binary_acc: 0.3189 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.008s\n",
      "| AdaDelta | epoch: 009 | loss: 0.00000 - binary_acc: 0.3189 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.008s\n",
      "| AdaDelta | epoch: 010 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.007s\n",
      "| AdaDelta | epoch: 011 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.008s\n",
      "| AdaDelta | epoch: 012 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.007s\n",
      "| AdaDelta | epoch: 013 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.007s\n",
      "| AdaDelta | epoch: 014 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.008s\n",
      "| AdaDelta | epoch: 015 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.008s\n",
      "| AdaDelta | epoch: 016 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.008s\n",
      "| AdaDelta | epoch: 017 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.007s\n",
      "| AdaDelta | epoch: 018 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.007s\n",
      "| AdaDelta | epoch: 019 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.008s\n",
      "| AdaDelta | epoch: 020 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.008s\n",
      "| AdaDelta | epoch: 021 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.008s\n",
      "| AdaDelta | epoch: 022 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.008s\n",
      "| AdaDelta | epoch: 023 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.008s\n",
      "| AdaDelta | epoch: 024 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.008s\n",
      "| AdaDelta | epoch: 025 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.008s\n",
      "| AdaDelta | epoch: 026 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.008s\n",
      "| AdaDelta | epoch: 027 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.008s\n",
      "| AdaDelta | epoch: 028 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.008s\n",
      "| AdaDelta | epoch: 029 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.009s\n",
      "| AdaDelta | epoch: 030 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'sigmoid', 5, [0.3002028369758482]]\n",
      "AdaDelta\n",
      "sigmoid\n",
      "35\n",
      "---------------------------------\n",
      "Run id: C6Q4EA\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.133s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.008s\n",
      "| AdaDelta | epoch: 002 | loss: 0.00000 - binary_acc: 0.2933 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.009s\n",
      "| AdaDelta | epoch: 003 | loss: 0.00000 - binary_acc: 0.3200 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.012s\n",
      "| AdaDelta | epoch: 004 | loss: 0.00000 - binary_acc: 0.3245 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.008s\n",
      "| AdaDelta | epoch: 005 | loss: 0.00000 - binary_acc: 0.3255 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.009s\n",
      "| AdaDelta | epoch: 006 | loss: 0.00000 - binary_acc: 0.3258 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.009s\n",
      "| AdaDelta | epoch: 007 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.008s\n",
      "| AdaDelta | epoch: 008 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.010s\n",
      "| AdaDelta | epoch: 009 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.010s\n",
      "| AdaDelta | epoch: 010 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.010s\n",
      "| AdaDelta | epoch: 011 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.010s\n",
      "| AdaDelta | epoch: 012 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.010s\n",
      "| AdaDelta | epoch: 013 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.009s\n",
      "| AdaDelta | epoch: 014 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.008s\n",
      "| AdaDelta | epoch: 015 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.010s\n",
      "| AdaDelta | epoch: 016 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.009s\n",
      "| AdaDelta | epoch: 017 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.009s\n",
      "| AdaDelta | epoch: 018 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.010s\n",
      "| AdaDelta | epoch: 019 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.009s\n",
      "| AdaDelta | epoch: 020 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.008s\n",
      "| AdaDelta | epoch: 021 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.008s\n",
      "| AdaDelta | epoch: 022 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.010s\n",
      "| AdaDelta | epoch: 023 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.009s\n",
      "| AdaDelta | epoch: 024 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.010s\n",
      "| AdaDelta | epoch: 025 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.009s\n",
      "| AdaDelta | epoch: 026 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.009s\n",
      "| AdaDelta | epoch: 027 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.010s\n",
      "| AdaDelta | epoch: 028 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.012s\n",
      "| AdaDelta | epoch: 029 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.009s\n",
      "| AdaDelta | epoch: 030 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'sigmoid', 35, [0.3002028369758482]]\n",
      "AdaDelta\n",
      "tanh\n",
      "10\n",
      "---------------------------------\n",
      "Run id: B4CU5G\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.146s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.4835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.007s\n",
      "| AdaDelta | epoch: 002 | loss: 0.00000 - binary_acc: 0.3373 | val_loss: 0.00000 - val_binary_acc: 0.4861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.007s\n",
      "| AdaDelta | epoch: 003 | loss: 0.00000 - binary_acc: 0.4702 | val_loss: 0.00000 - val_binary_acc: 0.4835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.008s\n",
      "| AdaDelta | epoch: 004 | loss: 0.00000 - binary_acc: 0.4129 | val_loss: 0.00000 - val_binary_acc: 0.4810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.008s\n",
      "| AdaDelta | epoch: 005 | loss: 0.00000 - binary_acc: 0.4725 | val_loss: 0.00000 - val_binary_acc: 0.4835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.008s\n",
      "| AdaDelta | epoch: 006 | loss: 0.00000 - binary_acc: 0.4920 | val_loss: 0.00000 - val_binary_acc: 0.4810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.008s\n",
      "| AdaDelta | epoch: 007 | loss: 0.00000 - binary_acc: 0.4962 | val_loss: 0.00000 - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.009s\n",
      "| AdaDelta | epoch: 008 | loss: 0.00000 - binary_acc: 0.4290 | val_loss: 0.00000 - val_binary_acc: 0.4810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.007s\n",
      "| AdaDelta | epoch: 009 | loss: 0.00000 - binary_acc: 0.4671 | val_loss: 0.00000 - val_binary_acc: 0.4886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.007s\n",
      "| AdaDelta | epoch: 010 | loss: 0.00000 - binary_acc: 0.4488 | val_loss: 0.00000 - val_binary_acc: 0.4810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.008s\n",
      "| AdaDelta | epoch: 011 | loss: 0.00000 - binary_acc: 0.4732 | val_loss: 0.00000 - val_binary_acc: 0.4835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.008s\n",
      "| AdaDelta | epoch: 012 | loss: 0.00000 - binary_acc: 0.4512 | val_loss: 0.00000 - val_binary_acc: 0.4861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.007s\n",
      "| AdaDelta | epoch: 013 | loss: 0.00000 - binary_acc: 0.4720 | val_loss: 0.00000 - val_binary_acc: 0.4835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.008s\n",
      "| AdaDelta | epoch: 014 | loss: 0.00000 - binary_acc: 0.4836 | val_loss: 0.00000 - val_binary_acc: 0.4810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.010s\n",
      "| AdaDelta | epoch: 015 | loss: 0.00000 - binary_acc: 0.4896 | val_loss: 0.00000 - val_binary_acc: 0.4810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.009s\n",
      "| AdaDelta | epoch: 016 | loss: 0.00000 - binary_acc: 0.4487 | val_loss: 0.00000 - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.007s\n",
      "| AdaDelta | epoch: 017 | loss: 0.00000 - binary_acc: 0.4682 | val_loss: 0.00000 - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.009s\n",
      "| AdaDelta | epoch: 018 | loss: 0.00000 - binary_acc: 0.4795 | val_loss: 0.00000 - val_binary_acc: 0.4886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.006s\n",
      "| AdaDelta | epoch: 019 | loss: 0.00000 - binary_acc: 0.4869 | val_loss: 0.00000 - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.009s\n",
      "| AdaDelta | epoch: 020 | loss: 0.00000 - binary_acc: 0.4914 | val_loss: 0.00000 - val_binary_acc: 0.4861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.008s\n",
      "| AdaDelta | epoch: 021 | loss: 0.00000 - binary_acc: 0.4948 | val_loss: 0.00000 - val_binary_acc: 0.4810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.008s\n",
      "| AdaDelta | epoch: 022 | loss: 0.00000 - binary_acc: 0.4806 | val_loss: 0.00000 - val_binary_acc: 0.4861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.007s\n",
      "| AdaDelta | epoch: 023 | loss: 0.00000 - binary_acc: 0.4871 | val_loss: 0.00000 - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.009s\n",
      "| AdaDelta | epoch: 024 | loss: 0.00000 - binary_acc: 0.4623 | val_loss: 0.00000 - val_binary_acc: 0.4861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.008s\n",
      "| AdaDelta | epoch: 025 | loss: 0.00000 - binary_acc: 0.4728 | val_loss: 0.00000 - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.008s\n",
      "| AdaDelta | epoch: 026 | loss: 0.00000 - binary_acc: 0.4571 | val_loss: 0.00000 - val_binary_acc: 0.4810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.006s\n",
      "| AdaDelta | epoch: 027 | loss: 0.00000 - binary_acc: 0.4684 | val_loss: 0.00000 - val_binary_acc: 0.4835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.008s\n",
      "| AdaDelta | epoch: 028 | loss: 0.00000 - binary_acc: 0.4537 | val_loss: 0.00000 - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.007s\n",
      "| AdaDelta | epoch: 029 | loss: 0.00000 - binary_acc: 0.4653 | val_loss: 0.00000 - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.007s\n",
      "| AdaDelta | epoch: 030 | loss: 0.00000 - binary_acc: 0.4580 | val_loss: 0.00000 - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'tanh', 10, [0.4624746454535827]]\n",
      "AdaDelta\n",
      "tanh\n",
      "5\n",
      "---------------------------------\n",
      "Run id: LXOT1F\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.139s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.2481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.008s\n",
      "| AdaDelta | epoch: 002 | loss: 0.00000 - binary_acc: 0.3350 | val_loss: 0.00000 - val_binary_acc: 0.2506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.007s\n",
      "| AdaDelta | epoch: 003 | loss: 0.00000 - binary_acc: 0.2845 | val_loss: 0.00000 - val_binary_acc: 0.2506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.008s\n",
      "| AdaDelta | epoch: 004 | loss: 0.00000 - binary_acc: 0.3551 | val_loss: 0.00000 - val_binary_acc: 0.2506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.007s\n",
      "| AdaDelta | epoch: 005 | loss: 0.00000 - binary_acc: 0.2971 | val_loss: 0.00000 - val_binary_acc: 0.2532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.009s\n",
      "| AdaDelta | epoch: 006 | loss: 0.00000 - binary_acc: 0.3442 | val_loss: 0.00000 - val_binary_acc: 0.2506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.007s\n",
      "| AdaDelta | epoch: 007 | loss: 0.00000 - binary_acc: 0.3001 | val_loss: 0.00000 - val_binary_acc: 0.2532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.008s\n",
      "| AdaDelta | epoch: 008 | loss: 0.00000 - binary_acc: 0.3443 | val_loss: 0.00000 - val_binary_acc: 0.2506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.007s\n",
      "| AdaDelta | epoch: 009 | loss: 0.00000 - binary_acc: 0.3053 | val_loss: 0.00000 - val_binary_acc: 0.2557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.007s\n",
      "| AdaDelta | epoch: 010 | loss: 0.00000 - binary_acc: 0.2877 | val_loss: 0.00000 - val_binary_acc: 0.2532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.006s\n",
      "| AdaDelta | epoch: 011 | loss: 0.00000 - binary_acc: 0.2779 | val_loss: 0.00000 - val_binary_acc: 0.2532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.008s\n",
      "| AdaDelta | epoch: 012 | loss: 0.00000 - binary_acc: 0.2904 | val_loss: 0.00000 - val_binary_acc: 0.2506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.008s\n",
      "| AdaDelta | epoch: 013 | loss: 0.00000 - binary_acc: 0.2814 | val_loss: 0.00000 - val_binary_acc: 0.2608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.008s\n",
      "| AdaDelta | epoch: 014 | loss: 0.00000 - binary_acc: 0.3004 | val_loss: 0.00000 - val_binary_acc: 0.2405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.008s\n",
      "| AdaDelta | epoch: 015 | loss: 0.00000 - binary_acc: 0.2893 | val_loss: 0.00000 - val_binary_acc: 0.2608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.008s\n",
      "| AdaDelta | epoch: 016 | loss: 0.00000 - binary_acc: 0.3204 | val_loss: 0.00000 - val_binary_acc: 0.2481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.008s\n",
      "| AdaDelta | epoch: 017 | loss: 0.00000 - binary_acc: 0.3028 | val_loss: 0.00000 - val_binary_acc: 0.2608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.008s\n",
      "| AdaDelta | epoch: 018 | loss: 0.00000 - binary_acc: 0.3330 | val_loss: 0.00000 - val_binary_acc: 0.2380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.007s\n",
      "| AdaDelta | epoch: 019 | loss: 0.00000 - binary_acc: 0.3124 | val_loss: 0.00000 - val_binary_acc: 0.2608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.010s\n",
      "| AdaDelta | epoch: 020 | loss: 0.00000 - binary_acc: 0.3202 | val_loss: 0.00000 - val_binary_acc: 0.2532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.007s\n",
      "| AdaDelta | epoch: 021 | loss: 0.00000 - binary_acc: 0.3053 | val_loss: 0.00000 - val_binary_acc: 0.2506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.008s\n",
      "| AdaDelta | epoch: 022 | loss: 0.00000 - binary_acc: 0.3077 | val_loss: 0.00000 - val_binary_acc: 0.2532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.008s\n",
      "| AdaDelta | epoch: 023 | loss: 0.00000 - binary_acc: 0.2986 | val_loss: 0.00000 - val_binary_acc: 0.2557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.007s\n",
      "| AdaDelta | epoch: 024 | loss: 0.00000 - binary_acc: 0.3086 | val_loss: 0.00000 - val_binary_acc: 0.2506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.008s\n",
      "| AdaDelta | epoch: 025 | loss: 0.00000 - binary_acc: 0.2983 | val_loss: 0.00000 - val_binary_acc: 0.2532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.007s\n",
      "| AdaDelta | epoch: 026 | loss: 0.00000 - binary_acc: 0.3071 | val_loss: 0.00000 - val_binary_acc: 0.2608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.008s\n",
      "| AdaDelta | epoch: 027 | loss: 0.00000 - binary_acc: 0.2971 | val_loss: 0.00000 - val_binary_acc: 0.2608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.008s\n",
      "| AdaDelta | epoch: 028 | loss: 0.00000 - binary_acc: 0.3045 | val_loss: 0.00000 - val_binary_acc: 0.2608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.006s\n",
      "| AdaDelta | epoch: 029 | loss: 0.00000 - binary_acc: 0.2947 | val_loss: 0.00000 - val_binary_acc: 0.2481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.008s\n",
      "| AdaDelta | epoch: 030 | loss: 0.00000 - binary_acc: 0.3053 | val_loss: 0.00000 - val_binary_acc: 0.2532 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'tanh', 5, [0.2697768734870044]]\n",
      "AdaDelta\n",
      "tanh\n",
      "35\n",
      "---------------------------------\n",
      "Run id: TWWKK9\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.154s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.5266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.008s\n",
      "| AdaDelta | epoch: 002 | loss: 0.00000 - binary_acc: 0.4457 | val_loss: 0.00000 - val_binary_acc: 0.5266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.008s\n",
      "| AdaDelta | epoch: 003 | loss: 0.00000 - binary_acc: 0.4318 | val_loss: 0.00000 - val_binary_acc: 0.5266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.010s\n",
      "| AdaDelta | epoch: 004 | loss: 0.00000 - binary_acc: 0.4794 | val_loss: 0.00000 - val_binary_acc: 0.5266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.008s\n",
      "| AdaDelta | epoch: 005 | loss: 0.00000 - binary_acc: 0.4899 | val_loss: 0.00000 - val_binary_acc: 0.5266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.010s\n",
      "| AdaDelta | epoch: 006 | loss: 0.00000 - binary_acc: 0.4326 | val_loss: 0.00000 - val_binary_acc: 0.5266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.009s\n",
      "| AdaDelta | epoch: 007 | loss: 0.00000 - binary_acc: 0.4702 | val_loss: 0.00000 - val_binary_acc: 0.5266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.009s\n",
      "| AdaDelta | epoch: 008 | loss: 0.00000 - binary_acc: 0.4329 | val_loss: 0.00000 - val_binary_acc: 0.5266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.010s\n",
      "| AdaDelta | epoch: 009 | loss: 0.00000 - binary_acc: 0.4656 | val_loss: 0.00000 - val_binary_acc: 0.5266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.008s\n",
      "| AdaDelta | epoch: 010 | loss: 0.00000 - binary_acc: 0.4500 | val_loss: 0.00000 - val_binary_acc: 0.5266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.010s\n",
      "| AdaDelta | epoch: 011 | loss: 0.00000 - binary_acc: 0.4717 | val_loss: 0.00000 - val_binary_acc: 0.5266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.011s\n",
      "| AdaDelta | epoch: 012 | loss: 0.00000 - binary_acc: 0.4552 | val_loss: 0.00000 - val_binary_acc: 0.5266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.010s\n",
      "| AdaDelta | epoch: 013 | loss: 0.00000 - binary_acc: 0.4724 | val_loss: 0.00000 - val_binary_acc: 0.5266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.010s\n",
      "| AdaDelta | epoch: 014 | loss: 0.00000 - binary_acc: 0.4817 | val_loss: 0.00000 - val_binary_acc: 0.5266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.010s\n",
      "| AdaDelta | epoch: 015 | loss: 0.00000 - binary_acc: 0.4870 | val_loss: 0.00000 - val_binary_acc: 0.5266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.008s\n",
      "| AdaDelta | epoch: 016 | loss: 0.00000 - binary_acc: 0.4487 | val_loss: 0.00000 - val_binary_acc: 0.5266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.010s\n",
      "| AdaDelta | epoch: 017 | loss: 0.00000 - binary_acc: 0.4652 | val_loss: 0.00000 - val_binary_acc: 0.5266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.009s\n",
      "| AdaDelta | epoch: 018 | loss: 0.00000 - binary_acc: 0.4414 | val_loss: 0.00000 - val_binary_acc: 0.5266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.009s\n",
      "| AdaDelta | epoch: 019 | loss: 0.00000 - binary_acc: 0.4593 | val_loss: 0.00000 - val_binary_acc: 0.5266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.009s\n",
      "| AdaDelta | epoch: 020 | loss: 0.00000 - binary_acc: 0.4442 | val_loss: 0.00000 - val_binary_acc: 0.5266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.008s\n",
      "| AdaDelta | epoch: 021 | loss: 0.00000 - binary_acc: 0.4600 | val_loss: 0.00000 - val_binary_acc: 0.5266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.008s\n",
      "| AdaDelta | epoch: 022 | loss: 0.00000 - binary_acc: 0.4489 | val_loss: 0.00000 - val_binary_acc: 0.5266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.008s\n",
      "| AdaDelta | epoch: 023 | loss: 0.00000 - binary_acc: 0.4625 | val_loss: 0.00000 - val_binary_acc: 0.5266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.008s\n",
      "| AdaDelta | epoch: 024 | loss: 0.00000 - binary_acc: 0.4437 | val_loss: 0.00000 - val_binary_acc: 0.5266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.009s\n",
      "| AdaDelta | epoch: 025 | loss: 0.00000 - binary_acc: 0.4576 | val_loss: 0.00000 - val_binary_acc: 0.5266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.009s\n",
      "| AdaDelta | epoch: 026 | loss: 0.00000 - binary_acc: 0.4488 | val_loss: 0.00000 - val_binary_acc: 0.5266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.009s\n",
      "| AdaDelta | epoch: 027 | loss: 0.00000 - binary_acc: 0.4607 | val_loss: 0.00000 - val_binary_acc: 0.5266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.010s\n",
      "| AdaDelta | epoch: 028 | loss: 0.00000 - binary_acc: 0.4478 | val_loss: 0.00000 - val_binary_acc: 0.5266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.009s\n",
      "| AdaDelta | epoch: 029 | loss: 0.00000 - binary_acc: 0.4595 | val_loss: 0.00000 - val_binary_acc: 0.5266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.009s\n",
      "| AdaDelta | epoch: 030 | loss: 0.00000 - binary_acc: 0.4408 | val_loss: 0.00000 - val_binary_acc: 0.5291 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'tanh', 35, [0.5070993930524551]]\n",
      "AdaDelta\n",
      "prelu\n",
      "10\n",
      "---------------------------------\n",
      "Run id: LFPF4E\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.199s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.006s\n",
      "| AdaDelta | epoch: 002 | loss: nan - binary_acc: 0.2888 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 003 | loss: nan - binary_acc: 0.4157 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 004 | loss: nan - binary_acc: 0.4368 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaDelta | epoch: 005 | loss: nan - binary_acc: 0.4417 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 006 | loss: nan - binary_acc: 0.4431 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 007 | loss: nan - binary_acc: 0.4436 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 008 | loss: nan - binary_acc: 0.4437 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 009 | loss: nan - binary_acc: 0.4438 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 010 | loss: nan - binary_acc: 0.4438 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaDelta | epoch: 011 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 012 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 013 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 014 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 015 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 016 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 017 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 018 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 019 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 020 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 021 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 022 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 023 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 024 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 025 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 026 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.006s\n",
      "| AdaDelta | epoch: 027 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 028 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 029 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaDelta | epoch: 030 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'prelu', 10, [0.45436105404132276]]\n",
      "AdaDelta\n",
      "prelu\n",
      "5\n",
      "---------------------------------\n",
      "Run id: YLPJ0O\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.220s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaDelta | epoch: 002 | loss: nan - binary_acc: 0.4012 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 003 | loss: nan - binary_acc: 0.4278 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 004 | loss: nan - binary_acc: 0.4323 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 005 | loss: nan - binary_acc: 0.4333 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 006 | loss: nan - binary_acc: 0.4336 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 007 | loss: nan - binary_acc: 0.4337 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 008 | loss: nan - binary_acc: 0.4337 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 009 | loss: nan - binary_acc: 0.4337 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 010 | loss: nan - binary_acc: 0.4337 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 011 | loss: nan - binary_acc: 0.4337 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 012 | loss: nan - binary_acc: 0.4337 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 013 | loss: nan - binary_acc: 0.4337 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 014 | loss: nan - binary_acc: 0.4337 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 015 | loss: nan - binary_acc: 0.4337 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 016 | loss: nan - binary_acc: 0.4337 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 017 | loss: nan - binary_acc: 0.4337 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 018 | loss: nan - binary_acc: 0.4337 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 019 | loss: nan - binary_acc: 0.4337 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaDelta | epoch: 020 | loss: nan - binary_acc: 0.4337 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaDelta | epoch: 021 | loss: nan - binary_acc: 0.4337 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 022 | loss: nan - binary_acc: 0.4337 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 023 | loss: nan - binary_acc: 0.4337 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaDelta | epoch: 024 | loss: nan - binary_acc: 0.4337 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 025 | loss: nan - binary_acc: 0.4337 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 026 | loss: nan - binary_acc: 0.4337 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 027 | loss: nan - binary_acc: 0.4337 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 028 | loss: nan - binary_acc: 0.4337 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 029 | loss: nan - binary_acc: 0.4337 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaDelta | epoch: 030 | loss: nan - binary_acc: 0.4337 | val_loss: nan - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'prelu', 5, [0.45436105404132276]]\n",
      "AdaDelta\n",
      "prelu\n",
      "35\n",
      "---------------------------------\n",
      "Run id: 49A9XD\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.248s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 002 | loss: nan - binary_acc: 0.3356 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| AdaDelta | epoch: 003 | loss: nan - binary_acc: 0.4242 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaDelta | epoch: 004 | loss: nan - binary_acc: 0.4390 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaDelta | epoch: 005 | loss: nan - binary_acc: 0.4424 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaDelta | epoch: 006 | loss: nan - binary_acc: 0.4433 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 007 | loss: nan - binary_acc: 0.4437 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| AdaDelta | epoch: 008 | loss: nan - binary_acc: 0.4438 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 009 | loss: nan - binary_acc: 0.4438 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 010 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| AdaDelta | epoch: 011 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.013s\n",
      "| AdaDelta | epoch: 012 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaDelta | epoch: 013 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaDelta | epoch: 014 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaDelta | epoch: 015 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 016 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 017 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaDelta | epoch: 018 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 019 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 020 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 021 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| AdaDelta | epoch: 022 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaDelta | epoch: 023 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaDelta | epoch: 024 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaDelta | epoch: 025 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaDelta | epoch: 026 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 027 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| AdaDelta | epoch: 028 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaDelta | epoch: 029 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaDelta | epoch: 030 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'prelu', 35, [0.45436105404132276]]\n",
      "RMSProp\n",
      "relu\n",
      "10\n",
      "---------------------------------\n",
      "Run id: WAWNNN\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.126s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.006s\n",
      "| RMSProp | epoch: 002 | loss: nan - binary_acc: 0.3270 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 003 | loss: nan - binary_acc: 0.4180 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 004 | loss: nan - binary_acc: 0.4331 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 005 | loss: nan - binary_acc: 0.4366 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 006 | loss: nan - binary_acc: 0.4376 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 007 | loss: nan - binary_acc: 0.4380 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| RMSProp | epoch: 008 | loss: nan - binary_acc: 0.4381 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 009 | loss: nan - binary_acc: 0.4381 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| RMSProp | epoch: 010 | loss: nan - binary_acc: 0.4382 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 011 | loss: nan - binary_acc: 0.4382 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 012 | loss: nan - binary_acc: 0.4382 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| RMSProp | epoch: 013 | loss: nan - binary_acc: 0.4382 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 014 | loss: nan - binary_acc: 0.4382 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 015 | loss: nan - binary_acc: 0.4382 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| RMSProp | epoch: 016 | loss: nan - binary_acc: 0.4382 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| RMSProp | epoch: 017 | loss: nan - binary_acc: 0.4382 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 018 | loss: nan - binary_acc: 0.4382 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 019 | loss: nan - binary_acc: 0.4382 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 020 | loss: nan - binary_acc: 0.4382 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 021 | loss: nan - binary_acc: 0.4382 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 022 | loss: nan - binary_acc: 0.4382 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 023 | loss: nan - binary_acc: 0.4382 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 024 | loss: nan - binary_acc: 0.4382 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.006s\n",
      "| RMSProp | epoch: 025 | loss: nan - binary_acc: 0.4382 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| RMSProp | epoch: 026 | loss: nan - binary_acc: 0.4382 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 027 | loss: nan - binary_acc: 0.4382 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| RMSProp | epoch: 028 | loss: nan - binary_acc: 0.4382 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| RMSProp | epoch: 029 | loss: nan - binary_acc: 0.4382 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 030 | loss: nan - binary_acc: 0.4382 | val_loss: nan - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'relu', 10, [0.45436105404132276]]\n",
      "RMSProp\n",
      "relu\n",
      "5\n",
      "---------------------------------\n",
      "Run id: 7ULZ1P\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.123s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.006s\n",
      "| RMSProp | epoch: 002 | loss: nan - binary_acc: 0.3048 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 003 | loss: nan - binary_acc: 0.4196 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 004 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 005 | loss: nan - binary_acc: 0.4432 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| RMSProp | epoch: 006 | loss: nan - binary_acc: 0.4444 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| RMSProp | epoch: 007 | loss: nan - binary_acc: 0.4449 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 008 | loss: nan - binary_acc: 0.4450 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 009 | loss: nan - binary_acc: 0.4451 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 010 | loss: nan - binary_acc: 0.4451 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 011 | loss: nan - binary_acc: 0.4451 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| RMSProp | epoch: 012 | loss: nan - binary_acc: 0.4451 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 013 | loss: nan - binary_acc: 0.4451 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| RMSProp | epoch: 014 | loss: nan - binary_acc: 0.4451 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 015 | loss: nan - binary_acc: 0.4451 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| RMSProp | epoch: 016 | loss: nan - binary_acc: 0.4451 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 017 | loss: nan - binary_acc: 0.4451 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| RMSProp | epoch: 018 | loss: nan - binary_acc: 0.4451 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 019 | loss: nan - binary_acc: 0.4451 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| RMSProp | epoch: 020 | loss: nan - binary_acc: 0.4451 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| RMSProp | epoch: 021 | loss: nan - binary_acc: 0.4451 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 022 | loss: nan - binary_acc: 0.4451 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 023 | loss: nan - binary_acc: 0.4451 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| RMSProp | epoch: 024 | loss: nan - binary_acc: 0.4451 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| RMSProp | epoch: 025 | loss: nan - binary_acc: 0.4451 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| RMSProp | epoch: 026 | loss: nan - binary_acc: 0.4451 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| RMSProp | epoch: 027 | loss: nan - binary_acc: 0.4451 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 028 | loss: nan - binary_acc: 0.4451 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| RMSProp | epoch: 029 | loss: nan - binary_acc: 0.4451 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| RMSProp | epoch: 030 | loss: nan - binary_acc: 0.4451 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'relu', 5, [0.45436105404132276]]\n",
      "RMSProp\n",
      "relu\n",
      "35\n",
      "---------------------------------\n",
      "Run id: 8ZT9UV\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.162s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 002 | loss: nan - binary_acc: 0.3436 | val_loss: nan - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 003 | loss: nan - binary_acc: 0.4189 | val_loss: nan - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 004 | loss: nan - binary_acc: 0.4315 | val_loss: nan - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 005 | loss: nan - binary_acc: 0.4343 | val_loss: nan - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| RMSProp | epoch: 006 | loss: nan - binary_acc: 0.4352 | val_loss: nan - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 007 | loss: nan - binary_acc: 0.4355 | val_loss: nan - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 008 | loss: nan - binary_acc: 0.4356 | val_loss: nan - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 009 | loss: nan - binary_acc: 0.4356 | val_loss: nan - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 010 | loss: nan - binary_acc: 0.4356 | val_loss: nan - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 011 | loss: nan - binary_acc: 0.4356 | val_loss: nan - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 012 | loss: nan - binary_acc: 0.4356 | val_loss: nan - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 013 | loss: nan - binary_acc: 0.4356 | val_loss: nan - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 014 | loss: nan - binary_acc: 0.4356 | val_loss: nan - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 015 | loss: nan - binary_acc: 0.4356 | val_loss: nan - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 016 | loss: nan - binary_acc: 0.4356 | val_loss: nan - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 017 | loss: nan - binary_acc: 0.4356 | val_loss: nan - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 018 | loss: nan - binary_acc: 0.4356 | val_loss: nan - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 019 | loss: nan - binary_acc: 0.4356 | val_loss: nan - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 020 | loss: nan - binary_acc: 0.4356 | val_loss: nan - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 021 | loss: nan - binary_acc: 0.4356 | val_loss: nan - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 022 | loss: nan - binary_acc: 0.4356 | val_loss: nan - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 023 | loss: nan - binary_acc: 0.4356 | val_loss: nan - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 024 | loss: nan - binary_acc: 0.4356 | val_loss: nan - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 025 | loss: nan - binary_acc: 0.4356 | val_loss: nan - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 026 | loss: nan - binary_acc: 0.4356 | val_loss: nan - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 027 | loss: nan - binary_acc: 0.4356 | val_loss: nan - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 028 | loss: nan - binary_acc: 0.4356 | val_loss: nan - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 029 | loss: nan - binary_acc: 0.4356 | val_loss: nan - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| RMSProp | epoch: 030 | loss: nan - binary_acc: 0.4356 | val_loss: nan - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'relu', 35, [0.45436105404132276]]\n",
      "RMSProp\n",
      "linear\n",
      "10\n",
      "---------------------------------\n",
      "Run id: TJ7UA9\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.129s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.008s\n",
      "| RMSProp | epoch: 002 | loss: 0.00000 - binary_acc: 0.3550 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.007s\n",
      "| RMSProp | epoch: 003 | loss: 0.00000 - binary_acc: 0.3224 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.009s\n",
      "| RMSProp | epoch: 004 | loss: 0.00000 - binary_acc: 0.3170 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.008s\n",
      "| RMSProp | epoch: 005 | loss: 0.00000 - binary_acc: 0.3157 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.008s\n",
      "| RMSProp | epoch: 006 | loss: 0.00000 - binary_acc: 0.3154 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.007s\n",
      "| RMSProp | epoch: 007 | loss: 0.00000 - binary_acc: 0.3152 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.008s\n",
      "| RMSProp | epoch: 008 | loss: 0.00000 - binary_acc: 0.3152 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.008s\n",
      "| RMSProp | epoch: 009 | loss: 0.00000 - binary_acc: 0.3152 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.008s\n",
      "| RMSProp | epoch: 010 | loss: 0.00000 - binary_acc: 0.3152 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.007s\n",
      "| RMSProp | epoch: 011 | loss: 0.00000 - binary_acc: 0.3152 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.008s\n",
      "| RMSProp | epoch: 012 | loss: 0.00000 - binary_acc: 0.3152 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.006s\n",
      "| RMSProp | epoch: 013 | loss: 0.00000 - binary_acc: 0.3152 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.007s\n",
      "| RMSProp | epoch: 014 | loss: 0.00000 - binary_acc: 0.3152 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.008s\n",
      "| RMSProp | epoch: 015 | loss: 0.00000 - binary_acc: 0.3152 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.008s\n",
      "| RMSProp | epoch: 016 | loss: 0.00000 - binary_acc: 0.3152 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.007s\n",
      "| RMSProp | epoch: 017 | loss: 0.00000 - binary_acc: 0.3152 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.007s\n",
      "| RMSProp | epoch: 018 | loss: 0.00000 - binary_acc: 0.3152 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.007s\n",
      "| RMSProp | epoch: 019 | loss: 0.00000 - binary_acc: 0.3152 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.005s\n",
      "| RMSProp | epoch: 020 | loss: 0.00000 - binary_acc: 0.3152 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.009s\n",
      "| RMSProp | epoch: 021 | loss: 0.00000 - binary_acc: 0.3152 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.007s\n",
      "| RMSProp | epoch: 022 | loss: 0.00000 - binary_acc: 0.3152 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.008s\n",
      "| RMSProp | epoch: 023 | loss: 0.00000 - binary_acc: 0.3152 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.008s\n",
      "| RMSProp | epoch: 024 | loss: 0.00000 - binary_acc: 0.3152 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.008s\n",
      "| RMSProp | epoch: 025 | loss: 0.00000 - binary_acc: 0.3152 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.008s\n",
      "| RMSProp | epoch: 026 | loss: 0.00000 - binary_acc: 0.3152 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.007s\n",
      "| RMSProp | epoch: 027 | loss: 0.00000 - binary_acc: 0.3152 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.008s\n",
      "| RMSProp | epoch: 028 | loss: 0.00000 - binary_acc: 0.3152 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.007s\n",
      "| RMSProp | epoch: 029 | loss: 0.00000 - binary_acc: 0.3152 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.008s\n",
      "| RMSProp | epoch: 030 | loss: 0.00000 - binary_acc: 0.3152 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'linear', 10, [0.3002028369758482]]\n",
      "RMSProp\n",
      "linear\n",
      "5\n",
      "---------------------------------\n",
      "Run id: 9Q5PBI\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.119s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.006s\n",
      "| RMSProp | epoch: 002 | loss: 0.00000 - binary_acc: 0.3516 | val_loss: 0.00000 - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.008s\n",
      "| RMSProp | epoch: 003 | loss: 0.00000 - binary_acc: 0.4255 | val_loss: 0.00000 - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.008s\n",
      "| RMSProp | epoch: 004 | loss: 0.00000 - binary_acc: 0.4379 | val_loss: 0.00000 - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.008s\n",
      "| RMSProp | epoch: 005 | loss: 0.00000 - binary_acc: 0.4407 | val_loss: 0.00000 - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.007s\n",
      "| RMSProp | epoch: 006 | loss: 0.00000 - binary_acc: 0.4415 | val_loss: 0.00000 - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.008s\n",
      "| RMSProp | epoch: 007 | loss: 0.00000 - binary_acc: 0.4418 | val_loss: 0.00000 - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.007s\n",
      "| RMSProp | epoch: 008 | loss: 0.00000 - binary_acc: 0.4419 | val_loss: 0.00000 - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.008s\n",
      "| RMSProp | epoch: 009 | loss: 0.00000 - binary_acc: 0.4419 | val_loss: 0.00000 - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.007s\n",
      "| RMSProp | epoch: 010 | loss: 0.00000 - binary_acc: 0.4420 | val_loss: 0.00000 - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.008s\n",
      "| RMSProp | epoch: 011 | loss: 0.00000 - binary_acc: 0.4420 | val_loss: 0.00000 - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.006s\n",
      "| RMSProp | epoch: 012 | loss: 0.00000 - binary_acc: 0.4420 | val_loss: 0.00000 - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.007s\n",
      "| RMSProp | epoch: 013 | loss: 0.00000 - binary_acc: 0.4420 | val_loss: 0.00000 - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.009s\n",
      "| RMSProp | epoch: 014 | loss: 0.00000 - binary_acc: 0.4420 | val_loss: 0.00000 - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.007s\n",
      "| RMSProp | epoch: 015 | loss: 0.00000 - binary_acc: 0.4420 | val_loss: 0.00000 - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.008s\n",
      "| RMSProp | epoch: 016 | loss: 0.00000 - binary_acc: 0.4420 | val_loss: 0.00000 - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.008s\n",
      "| RMSProp | epoch: 017 | loss: 0.00000 - binary_acc: 0.4420 | val_loss: 0.00000 - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.007s\n",
      "| RMSProp | epoch: 018 | loss: 0.00000 - binary_acc: 0.4420 | val_loss: 0.00000 - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.006s\n",
      "| RMSProp | epoch: 019 | loss: 0.00000 - binary_acc: 0.4420 | val_loss: 0.00000 - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.008s\n",
      "| RMSProp | epoch: 020 | loss: 0.00000 - binary_acc: 0.4420 | val_loss: 0.00000 - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.007s\n",
      "| RMSProp | epoch: 021 | loss: 0.00000 - binary_acc: 0.4420 | val_loss: 0.00000 - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.007s\n",
      "| RMSProp | epoch: 022 | loss: 0.00000 - binary_acc: 0.4420 | val_loss: 0.00000 - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.006s\n",
      "| RMSProp | epoch: 023 | loss: 0.00000 - binary_acc: 0.4420 | val_loss: 0.00000 - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.006s\n",
      "| RMSProp | epoch: 024 | loss: 0.00000 - binary_acc: 0.4420 | val_loss: 0.00000 - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.008s\n",
      "| RMSProp | epoch: 025 | loss: 0.00000 - binary_acc: 0.4420 | val_loss: 0.00000 - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.008s\n",
      "| RMSProp | epoch: 026 | loss: 0.00000 - binary_acc: 0.4420 | val_loss: 0.00000 - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.007s\n",
      "| RMSProp | epoch: 027 | loss: 0.00000 - binary_acc: 0.4420 | val_loss: 0.00000 - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.008s\n",
      "| RMSProp | epoch: 028 | loss: 0.00000 - binary_acc: 0.4420 | val_loss: 0.00000 - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.006s\n",
      "| RMSProp | epoch: 029 | loss: 0.00000 - binary_acc: 0.4420 | val_loss: 0.00000 - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.007s\n",
      "| RMSProp | epoch: 030 | loss: 0.00000 - binary_acc: 0.4420 | val_loss: 0.00000 - val_binary_acc: 0.4354 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'linear', 5, [0.45436105404132276]]\n",
      "RMSProp\n",
      "linear\n",
      "35\n",
      "---------------------------------\n",
      "Run id: K2RQCJ\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.127s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.2405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.007s\n",
      "| RMSProp | epoch: 002 | loss: 0.00000 - binary_acc: 0.3150 | val_loss: 0.00000 - val_binary_acc: 0.2405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.009s\n",
      "| RMSProp | epoch: 003 | loss: 0.00000 - binary_acc: 0.2830 | val_loss: 0.00000 - val_binary_acc: 0.2278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.011s\n",
      "| RMSProp | epoch: 004 | loss: 0.00000 - binary_acc: 0.3314 | val_loss: 0.00000 - val_binary_acc: 0.2304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.011s\n",
      "| RMSProp | epoch: 005 | loss: 0.00000 - binary_acc: 0.2920 | val_loss: 0.00000 - val_binary_acc: 0.2304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.008s\n",
      "| RMSProp | epoch: 006 | loss: 0.00000 - binary_acc: 0.3195 | val_loss: 0.00000 - val_binary_acc: 0.2329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.009s\n",
      "| RMSProp | epoch: 007 | loss: 0.00000 - binary_acc: 0.2926 | val_loss: 0.00000 - val_binary_acc: 0.2329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.009s\n",
      "| RMSProp | epoch: 008 | loss: 0.00000 - binary_acc: 0.3302 | val_loss: 0.00000 - val_binary_acc: 0.2304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.009s\n",
      "| RMSProp | epoch: 009 | loss: 0.00000 - binary_acc: 0.3008 | val_loss: 0.00000 - val_binary_acc: 0.2304 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.009s\n",
      "| RMSProp | epoch: 010 | loss: 0.00000 - binary_acc: 0.3384 | val_loss: 0.00000 - val_binary_acc: 0.2354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.009s\n",
      "| RMSProp | epoch: 011 | loss: 0.00000 - binary_acc: 0.3082 | val_loss: 0.00000 - val_binary_acc: 0.2354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.009s\n",
      "| RMSProp | epoch: 012 | loss: 0.00000 - binary_acc: 0.3330 | val_loss: 0.00000 - val_binary_acc: 0.2329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.008s\n",
      "| RMSProp | epoch: 013 | loss: 0.00000 - binary_acc: 0.3080 | val_loss: 0.00000 - val_binary_acc: 0.2354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.009s\n",
      "| RMSProp | epoch: 014 | loss: 0.00000 - binary_acc: 0.3223 | val_loss: 0.00000 - val_binary_acc: 0.2380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.008s\n",
      "| RMSProp | epoch: 015 | loss: 0.00000 - binary_acc: 0.3036 | val_loss: 0.00000 - val_binary_acc: 0.2278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.009s\n",
      "| RMSProp | epoch: 016 | loss: 0.00000 - binary_acc: 0.3160 | val_loss: 0.00000 - val_binary_acc: 0.2354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.008s\n",
      "| RMSProp | epoch: 017 | loss: 0.00000 - binary_acc: 0.3011 | val_loss: 0.00000 - val_binary_acc: 0.2380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.008s\n",
      "| RMSProp | epoch: 018 | loss: 0.00000 - binary_acc: 0.3097 | val_loss: 0.00000 - val_binary_acc: 0.2329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.009s\n",
      "| RMSProp | epoch: 019 | loss: 0.00000 - binary_acc: 0.2978 | val_loss: 0.00000 - val_binary_acc: 0.2329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.008s\n",
      "| RMSProp | epoch: 020 | loss: 0.00000 - binary_acc: 0.3064 | val_loss: 0.00000 - val_binary_acc: 0.2329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.008s\n",
      "| RMSProp | epoch: 021 | loss: 0.00000 - binary_acc: 0.2977 | val_loss: 0.00000 - val_binary_acc: 0.2430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.008s\n",
      "| RMSProp | epoch: 022 | loss: 0.00000 - binary_acc: 0.3127 | val_loss: 0.00000 - val_binary_acc: 0.2430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.009s\n",
      "| RMSProp | epoch: 023 | loss: 0.00000 - binary_acc: 0.3034 | val_loss: 0.00000 - val_binary_acc: 0.2430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.008s\n",
      "| RMSProp | epoch: 024 | loss: 0.00000 - binary_acc: 0.3062 | val_loss: 0.00000 - val_binary_acc: 0.2430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.008s\n",
      "| RMSProp | epoch: 025 | loss: 0.00000 - binary_acc: 0.2993 | val_loss: 0.00000 - val_binary_acc: 0.2430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.009s\n",
      "| RMSProp | epoch: 026 | loss: 0.00000 - binary_acc: 0.3035 | val_loss: 0.00000 - val_binary_acc: 0.2354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.008s\n",
      "| RMSProp | epoch: 027 | loss: 0.00000 - binary_acc: 0.2977 | val_loss: 0.00000 - val_binary_acc: 0.2354 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.009s\n",
      "| RMSProp | epoch: 028 | loss: 0.00000 - binary_acc: 0.3043 | val_loss: 0.00000 - val_binary_acc: 0.2430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.009s\n",
      "| RMSProp | epoch: 029 | loss: 0.00000 - binary_acc: 0.2983 | val_loss: 0.00000 - val_binary_acc: 0.2380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.010s\n",
      "| RMSProp | epoch: 030 | loss: 0.00000 - binary_acc: 0.3032 | val_loss: 0.00000 - val_binary_acc: 0.2380 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'linear', 35, [0.2799188644600688]]\n",
      "RMSProp\n",
      "softmax\n",
      "10\n",
      "---------------------------------\n",
      "Run id: 6ME42S\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.143s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3468 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.007s\n",
      "| RMSProp | epoch: 002 | loss: 0.00000 - binary_acc: 0.2859 | val_loss: 0.00000 - val_binary_acc: 0.3468 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.009s\n",
      "| RMSProp | epoch: 003 | loss: 0.00000 - binary_acc: 0.3119 | val_loss: 0.00000 - val_binary_acc: 0.3468 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.009s\n",
      "| RMSProp | epoch: 004 | loss: 0.00000 - binary_acc: 0.3162 | val_loss: 0.00000 - val_binary_acc: 0.3468 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.008s\n",
      "| RMSProp | epoch: 005 | loss: 0.00000 - binary_acc: 0.3172 | val_loss: 0.00000 - val_binary_acc: 0.3468 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.009s\n",
      "| RMSProp | epoch: 006 | loss: 0.00000 - binary_acc: 0.3175 | val_loss: 0.00000 - val_binary_acc: 0.3468 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.008s\n",
      "| RMSProp | epoch: 007 | loss: 0.00000 - binary_acc: 0.3176 | val_loss: 0.00000 - val_binary_acc: 0.3468 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.009s\n",
      "| RMSProp | epoch: 008 | loss: 0.00000 - binary_acc: 0.3177 | val_loss: 0.00000 - val_binary_acc: 0.3468 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.009s\n",
      "| RMSProp | epoch: 009 | loss: 0.00000 - binary_acc: 0.3177 | val_loss: 0.00000 - val_binary_acc: 0.3468 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.010s\n",
      "| RMSProp | epoch: 010 | loss: 0.00000 - binary_acc: 0.3177 | val_loss: 0.00000 - val_binary_acc: 0.3468 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.008s\n",
      "| RMSProp | epoch: 011 | loss: 0.00000 - binary_acc: 0.3177 | val_loss: 0.00000 - val_binary_acc: 0.3468 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.009s\n",
      "| RMSProp | epoch: 012 | loss: 0.00000 - binary_acc: 0.3177 | val_loss: 0.00000 - val_binary_acc: 0.3468 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.010s\n",
      "| RMSProp | epoch: 013 | loss: 0.00000 - binary_acc: 0.3177 | val_loss: 0.00000 - val_binary_acc: 0.3468 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.010s\n",
      "| RMSProp | epoch: 014 | loss: 0.00000 - binary_acc: 0.3177 | val_loss: 0.00000 - val_binary_acc: 0.3468 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.009s\n",
      "| RMSProp | epoch: 015 | loss: 0.00000 - binary_acc: 0.3177 | val_loss: 0.00000 - val_binary_acc: 0.3468 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.010s\n",
      "| RMSProp | epoch: 016 | loss: 0.00000 - binary_acc: 0.3177 | val_loss: 0.00000 - val_binary_acc: 0.3468 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.008s\n",
      "| RMSProp | epoch: 017 | loss: 0.00000 - binary_acc: 0.3177 | val_loss: 0.00000 - val_binary_acc: 0.3468 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.007s\n",
      "| RMSProp | epoch: 018 | loss: 0.00000 - binary_acc: 0.3177 | val_loss: 0.00000 - val_binary_acc: 0.3468 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.009s\n",
      "| RMSProp | epoch: 019 | loss: 0.00000 - binary_acc: 0.3177 | val_loss: 0.00000 - val_binary_acc: 0.3468 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.010s\n",
      "| RMSProp | epoch: 020 | loss: 0.00000 - binary_acc: 0.3177 | val_loss: 0.00000 - val_binary_acc: 0.3468 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.007s\n",
      "| RMSProp | epoch: 021 | loss: 0.00000 - binary_acc: 0.3177 | val_loss: 0.00000 - val_binary_acc: 0.3468 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.009s\n",
      "| RMSProp | epoch: 022 | loss: 0.00000 - binary_acc: 0.3177 | val_loss: 0.00000 - val_binary_acc: 0.3468 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.010s\n",
      "| RMSProp | epoch: 023 | loss: 0.00000 - binary_acc: 0.3177 | val_loss: 0.00000 - val_binary_acc: 0.3468 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.009s\n",
      "| RMSProp | epoch: 024 | loss: 0.00000 - binary_acc: 0.3177 | val_loss: 0.00000 - val_binary_acc: 0.3468 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.006s\n",
      "| RMSProp | epoch: 025 | loss: 0.00000 - binary_acc: 0.3177 | val_loss: 0.00000 - val_binary_acc: 0.3468 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.009s\n",
      "| RMSProp | epoch: 026 | loss: 0.00000 - binary_acc: 0.3177 | val_loss: 0.00000 - val_binary_acc: 0.3468 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.010s\n",
      "| RMSProp | epoch: 027 | loss: 0.00000 - binary_acc: 0.3177 | val_loss: 0.00000 - val_binary_acc: 0.3468 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.008s\n",
      "| RMSProp | epoch: 028 | loss: 0.00000 - binary_acc: 0.3177 | val_loss: 0.00000 - val_binary_acc: 0.3468 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.008s\n",
      "| RMSProp | epoch: 029 | loss: 0.00000 - binary_acc: 0.3177 | val_loss: 0.00000 - val_binary_acc: 0.3468 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.013s\n",
      "| RMSProp | epoch: 030 | loss: 0.00000 - binary_acc: 0.3177 | val_loss: 0.00000 - val_binary_acc: 0.3468 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'softmax', 10, [0.3002028369758482]]\n",
      "RMSProp\n",
      "softmax\n",
      "5\n",
      "---------------------------------\n",
      "Run id: MZPKJ8\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.128s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.007s\n",
      "| RMSProp | epoch: 002 | loss: 0.00000 - binary_acc: 0.2956 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.008s\n",
      "| RMSProp | epoch: 003 | loss: 0.00000 - binary_acc: 0.3225 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.009s\n",
      "| RMSProp | epoch: 004 | loss: 0.00000 - binary_acc: 0.3270 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.009s\n",
      "| RMSProp | epoch: 005 | loss: 0.00000 - binary_acc: 0.3280 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.009s\n",
      "| RMSProp | epoch: 006 | loss: 0.00000 - binary_acc: 0.3283 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.008s\n",
      "| RMSProp | epoch: 007 | loss: 0.00000 - binary_acc: 0.3284 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.007s\n",
      "| RMSProp | epoch: 008 | loss: 0.00000 - binary_acc: 0.3284 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.007s\n",
      "| RMSProp | epoch: 009 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.009s\n",
      "| RMSProp | epoch: 010 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.007s\n",
      "| RMSProp | epoch: 011 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.009s\n",
      "| RMSProp | epoch: 012 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.008s\n",
      "| RMSProp | epoch: 013 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.007s\n",
      "| RMSProp | epoch: 014 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.014s\n",
      "| RMSProp | epoch: 015 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.009s\n",
      "| RMSProp | epoch: 016 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.008s\n",
      "| RMSProp | epoch: 017 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.008s\n",
      "| RMSProp | epoch: 018 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.008s\n",
      "| RMSProp | epoch: 019 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.008s\n",
      "| RMSProp | epoch: 020 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.008s\n",
      "| RMSProp | epoch: 021 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.009s\n",
      "| RMSProp | epoch: 022 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.009s\n",
      "| RMSProp | epoch: 023 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.008s\n",
      "| RMSProp | epoch: 024 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.009s\n",
      "| RMSProp | epoch: 025 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.009s\n",
      "| RMSProp | epoch: 026 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.009s\n",
      "| RMSProp | epoch: 027 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.009s\n",
      "| RMSProp | epoch: 028 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.008s\n",
      "| RMSProp | epoch: 029 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.010s\n",
      "| RMSProp | epoch: 030 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'softmax', 5, [0.3002028369758482]]\n",
      "RMSProp\n",
      "softmax\n",
      "35\n",
      "---------------------------------\n",
      "Run id: 1KEN4M\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.123s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.007s\n",
      "| RMSProp | epoch: 002 | loss: 0.00000 - binary_acc: 0.2956 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.009s\n",
      "| RMSProp | epoch: 003 | loss: 0.00000 - binary_acc: 0.3225 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.010s\n",
      "| RMSProp | epoch: 004 | loss: 0.00000 - binary_acc: 0.3270 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.010s\n",
      "| RMSProp | epoch: 005 | loss: 0.00000 - binary_acc: 0.3280 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.010s\n",
      "| RMSProp | epoch: 006 | loss: 0.00000 - binary_acc: 0.3283 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.010s\n",
      "| RMSProp | epoch: 007 | loss: 0.00000 - binary_acc: 0.3284 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.009s\n",
      "| RMSProp | epoch: 008 | loss: 0.00000 - binary_acc: 0.3284 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.010s\n",
      "| RMSProp | epoch: 009 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.010s\n",
      "| RMSProp | epoch: 010 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.010s\n",
      "| RMSProp | epoch: 011 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.011s\n",
      "| RMSProp | epoch: 012 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.010s\n",
      "| RMSProp | epoch: 013 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.011s\n",
      "| RMSProp | epoch: 014 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.010s\n",
      "| RMSProp | epoch: 015 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.011s\n",
      "| RMSProp | epoch: 016 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.010s\n",
      "| RMSProp | epoch: 017 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.011s\n",
      "| RMSProp | epoch: 018 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.011s\n",
      "| RMSProp | epoch: 019 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.010s\n",
      "| RMSProp | epoch: 020 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.011s\n",
      "| RMSProp | epoch: 021 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.010s\n",
      "| RMSProp | epoch: 022 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.010s\n",
      "| RMSProp | epoch: 023 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.010s\n",
      "| RMSProp | epoch: 024 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.010s\n",
      "| RMSProp | epoch: 025 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.011s\n",
      "| RMSProp | epoch: 026 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.011s\n",
      "| RMSProp | epoch: 027 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.011s\n",
      "| RMSProp | epoch: 028 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.011s\n",
      "| RMSProp | epoch: 029 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.011s\n",
      "| RMSProp | epoch: 030 | loss: 0.00000 - binary_acc: 0.3285 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'softmax', 35, [0.3002028369758482]]\n",
      "RMSProp\n",
      "sigmoid\n",
      "10\n",
      "---------------------------------\n",
      "Run id: MTWQST\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.114s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.006s\n",
      "| RMSProp | epoch: 002 | loss: 0.00000 - binary_acc: 0.2842 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.009s\n",
      "| RMSProp | epoch: 003 | loss: 0.00000 - binary_acc: 0.3100 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.008s\n",
      "| RMSProp | epoch: 004 | loss: 0.00000 - binary_acc: 0.3144 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.008s\n",
      "| RMSProp | epoch: 005 | loss: 0.00000 - binary_acc: 0.3153 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.008s\n",
      "| RMSProp | epoch: 006 | loss: 0.00000 - binary_acc: 0.3156 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.008s\n",
      "| RMSProp | epoch: 007 | loss: 0.00000 - binary_acc: 0.3157 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.008s\n",
      "| RMSProp | epoch: 008 | loss: 0.00000 - binary_acc: 0.3158 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.008s\n",
      "| RMSProp | epoch: 009 | loss: 0.00000 - binary_acc: 0.3158 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.008s\n",
      "| RMSProp | epoch: 010 | loss: 0.00000 - binary_acc: 0.3158 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.008s\n",
      "| RMSProp | epoch: 011 | loss: 0.00000 - binary_acc: 0.3158 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.009s\n",
      "| RMSProp | epoch: 012 | loss: 0.00000 - binary_acc: 0.3158 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.007s\n",
      "| RMSProp | epoch: 013 | loss: 0.00000 - binary_acc: 0.3158 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.009s\n",
      "| RMSProp | epoch: 014 | loss: 0.00000 - binary_acc: 0.3158 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.008s\n",
      "| RMSProp | epoch: 015 | loss: 0.00000 - binary_acc: 0.3158 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.007s\n",
      "| RMSProp | epoch: 016 | loss: 0.00000 - binary_acc: 0.3158 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.008s\n",
      "| RMSProp | epoch: 017 | loss: 0.00000 - binary_acc: 0.3158 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.008s\n",
      "| RMSProp | epoch: 018 | loss: 0.00000 - binary_acc: 0.3158 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.008s\n",
      "| RMSProp | epoch: 019 | loss: 0.00000 - binary_acc: 0.3158 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.008s\n",
      "| RMSProp | epoch: 020 | loss: 0.00000 - binary_acc: 0.3158 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.007s\n",
      "| RMSProp | epoch: 021 | loss: 0.00000 - binary_acc: 0.3158 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.008s\n",
      "| RMSProp | epoch: 022 | loss: 0.00000 - binary_acc: 0.3158 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.006s\n",
      "| RMSProp | epoch: 023 | loss: 0.00000 - binary_acc: 0.3158 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.009s\n",
      "| RMSProp | epoch: 024 | loss: 0.00000 - binary_acc: 0.3158 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.007s\n",
      "| RMSProp | epoch: 025 | loss: 0.00000 - binary_acc: 0.3158 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.007s\n",
      "| RMSProp | epoch: 026 | loss: 0.00000 - binary_acc: 0.3158 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.008s\n",
      "| RMSProp | epoch: 027 | loss: 0.00000 - binary_acc: 0.3158 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.008s\n",
      "| RMSProp | epoch: 028 | loss: 0.00000 - binary_acc: 0.3158 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.008s\n",
      "| RMSProp | epoch: 029 | loss: 0.00000 - binary_acc: 0.3158 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.009s\n",
      "| RMSProp | epoch: 030 | loss: 0.00000 - binary_acc: 0.3158 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'sigmoid', 10, [0.3002028369758482]]\n",
      "RMSProp\n",
      "sigmoid\n",
      "5\n",
      "---------------------------------\n",
      "Run id: 9T4Q6S\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.116s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.007s\n",
      "| RMSProp | epoch: 002 | loss: 0.00000 - binary_acc: 0.2922 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.008s\n",
      "| RMSProp | epoch: 003 | loss: 0.00000 - binary_acc: 0.3188 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.008s\n",
      "| RMSProp | epoch: 004 | loss: 0.00000 - binary_acc: 0.3232 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.008s\n",
      "| RMSProp | epoch: 005 | loss: 0.00000 - binary_acc: 0.3242 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.008s\n",
      "| RMSProp | epoch: 006 | loss: 0.00000 - binary_acc: 0.3245 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.008s\n",
      "| RMSProp | epoch: 007 | loss: 0.00000 - binary_acc: 0.3246 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.007s\n",
      "| RMSProp | epoch: 008 | loss: 0.00000 - binary_acc: 0.3246 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.008s\n",
      "| RMSProp | epoch: 009 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.007s\n",
      "| RMSProp | epoch: 010 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.008s\n",
      "| RMSProp | epoch: 011 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.008s\n",
      "| RMSProp | epoch: 012 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.008s\n",
      "| RMSProp | epoch: 013 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.007s\n",
      "| RMSProp | epoch: 014 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.008s\n",
      "| RMSProp | epoch: 015 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.008s\n",
      "| RMSProp | epoch: 016 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.009s\n",
      "| RMSProp | epoch: 017 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.008s\n",
      "| RMSProp | epoch: 018 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.008s\n",
      "| RMSProp | epoch: 019 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.007s\n",
      "| RMSProp | epoch: 020 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.007s\n",
      "| RMSProp | epoch: 021 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.007s\n",
      "| RMSProp | epoch: 022 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.008s\n",
      "| RMSProp | epoch: 023 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.007s\n",
      "| RMSProp | epoch: 024 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.008s\n",
      "| RMSProp | epoch: 025 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.008s\n",
      "| RMSProp | epoch: 026 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.007s\n",
      "| RMSProp | epoch: 027 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.007s\n",
      "| RMSProp | epoch: 028 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.008s\n",
      "| RMSProp | epoch: 029 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.008s\n",
      "| RMSProp | epoch: 030 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'sigmoid', 5, [0.3002028369758482]]\n",
      "RMSProp\n",
      "sigmoid\n",
      "35\n",
      "---------------------------------\n",
      "Run id: 8I0ZVD\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.112s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.007s\n",
      "| RMSProp | epoch: 002 | loss: 0.00000 - binary_acc: 0.2928 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.008s\n",
      "| RMSProp | epoch: 003 | loss: 0.00000 - binary_acc: 0.3194 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.009s\n",
      "| RMSProp | epoch: 004 | loss: 0.00000 - binary_acc: 0.3238 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.008s\n",
      "| RMSProp | epoch: 005 | loss: 0.00000 - binary_acc: 0.3248 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.010s\n",
      "| RMSProp | epoch: 006 | loss: 0.00000 - binary_acc: 0.3251 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.009s\n",
      "| RMSProp | epoch: 007 | loss: 0.00000 - binary_acc: 0.3252 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.010s\n",
      "| RMSProp | epoch: 008 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.009s\n",
      "| RMSProp | epoch: 009 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.008s\n",
      "| RMSProp | epoch: 010 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.009s\n",
      "| RMSProp | epoch: 011 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.010s\n",
      "| RMSProp | epoch: 012 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.009s\n",
      "| RMSProp | epoch: 013 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.010s\n",
      "| RMSProp | epoch: 014 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.012s\n",
      "| RMSProp | epoch: 015 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.009s\n",
      "| RMSProp | epoch: 016 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.009s\n",
      "| RMSProp | epoch: 017 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.009s\n",
      "| RMSProp | epoch: 018 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.010s\n",
      "| RMSProp | epoch: 019 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.009s\n",
      "| RMSProp | epoch: 020 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.009s\n",
      "| RMSProp | epoch: 021 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.010s\n",
      "| RMSProp | epoch: 022 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.010s\n",
      "| RMSProp | epoch: 023 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.009s\n",
      "| RMSProp | epoch: 024 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.009s\n",
      "| RMSProp | epoch: 025 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.010s\n",
      "| RMSProp | epoch: 026 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.009s\n",
      "| RMSProp | epoch: 027 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.009s\n",
      "| RMSProp | epoch: 028 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.009s\n",
      "| RMSProp | epoch: 029 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.009s\n",
      "| RMSProp | epoch: 030 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.3165 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'sigmoid', 35, [0.3002028369758482]]\n",
      "RMSProp\n",
      "tanh\n",
      "10\n",
      "---------------------------------\n",
      "Run id: 64OPQQ\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.122s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.007s\n",
      "| RMSProp | epoch: 002 | loss: 0.00000 - binary_acc: 0.3185 | val_loss: 0.00000 - val_binary_acc: 0.2582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.008s\n",
      "| RMSProp | epoch: 003 | loss: 0.00000 - binary_acc: 0.2794 | val_loss: 0.00000 - val_binary_acc: 0.2810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.008s\n",
      "| RMSProp | epoch: 004 | loss: 0.00000 - binary_acc: 0.3233 | val_loss: 0.00000 - val_binary_acc: 0.2810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.008s\n",
      "| RMSProp | epoch: 005 | loss: 0.00000 - binary_acc: 0.3023 | val_loss: 0.00000 - val_binary_acc: 0.2810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.008s\n",
      "| RMSProp | epoch: 006 | loss: 0.00000 - binary_acc: 0.3171 | val_loss: 0.00000 - val_binary_acc: 0.2810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.008s\n",
      "| RMSProp | epoch: 007 | loss: 0.00000 - binary_acc: 0.3015 | val_loss: 0.00000 - val_binary_acc: 0.2759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.009s\n",
      "| RMSProp | epoch: 008 | loss: 0.00000 - binary_acc: 0.2956 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.008s\n",
      "| RMSProp | epoch: 009 | loss: 0.00000 - binary_acc: 0.2925 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.008s\n",
      "| RMSProp | epoch: 010 | loss: 0.00000 - binary_acc: 0.3162 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.009s\n",
      "| RMSProp | epoch: 011 | loss: 0.00000 - binary_acc: 0.3055 | val_loss: 0.00000 - val_binary_acc: 0.2861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.008s\n",
      "| RMSProp | epoch: 012 | loss: 0.00000 - binary_acc: 0.3178 | val_loss: 0.00000 - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.008s\n",
      "| RMSProp | epoch: 013 | loss: 0.00000 - binary_acc: 0.3072 | val_loss: 0.00000 - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.008s\n",
      "| RMSProp | epoch: 014 | loss: 0.00000 - binary_acc: 0.3621 | val_loss: 0.00000 - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.009s\n",
      "| RMSProp | epoch: 015 | loss: 0.00000 - binary_acc: 0.3931 | val_loss: 0.00000 - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.008s\n",
      "| RMSProp | epoch: 016 | loss: 0.00000 - binary_acc: 0.4112 | val_loss: 0.00000 - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.008s\n",
      "| RMSProp | epoch: 017 | loss: 0.00000 - binary_acc: 0.4220 | val_loss: 0.00000 - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.008s\n",
      "| RMSProp | epoch: 018 | loss: 0.00000 - binary_acc: 0.4287 | val_loss: 0.00000 - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.008s\n",
      "| RMSProp | epoch: 019 | loss: 0.00000 - binary_acc: 0.4329 | val_loss: 0.00000 - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.007s\n",
      "| RMSProp | epoch: 020 | loss: 0.00000 - binary_acc: 0.4356 | val_loss: 0.00000 - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.008s\n",
      "| RMSProp | epoch: 021 | loss: 0.00000 - binary_acc: 0.4374 | val_loss: 0.00000 - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.008s\n",
      "| RMSProp | epoch: 022 | loss: 0.00000 - binary_acc: 0.4386 | val_loss: 0.00000 - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.009s\n",
      "| RMSProp | epoch: 023 | loss: 0.00000 - binary_acc: 0.4394 | val_loss: 0.00000 - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.008s\n",
      "| RMSProp | epoch: 024 | loss: 0.00000 - binary_acc: 0.4399 | val_loss: 0.00000 - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.007s\n",
      "| RMSProp | epoch: 025 | loss: 0.00000 - binary_acc: 0.4403 | val_loss: 0.00000 - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.008s\n",
      "| RMSProp | epoch: 026 | loss: 0.00000 - binary_acc: 0.4406 | val_loss: 0.00000 - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.009s\n",
      "| RMSProp | epoch: 027 | loss: 0.00000 - binary_acc: 0.4408 | val_loss: 0.00000 - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.008s\n",
      "| RMSProp | epoch: 028 | loss: 0.00000 - binary_acc: 0.4409 | val_loss: 0.00000 - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.008s\n",
      "| RMSProp | epoch: 029 | loss: 0.00000 - binary_acc: 0.4410 | val_loss: 0.00000 - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.008s\n",
      "| RMSProp | epoch: 030 | loss: 0.00000 - binary_acc: 0.4411 | val_loss: 0.00000 - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'tanh', 10, [0.45436105404132276]]\n",
      "RMSProp\n",
      "tanh\n",
      "5\n",
      "---------------------------------\n",
      "Run id: 55I9LV\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.110s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.2608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.006s\n",
      "| RMSProp | epoch: 002 | loss: 0.00000 - binary_acc: 0.3105 | val_loss: 0.00000 - val_binary_acc: 0.4076 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.010s\n",
      "| RMSProp | epoch: 003 | loss: 0.00000 - binary_acc: 0.3076 | val_loss: 0.00000 - val_binary_acc: 0.4076 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.007s\n",
      "| RMSProp | epoch: 004 | loss: 0.00000 - binary_acc: 0.4136 | val_loss: 0.00000 - val_binary_acc: 0.4076 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.007s\n",
      "| RMSProp | epoch: 005 | loss: 0.00000 - binary_acc: 0.4381 | val_loss: 0.00000 - val_binary_acc: 0.4076 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.008s\n",
      "| RMSProp | epoch: 006 | loss: 0.00000 - binary_acc: 0.4451 | val_loss: 0.00000 - val_binary_acc: 0.4076 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.008s\n",
      "| RMSProp | epoch: 007 | loss: 0.00000 - binary_acc: 0.4474 | val_loss: 0.00000 - val_binary_acc: 0.4076 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.007s\n",
      "| RMSProp | epoch: 008 | loss: 0.00000 - binary_acc: 0.4483 | val_loss: 0.00000 - val_binary_acc: 0.4076 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.008s\n",
      "| RMSProp | epoch: 009 | loss: 0.00000 - binary_acc: 0.4486 | val_loss: 0.00000 - val_binary_acc: 0.4076 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.008s\n",
      "| RMSProp | epoch: 010 | loss: 0.00000 - binary_acc: 0.4488 | val_loss: 0.00000 - val_binary_acc: 0.4076 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.007s\n",
      "| RMSProp | epoch: 011 | loss: 0.00000 - binary_acc: 0.4489 | val_loss: 0.00000 - val_binary_acc: 0.4076 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.007s\n",
      "| RMSProp | epoch: 012 | loss: 0.00000 - binary_acc: 0.4489 | val_loss: 0.00000 - val_binary_acc: 0.4076 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.007s\n",
      "| RMSProp | epoch: 013 | loss: 0.00000 - binary_acc: 0.4489 | val_loss: 0.00000 - val_binary_acc: 0.4076 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.008s\n",
      "| RMSProp | epoch: 014 | loss: 0.00000 - binary_acc: 0.4489 | val_loss: 0.00000 - val_binary_acc: 0.4076 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.007s\n",
      "| RMSProp | epoch: 015 | loss: 0.00000 - binary_acc: 0.4489 | val_loss: 0.00000 - val_binary_acc: 0.4076 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.008s\n",
      "| RMSProp | epoch: 016 | loss: 0.00000 - binary_acc: 0.4489 | val_loss: 0.00000 - val_binary_acc: 0.4076 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.008s\n",
      "| RMSProp | epoch: 017 | loss: 0.00000 - binary_acc: 0.4489 | val_loss: 0.00000 - val_binary_acc: 0.4076 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.007s\n",
      "| RMSProp | epoch: 018 | loss: 0.00000 - binary_acc: 0.4490 | val_loss: 0.00000 - val_binary_acc: 0.4076 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.007s\n",
      "| RMSProp | epoch: 019 | loss: 0.00000 - binary_acc: 0.4490 | val_loss: 0.00000 - val_binary_acc: 0.4076 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.007s\n",
      "| RMSProp | epoch: 020 | loss: 0.00000 - binary_acc: 0.4490 | val_loss: 0.00000 - val_binary_acc: 0.4076 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.007s\n",
      "| RMSProp | epoch: 021 | loss: 0.00000 - binary_acc: 0.4490 | val_loss: 0.00000 - val_binary_acc: 0.4076 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.008s\n",
      "| RMSProp | epoch: 022 | loss: 0.00000 - binary_acc: 0.4490 | val_loss: 0.00000 - val_binary_acc: 0.4076 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.007s\n",
      "| RMSProp | epoch: 023 | loss: 0.00000 - binary_acc: 0.4490 | val_loss: 0.00000 - val_binary_acc: 0.4076 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.008s\n",
      "| RMSProp | epoch: 024 | loss: 0.00000 - binary_acc: 0.4490 | val_loss: 0.00000 - val_binary_acc: 0.4076 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.007s\n",
      "| RMSProp | epoch: 025 | loss: 0.00000 - binary_acc: 0.4490 | val_loss: 0.00000 - val_binary_acc: 0.4076 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.008s\n",
      "| RMSProp | epoch: 026 | loss: 0.00000 - binary_acc: 0.4490 | val_loss: 0.00000 - val_binary_acc: 0.4076 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.008s\n",
      "| RMSProp | epoch: 027 | loss: 0.00000 - binary_acc: 0.4490 | val_loss: 0.00000 - val_binary_acc: 0.4076 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.007s\n",
      "| RMSProp | epoch: 028 | loss: 0.00000 - binary_acc: 0.4490 | val_loss: 0.00000 - val_binary_acc: 0.4076 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.007s\n",
      "| RMSProp | epoch: 029 | loss: 0.00000 - binary_acc: 0.4490 | val_loss: 0.00000 - val_binary_acc: 0.4076 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.007s\n",
      "| RMSProp | epoch: 030 | loss: 0.00000 - binary_acc: 0.4490 | val_loss: 0.00000 - val_binary_acc: 0.4076 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'tanh', 5, [0.45436105404132276]]\n",
      "RMSProp\n",
      "tanh\n",
      "35\n",
      "---------------------------------\n",
      "Run id: IR4L0L\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.132s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.5089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.008s\n",
      "| RMSProp | epoch: 002 | loss: 0.00000 - binary_acc: 0.3464 | val_loss: 0.00000 - val_binary_acc: 0.5063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.009s\n",
      "| RMSProp | epoch: 003 | loss: 0.00000 - binary_acc: 0.4656 | val_loss: 0.00000 - val_binary_acc: 0.5063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.010s\n",
      "| RMSProp | epoch: 004 | loss: 0.00000 - binary_acc: 0.4855 | val_loss: 0.00000 - val_binary_acc: 0.5063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.009s\n",
      "| RMSProp | epoch: 005 | loss: 0.00000 - binary_acc: 0.4892 | val_loss: 0.00000 - val_binary_acc: 0.5063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.010s\n",
      "| RMSProp | epoch: 006 | loss: 0.00000 - binary_acc: 0.4287 | val_loss: 0.00000 - val_binary_acc: 0.5063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.009s\n",
      "| RMSProp | epoch: 007 | loss: 0.00000 - binary_acc: 0.4659 | val_loss: 0.00000 - val_binary_acc: 0.5063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.009s\n",
      "| RMSProp | epoch: 008 | loss: 0.00000 - binary_acc: 0.4296 | val_loss: 0.00000 - val_binary_acc: 0.5063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.008s\n",
      "| RMSProp | epoch: 009 | loss: 0.00000 - binary_acc: 0.4617 | val_loss: 0.00000 - val_binary_acc: 0.5063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.010s\n",
      "| RMSProp | epoch: 010 | loss: 0.00000 - binary_acc: 0.4534 | val_loss: 0.00000 - val_binary_acc: 0.5063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.009s\n",
      "| RMSProp | epoch: 011 | loss: 0.00000 - binary_acc: 0.4717 | val_loss: 0.00000 - val_binary_acc: 0.5063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.010s\n",
      "| RMSProp | epoch: 012 | loss: 0.00000 - binary_acc: 0.4255 | val_loss: 0.00000 - val_binary_acc: 0.5063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.009s\n",
      "| RMSProp | epoch: 013 | loss: 0.00000 - binary_acc: 0.4540 | val_loss: 0.00000 - val_binary_acc: 0.5089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.010s\n",
      "| RMSProp | epoch: 014 | loss: 0.00000 - binary_acc: 0.4582 | val_loss: 0.00000 - val_binary_acc: 0.5089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.009s\n",
      "| RMSProp | epoch: 015 | loss: 0.00000 - binary_acc: 0.4712 | val_loss: 0.00000 - val_binary_acc: 0.5089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.010s\n",
      "| RMSProp | epoch: 016 | loss: 0.00000 - binary_acc: 0.4564 | val_loss: 0.00000 - val_binary_acc: 0.5114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.009s\n",
      "| RMSProp | epoch: 017 | loss: 0.00000 - binary_acc: 0.4690 | val_loss: 0.00000 - val_binary_acc: 0.5114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.009s\n",
      "| RMSProp | epoch: 018 | loss: 0.00000 - binary_acc: 0.4775 | val_loss: 0.00000 - val_binary_acc: 0.5114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.009s\n",
      "| RMSProp | epoch: 019 | loss: 0.00000 - binary_acc: 0.4827 | val_loss: 0.00000 - val_binary_acc: 0.5114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.009s\n",
      "| RMSProp | epoch: 020 | loss: 0.00000 - binary_acc: 0.4635 | val_loss: 0.00000 - val_binary_acc: 0.5114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.009s\n",
      "| RMSProp | epoch: 021 | loss: 0.00000 - binary_acc: 0.4730 | val_loss: 0.00000 - val_binary_acc: 0.5114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.010s\n",
      "| RMSProp | epoch: 022 | loss: 0.00000 - binary_acc: 0.4597 | val_loss: 0.00000 - val_binary_acc: 0.5114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.008s\n",
      "| RMSProp | epoch: 023 | loss: 0.00000 - binary_acc: 0.4700 | val_loss: 0.00000 - val_binary_acc: 0.5139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.009s\n",
      "| RMSProp | epoch: 024 | loss: 0.00000 - binary_acc: 0.4523 | val_loss: 0.00000 - val_binary_acc: 0.5139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.011s\n",
      "| RMSProp | epoch: 025 | loss: 0.00000 - binary_acc: 0.4635 | val_loss: 0.00000 - val_binary_acc: 0.5114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.009s\n",
      "| RMSProp | epoch: 026 | loss: 0.00000 - binary_acc: 0.4484 | val_loss: 0.00000 - val_binary_acc: 0.5114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.009s\n",
      "| RMSProp | epoch: 027 | loss: 0.00000 - binary_acc: 0.4585 | val_loss: 0.00000 - val_binary_acc: 0.5139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.008s\n",
      "| RMSProp | epoch: 028 | loss: 0.00000 - binary_acc: 0.4482 | val_loss: 0.00000 - val_binary_acc: 0.5139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.009s\n",
      "| RMSProp | epoch: 029 | loss: 0.00000 - binary_acc: 0.4581 | val_loss: 0.00000 - val_binary_acc: 0.5114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.009s\n",
      "| RMSProp | epoch: 030 | loss: 0.00000 - binary_acc: 0.4444 | val_loss: 0.00000 - val_binary_acc: 0.5139 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'tanh', 35, [0.47870182368382963]]\n",
      "RMSProp\n",
      "prelu\n",
      "10\n",
      "---------------------------------\n",
      "Run id: 8PMQGC\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.184s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 002 | loss: nan - binary_acc: 0.3932 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 003 | loss: nan - binary_acc: 0.4316 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 004 | loss: nan - binary_acc: 0.4379 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 005 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 006 | loss: nan - binary_acc: 0.4398 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 007 | loss: nan - binary_acc: 0.4400 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 008 | loss: nan - binary_acc: 0.4400 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 009 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 010 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 011 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 012 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 013 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 014 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 015 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 016 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 017 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 018 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 019 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 020 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| RMSProp | epoch: 021 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 022 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 023 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 024 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 025 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 026 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 027 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 028 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.006s\n",
      "| RMSProp | epoch: 029 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 030 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'prelu', 10, [0.45436105404132276]]\n",
      "RMSProp\n",
      "prelu\n",
      "5\n",
      "---------------------------------\n",
      "Run id: MHFG4U\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.235s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 002 | loss: nan - binary_acc: 0.2859 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 003 | loss: nan - binary_acc: 0.4152 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 004 | loss: nan - binary_acc: 0.4367 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 005 | loss: nan - binary_acc: 0.4417 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 006 | loss: nan - binary_acc: 0.4431 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 007 | loss: nan - binary_acc: 0.4436 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 008 | loss: nan - binary_acc: 0.4437 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 009 | loss: nan - binary_acc: 0.4438 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 010 | loss: nan - binary_acc: 0.4438 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| RMSProp | epoch: 011 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 012 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 013 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 014 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 015 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 016 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 017 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 018 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 019 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 020 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 021 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 022 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 023 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 024 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 025 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 026 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 027 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 028 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 029 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| RMSProp | epoch: 030 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'prelu', 5, [0.45436105404132276]]\n",
      "RMSProp\n",
      "prelu\n",
      "35\n",
      "---------------------------------\n",
      "Run id: THIX2S\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.203s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| RMSProp | epoch: 002 | loss: nan - binary_acc: 0.3921 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| RMSProp | epoch: 003 | loss: nan - binary_acc: 0.4319 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| RMSProp | epoch: 004 | loss: nan - binary_acc: 0.4385 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 005 | loss: nan - binary_acc: 0.4400 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| RMSProp | epoch: 006 | loss: nan - binary_acc: 0.4405 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| RMSProp | epoch: 007 | loss: nan - binary_acc: 0.4406 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| RMSProp | epoch: 008 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 009 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| RMSProp | epoch: 010 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 011 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 012 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| RMSProp | epoch: 013 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| RMSProp | epoch: 014 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| RMSProp | epoch: 015 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 016 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| RMSProp | epoch: 017 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 018 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 019 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 020 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| RMSProp | epoch: 021 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| RMSProp | epoch: 022 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 023 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| RMSProp | epoch: 024 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 025 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| RMSProp | epoch: 026 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 027 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| RMSProp | epoch: 028 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| RMSProp | epoch: 029 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| RMSProp | epoch: 030 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'prelu', 35, [0.45436105404132276]]\n",
      "AdaGrad\n",
      "relu\n",
      "10\n",
      "---------------------------------\n",
      "Run id: Z0NORR\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.124s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaGrad | epoch: 002 | loss: nan - binary_acc: 0.4001 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 003 | loss: nan - binary_acc: 0.4364 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 004 | loss: nan - binary_acc: 0.4425 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 005 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 006 | loss: nan - binary_acc: 0.4443 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 007 | loss: nan - binary_acc: 0.4444 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 008 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 009 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 010 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 011 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 012 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 013 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 014 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaGrad | epoch: 015 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaGrad | epoch: 016 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaGrad | epoch: 017 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 018 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 019 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.006s\n",
      "| AdaGrad | epoch: 020 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 021 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaGrad | epoch: 022 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaGrad | epoch: 023 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 024 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 025 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaGrad | epoch: 026 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaGrad | epoch: 027 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 028 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaGrad | epoch: 029 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 030 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'relu', 10, [0.45436105404132276]]\n",
      "AdaGrad\n",
      "relu\n",
      "5\n",
      "---------------------------------\n",
      "Run id: TETCGP\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.153s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaGrad | epoch: 002 | loss: nan - binary_acc: 0.2956 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 003 | loss: nan - binary_acc: 0.4169 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 004 | loss: nan - binary_acc: 0.4371 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 005 | loss: nan - binary_acc: 0.4418 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 006 | loss: nan - binary_acc: 0.4431 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 007 | loss: nan - binary_acc: 0.4436 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 008 | loss: nan - binary_acc: 0.4438 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 009 | loss: nan - binary_acc: 0.4438 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 010 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 011 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 012 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 013 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 014 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 015 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 016 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 017 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 018 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 019 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 020 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 021 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaGrad | epoch: 022 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 023 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaGrad | epoch: 024 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 025 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaGrad | epoch: 026 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 027 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 028 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 029 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 030 | loss: nan - binary_acc: 0.4439 | val_loss: nan - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'relu', 5, [0.45436105404132276]]\n",
      "AdaGrad\n",
      "relu\n",
      "35\n",
      "---------------------------------\n",
      "Run id: 081GLC\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.113s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.008s\n",
      "| AdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.2905 | val_loss: nan - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 003 | loss: nan - binary_acc: 0.3164 | val_loss: nan - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 004 | loss: nan - binary_acc: 0.4058 | val_loss: nan - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 005 | loss: nan - binary_acc: 0.4265 | val_loss: nan - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 006 | loss: nan - binary_acc: 0.4324 | val_loss: nan - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 007 | loss: nan - binary_acc: 0.4343 | val_loss: nan - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 008 | loss: nan - binary_acc: 0.4351 | val_loss: nan - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaGrad | epoch: 009 | loss: nan - binary_acc: 0.4354 | val_loss: nan - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 010 | loss: nan - binary_acc: 0.4355 | val_loss: nan - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 011 | loss: nan - binary_acc: 0.4356 | val_loss: nan - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 012 | loss: nan - binary_acc: 0.4356 | val_loss: nan - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 013 | loss: nan - binary_acc: 0.4356 | val_loss: nan - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 014 | loss: nan - binary_acc: 0.4356 | val_loss: nan - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 015 | loss: nan - binary_acc: 0.4356 | val_loss: nan - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 016 | loss: nan - binary_acc: 0.4356 | val_loss: nan - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 017 | loss: nan - binary_acc: 0.4356 | val_loss: nan - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 018 | loss: nan - binary_acc: 0.4356 | val_loss: nan - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 019 | loss: nan - binary_acc: 0.4356 | val_loss: nan - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 020 | loss: nan - binary_acc: 0.4356 | val_loss: nan - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 021 | loss: nan - binary_acc: 0.4356 | val_loss: nan - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 022 | loss: nan - binary_acc: 0.4356 | val_loss: nan - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 023 | loss: nan - binary_acc: 0.4356 | val_loss: nan - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 024 | loss: nan - binary_acc: 0.4356 | val_loss: nan - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 025 | loss: nan - binary_acc: 0.4356 | val_loss: nan - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 026 | loss: nan - binary_acc: 0.4356 | val_loss: nan - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 027 | loss: nan - binary_acc: 0.4356 | val_loss: nan - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 028 | loss: nan - binary_acc: 0.4356 | val_loss: nan - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 029 | loss: nan - binary_acc: 0.4356 | val_loss: nan - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 030 | loss: nan - binary_acc: 0.4356 | val_loss: nan - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'relu', 35, [0.45436105404132276]]\n",
      "AdaGrad\n",
      "linear\n",
      "10\n",
      "---------------------------------\n",
      "Run id: 2VZK4D\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.108s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.006s\n",
      "| AdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.3658 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.008s\n",
      "| AdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.4530 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.007s\n",
      "| AdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3491 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.007s\n",
      "| AdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.3252 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.007s\n",
      "| AdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3183 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.007s\n",
      "| AdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.3160 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.008s\n",
      "| AdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3152 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.008s\n",
      "| AdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.3148 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.008s\n",
      "| AdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3147 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.008s\n",
      "| AdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.3146 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.008s\n",
      "| AdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3146 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.008s\n",
      "| AdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.007s\n",
      "| AdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.008s\n",
      "| AdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.007s\n",
      "| AdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.008s\n",
      "| AdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.008s\n",
      "| AdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.008s\n",
      "| AdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.008s\n",
      "| AdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.008s\n",
      "| AdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.008s\n",
      "| AdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.008s\n",
      "| AdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.008s\n",
      "| AdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.007s\n",
      "| AdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.008s\n",
      "| AdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.008s\n",
      "| AdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.008s\n",
      "| AdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.008s\n",
      "| AdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.008s\n",
      "| AdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3145 | val_loss: 0.00000 - val_binary_acc: 0.3595 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'linear', 10, [0.3002028369758482]]\n",
      "AdaGrad\n",
      "linear\n",
      "5\n",
      "---------------------------------\n",
      "Run id: QAYC06\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.109s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.006s\n",
      "| AdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.3373 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.008s\n",
      "| AdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.3327 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.008s\n",
      "| AdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3319 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.008s\n",
      "| AdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.3317 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.009s\n",
      "| AdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3317 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.008s\n",
      "| AdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.3317 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.007s\n",
      "| AdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.008s\n",
      "| AdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.007s\n",
      "| AdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.008s\n",
      "| AdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.009s\n",
      "| AdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.007s\n",
      "| AdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.007s\n",
      "| AdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.008s\n",
      "| AdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.008s\n",
      "| AdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.007s\n",
      "| AdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.007s\n",
      "| AdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.007s\n",
      "| AdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.007s\n",
      "| AdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.007s\n",
      "| AdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.007s\n",
      "| AdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.007s\n",
      "| AdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.008s\n",
      "| AdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.008s\n",
      "| AdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.008s\n",
      "| AdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.008s\n",
      "| AdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.008s\n",
      "| AdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.007s\n",
      "| AdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.008s\n",
      "| AdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'linear', 5, [0.3002028369758482]]\n",
      "AdaGrad\n",
      "linear\n",
      "35\n",
      "---------------------------------\n",
      "Run id: M9R2WM\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.110s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.2608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.007s\n",
      "| AdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.3150 | val_loss: 0.00000 - val_binary_acc: 0.2608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.008s\n",
      "| AdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.2783 | val_loss: 0.00000 - val_binary_acc: 0.2608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.009s\n",
      "| AdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3392 | val_loss: 0.00000 - val_binary_acc: 0.2608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.009s\n",
      "| AdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.2914 | val_loss: 0.00000 - val_binary_acc: 0.2658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.008s\n",
      "| AdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.2789 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.008s\n",
      "| AdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.3155 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.008s\n",
      "| AdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3160 | val_loss: 0.00000 - val_binary_acc: 0.2658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.009s\n",
      "| AdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.2927 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.009s\n",
      "| AdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.2982 | val_loss: 0.00000 - val_binary_acc: 0.2658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.009s\n",
      "| AdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.2849 | val_loss: 0.00000 - val_binary_acc: 0.2658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.009s\n",
      "| AdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.2905 | val_loss: 0.00000 - val_binary_acc: 0.2684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.008s\n",
      "| AdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.2823 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.009s\n",
      "| AdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3144 | val_loss: 0.00000 - val_binary_acc: 0.2608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.008s\n",
      "| AdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.3001 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.009s\n",
      "| AdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3198 | val_loss: 0.00000 - val_binary_acc: 0.2658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.009s\n",
      "| AdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.3019 | val_loss: 0.00000 - val_binary_acc: 0.2658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.009s\n",
      "| AdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3085 | val_loss: 0.00000 - val_binary_acc: 0.2658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.009s\n",
      "| AdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.2963 | val_loss: 0.00000 - val_binary_acc: 0.2658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.008s\n",
      "| AdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3058 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.009s\n",
      "| AdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.2952 | val_loss: 0.00000 - val_binary_acc: 0.2684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.009s\n",
      "| AdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3101 | val_loss: 0.00000 - val_binary_acc: 0.2684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.009s\n",
      "| AdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.3042 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.008s\n",
      "| AdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3110 | val_loss: 0.00000 - val_binary_acc: 0.2684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.008s\n",
      "| AdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3040 | val_loss: 0.00000 - val_binary_acc: 0.2684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.008s\n",
      "| AdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3154 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.009s\n",
      "| AdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.3088 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.009s\n",
      "| AdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3118 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.009s\n",
      "| AdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.3078 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.010s\n",
      "| AdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3139 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'linear', 35, [0.28194726202599174]]\n",
      "AdaGrad\n",
      "softmax\n",
      "10\n",
      "---------------------------------\n",
      "Run id: W4IBQ4\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.121s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.008s\n",
      "| AdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.2922 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.009s\n",
      "| AdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.3188 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.012s\n",
      "| AdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3232 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.008s\n",
      "| AdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.3242 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.009s\n",
      "| AdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3245 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.008s\n",
      "| AdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.3246 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.009s\n",
      "| AdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3246 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.009s\n",
      "| AdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.009s\n",
      "| AdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.008s\n",
      "| AdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.009s\n",
      "| AdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.009s\n",
      "| AdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.010s\n",
      "| AdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.008s\n",
      "| AdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.008s\n",
      "| AdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.009s\n",
      "| AdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.009s\n",
      "| AdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.009s\n",
      "| AdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.008s\n",
      "| AdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.009s\n",
      "| AdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.009s\n",
      "| AdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.009s\n",
      "| AdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.009s\n",
      "| AdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.009s\n",
      "| AdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.009s\n",
      "| AdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.008s\n",
      "| AdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.009s\n",
      "| AdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.009s\n",
      "| AdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.008s\n",
      "| AdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'softmax', 10, [0.3002028369758482]]\n",
      "AdaGrad\n",
      "softmax\n",
      "5\n",
      "---------------------------------\n",
      "Run id: PZAN78\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.116s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.007s\n",
      "| AdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.2871 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.009s\n",
      "| AdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.3132 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.009s\n",
      "| AdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3175 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.008s\n",
      "| AdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.3185 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.009s\n",
      "| AdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3188 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.008s\n",
      "| AdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.3189 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.009s\n",
      "| AdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3189 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.009s\n",
      "| AdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.3189 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.009s\n",
      "| AdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.009s\n",
      "| AdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.009s\n",
      "| AdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.008s\n",
      "| AdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.008s\n",
      "| AdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.009s\n",
      "| AdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.008s\n",
      "| AdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.009s\n",
      "| AdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.008s\n",
      "| AdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.008s\n",
      "| AdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.009s\n",
      "| AdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.009s\n",
      "| AdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.009s\n",
      "| AdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.009s\n",
      "| AdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.009s\n",
      "| AdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.008s\n",
      "| AdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.008s\n",
      "| AdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.008s\n",
      "| AdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.009s\n",
      "| AdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.008s\n",
      "| AdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.008s\n",
      "| AdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'softmax', 5, [0.3002028369758482]]\n",
      "AdaGrad\n",
      "softmax\n",
      "35\n",
      "---------------------------------\n",
      "Run id: SM0KB6\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.132s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3671 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.009s\n",
      "| AdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.2814 | val_loss: 0.00000 - val_binary_acc: 0.3671 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.010s\n",
      "| AdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.3069 | val_loss: 0.00000 - val_binary_acc: 0.3671 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.011s\n",
      "| AdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3112 | val_loss: 0.00000 - val_binary_acc: 0.3671 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.011s\n",
      "| AdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.3122 | val_loss: 0.00000 - val_binary_acc: 0.3671 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.010s\n",
      "| AdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3125 | val_loss: 0.00000 - val_binary_acc: 0.3671 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.010s\n",
      "| AdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.3126 | val_loss: 0.00000 - val_binary_acc: 0.3671 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.011s\n",
      "| AdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3126 | val_loss: 0.00000 - val_binary_acc: 0.3671 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.010s\n",
      "| AdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.3126 | val_loss: 0.00000 - val_binary_acc: 0.3671 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.011s\n",
      "| AdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3126 | val_loss: 0.00000 - val_binary_acc: 0.3671 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.010s\n",
      "| AdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.3126 | val_loss: 0.00000 - val_binary_acc: 0.3671 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.011s\n",
      "| AdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3126 | val_loss: 0.00000 - val_binary_acc: 0.3671 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.010s\n",
      "| AdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.3126 | val_loss: 0.00000 - val_binary_acc: 0.3671 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.011s\n",
      "| AdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3126 | val_loss: 0.00000 - val_binary_acc: 0.3671 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.010s\n",
      "| AdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.3126 | val_loss: 0.00000 - val_binary_acc: 0.3671 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.010s\n",
      "| AdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3126 | val_loss: 0.00000 - val_binary_acc: 0.3671 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.010s\n",
      "| AdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.3126 | val_loss: 0.00000 - val_binary_acc: 0.3671 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.010s\n",
      "| AdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3126 | val_loss: 0.00000 - val_binary_acc: 0.3671 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.010s\n",
      "| AdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.3126 | val_loss: 0.00000 - val_binary_acc: 0.3671 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.011s\n",
      "| AdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3126 | val_loss: 0.00000 - val_binary_acc: 0.3671 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.010s\n",
      "| AdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.3126 | val_loss: 0.00000 - val_binary_acc: 0.3671 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.010s\n",
      "| AdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3126 | val_loss: 0.00000 - val_binary_acc: 0.3671 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.011s\n",
      "| AdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.3126 | val_loss: 0.00000 - val_binary_acc: 0.3671 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.010s\n",
      "| AdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3126 | val_loss: 0.00000 - val_binary_acc: 0.3671 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.010s\n",
      "| AdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3126 | val_loss: 0.00000 - val_binary_acc: 0.3671 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.010s\n",
      "| AdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3126 | val_loss: 0.00000 - val_binary_acc: 0.3671 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.010s\n",
      "| AdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.3126 | val_loss: 0.00000 - val_binary_acc: 0.3671 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.010s\n",
      "| AdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3126 | val_loss: 0.00000 - val_binary_acc: 0.3671 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.011s\n",
      "| AdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.3126 | val_loss: 0.00000 - val_binary_acc: 0.3671 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.011s\n",
      "| AdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3126 | val_loss: 0.00000 - val_binary_acc: 0.3671 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'softmax', 35, [0.3002028369758482]]\n",
      "AdaGrad\n",
      "sigmoid\n",
      "10\n",
      "---------------------------------\n",
      "Run id: K0NMI5\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.116s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.006s\n",
      "| AdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.2871 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.009s\n",
      "| AdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.3132 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.015s\n",
      "| AdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3175 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.008s\n",
      "| AdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.3185 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.008s\n",
      "| AdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3188 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.008s\n",
      "| AdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.3189 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.008s\n",
      "| AdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3189 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.008s\n",
      "| AdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.3189 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.008s\n",
      "| AdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.008s\n",
      "| AdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.008s\n",
      "| AdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.008s\n",
      "| AdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.008s\n",
      "| AdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.008s\n",
      "| AdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.008s\n",
      "| AdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.008s\n",
      "| AdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.008s\n",
      "| AdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.007s\n",
      "| AdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.007s\n",
      "| AdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.007s\n",
      "| AdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.008s\n",
      "| AdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.007s\n",
      "| AdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.008s\n",
      "| AdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.008s\n",
      "| AdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.008s\n",
      "| AdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.008s\n",
      "| AdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.008s\n",
      "| AdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.008s\n",
      "| AdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.008s\n",
      "| AdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'sigmoid', 10, [0.3002028369758482]]\n",
      "AdaGrad\n",
      "sigmoid\n",
      "5\n",
      "---------------------------------\n",
      "Run id: CW8NC1\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.124s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.006s\n",
      "| AdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.2973 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.008s\n",
      "| AdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.3244 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.008s\n",
      "| AdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3289 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.008s\n",
      "| AdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.3299 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.007s\n",
      "| AdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3302 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.008s\n",
      "| AdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.3303 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.008s\n",
      "| AdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3303 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.008s\n",
      "| AdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.3304 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.008s\n",
      "| AdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3304 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.007s\n",
      "| AdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.3304 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.007s\n",
      "| AdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3304 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.008s\n",
      "| AdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.3304 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.007s\n",
      "| AdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3304 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.007s\n",
      "| AdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.3304 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.007s\n",
      "| AdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3304 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.008s\n",
      "| AdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.3304 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.008s\n",
      "| AdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3304 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.007s\n",
      "| AdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.3304 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.008s\n",
      "| AdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3304 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.007s\n",
      "| AdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.3304 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.008s\n",
      "| AdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3304 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.008s\n",
      "| AdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.3304 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.008s\n",
      "| AdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3304 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.007s\n",
      "| AdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3304 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.008s\n",
      "| AdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3304 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.008s\n",
      "| AdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.3304 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.008s\n",
      "| AdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3304 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.007s\n",
      "| AdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.3304 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.008s\n",
      "| AdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3304 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'sigmoid', 5, [0.3002028369758482]]\n",
      "AdaGrad\n",
      "sigmoid\n",
      "35\n",
      "---------------------------------\n",
      "Run id: 0Y5945\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.120s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.009s\n",
      "| AdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.2945 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.009s\n",
      "| AdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.3213 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.009s\n",
      "| AdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3257 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.009s\n",
      "| AdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.3267 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.009s\n",
      "| AdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3270 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.009s\n",
      "| AdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.3271 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.009s\n",
      "| AdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.009s\n",
      "| AdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.010s\n",
      "| AdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.008s\n",
      "| AdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.009s\n",
      "| AdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.009s\n",
      "| AdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.009s\n",
      "| AdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.009s\n",
      "| AdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.009s\n",
      "| AdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.009s\n",
      "| AdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.009s\n",
      "| AdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.009s\n",
      "| AdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.009s\n",
      "| AdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.009s\n",
      "| AdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.009s\n",
      "| AdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.009s\n",
      "| AdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.009s\n",
      "| AdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.008s\n",
      "| AdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.010s\n",
      "| AdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.009s\n",
      "| AdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.008s\n",
      "| AdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.008s\n",
      "| AdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.010s\n",
      "| AdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'sigmoid', 35, [0.3002028369758482]]\n",
      "AdaGrad\n",
      "tanh\n",
      "10\n",
      "---------------------------------\n",
      "Run id: KKZZ03\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.114s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.5063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.006s\n",
      "| AdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.3687 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.008s\n",
      "| AdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.4702 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.007s\n",
      "| AdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3553 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.008s\n",
      "| AdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.3288 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.007s\n",
      "| AdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3213 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.008s\n",
      "| AdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.3187 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.008s\n",
      "| AdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3178 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.007s\n",
      "| AdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.3174 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.008s\n",
      "| AdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3172 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.008s\n",
      "| AdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.3171 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.008s\n",
      "| AdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3171 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.009s\n",
      "| AdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.3171 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.008s\n",
      "| AdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3171 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.008s\n",
      "| AdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.3171 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.008s\n",
      "| AdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3171 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.008s\n",
      "| AdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.3171 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.007s\n",
      "| AdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3171 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.008s\n",
      "| AdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.3171 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.008s\n",
      "| AdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3171 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.008s\n",
      "| AdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.3171 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.008s\n",
      "| AdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3171 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.008s\n",
      "| AdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.3171 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.008s\n",
      "| AdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3171 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.009s\n",
      "| AdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3171 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.008s\n",
      "| AdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3171 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.008s\n",
      "| AdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.3171 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.008s\n",
      "| AdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3171 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.008s\n",
      "| AdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.3171 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.008s\n",
      "| AdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3171 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'tanh', 10, [0.3002028369758482]]\n",
      "AdaGrad\n",
      "tanh\n",
      "5\n",
      "---------------------------------\n",
      "Run id: UFGTV1\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.120s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.4759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.007s\n",
      "| AdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.3527 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.008s\n",
      "| AdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.4750 | val_loss: 0.00000 - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.008s\n",
      "| AdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.4569 | val_loss: 0.00000 - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.008s\n",
      "| AdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.4690 | val_loss: 0.00000 - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.007s\n",
      "| AdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.4435 | val_loss: 0.00000 - val_binary_acc: 0.4203 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.008s\n",
      "| AdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.4597 | val_loss: 0.00000 - val_binary_acc: 0.4203 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.008s\n",
      "| AdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.4522 | val_loss: 0.00000 - val_binary_acc: 0.4203 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.008s\n",
      "| AdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.4495 | val_loss: 0.00000 - val_binary_acc: 0.4203 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.007s\n",
      "| AdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.4480 | val_loss: 0.00000 - val_binary_acc: 0.4203 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.008s\n",
      "| AdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.4475 | val_loss: 0.00000 - val_binary_acc: 0.4203 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.007s\n",
      "| AdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.4467 | val_loss: 0.00000 - val_binary_acc: 0.4203 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.008s\n",
      "| AdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.4463 | val_loss: 0.00000 - val_binary_acc: 0.4203 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.008s\n",
      "| AdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.4461 | val_loss: 0.00000 - val_binary_acc: 0.4203 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.007s\n",
      "| AdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.4462 | val_loss: 0.00000 - val_binary_acc: 0.4203 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.008s\n",
      "| AdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.4463 | val_loss: 0.00000 - val_binary_acc: 0.4203 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.008s\n",
      "| AdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.4463 | val_loss: 0.00000 - val_binary_acc: 0.4203 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.008s\n",
      "| AdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.4459 | val_loss: 0.00000 - val_binary_acc: 0.4203 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.008s\n",
      "| AdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.4461 | val_loss: 0.00000 - val_binary_acc: 0.4203 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.008s\n",
      "| AdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.4458 | val_loss: 0.00000 - val_binary_acc: 0.4203 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.008s\n",
      "| AdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.4462 | val_loss: 0.00000 - val_binary_acc: 0.4203 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.008s\n",
      "| AdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.4464 | val_loss: 0.00000 - val_binary_acc: 0.4203 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.008s\n",
      "| AdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.4466 | val_loss: 0.00000 - val_binary_acc: 0.4203 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.007s\n",
      "| AdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.4462 | val_loss: 0.00000 - val_binary_acc: 0.4203 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.008s\n",
      "| AdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.4464 | val_loss: 0.00000 - val_binary_acc: 0.4203 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.008s\n",
      "| AdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.4463 | val_loss: 0.00000 - val_binary_acc: 0.4203 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.008s\n",
      "| AdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.4465 | val_loss: 0.00000 - val_binary_acc: 0.4203 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.008s\n",
      "| AdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.4461 | val_loss: 0.00000 - val_binary_acc: 0.4203 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.008s\n",
      "| AdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.4462 | val_loss: 0.00000 - val_binary_acc: 0.4203 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.008s\n",
      "| AdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.4458 | val_loss: 0.00000 - val_binary_acc: 0.4203 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'tanh', 5, [0.45841784917316863]]\n",
      "AdaGrad\n",
      "tanh\n",
      "35\n",
      "---------------------------------\n",
      "Run id: NE4219\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.121s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.008s\n",
      "| AdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.2911 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.009s\n",
      "| AdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.2641 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.010s\n",
      "| AdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3442 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.008s\n",
      "| AdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.2850 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.009s\n",
      "| AdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3207 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.008s\n",
      "| AdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.2835 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.009s\n",
      "| AdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3320 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.010s\n",
      "| AdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.2932 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.009s\n",
      "| AdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3273 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.009s\n",
      "| AdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.2948 | val_loss: 0.00000 - val_binary_acc: 0.2886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.009s\n",
      "| AdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3182 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.009s\n",
      "| AdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.2930 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.010s\n",
      "| AdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3220 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.009s\n",
      "| AdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.2975 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.009s\n",
      "| AdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3241 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.009s\n",
      "| AdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.3001 | val_loss: 0.00000 - val_binary_acc: 0.2987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.010s\n",
      "| AdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.2856 | val_loss: 0.00000 - val_binary_acc: 0.2987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.009s\n",
      "| AdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.2762 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.010s\n",
      "| AdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.2932 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.010s\n",
      "| AdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.2821 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.009s\n",
      "| AdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.2943 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.009s\n",
      "| AdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.2836 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.009s\n",
      "| AdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.2927 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.009s\n",
      "| AdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.2834 | val_loss: 0.00000 - val_binary_acc: 0.2987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.009s\n",
      "| AdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.2918 | val_loss: 0.00000 - val_binary_acc: 0.2987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.009s\n",
      "| AdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.2835 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.010s\n",
      "| AdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.2950 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.009s\n",
      "| AdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.2865 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.009s\n",
      "| AdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.2912 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'tanh', 35, [0.2616632843718809]]\n",
      "AdaGrad\n",
      "prelu\n",
      "10\n",
      "---------------------------------\n",
      "Run id: 2FFDGU\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.163s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 002 | loss: nan - binary_acc: 0.3961 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 003 | loss: nan - binary_acc: 0.4362 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 004 | loss: nan - binary_acc: 0.4429 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 005 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 006 | loss: nan - binary_acc: 0.4449 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 007 | loss: nan - binary_acc: 0.4451 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 008 | loss: nan - binary_acc: 0.4451 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 009 | loss: nan - binary_acc: 0.4451 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaGrad | epoch: 010 | loss: nan - binary_acc: 0.4451 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| AdaGrad | epoch: 011 | loss: nan - binary_acc: 0.4451 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 012 | loss: nan - binary_acc: 0.4451 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 013 | loss: nan - binary_acc: 0.4451 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 014 | loss: nan - binary_acc: 0.4451 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 015 | loss: nan - binary_acc: 0.4451 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 016 | loss: nan - binary_acc: 0.4451 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 017 | loss: nan - binary_acc: 0.4451 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 018 | loss: nan - binary_acc: 0.4451 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 019 | loss: nan - binary_acc: 0.4451 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 020 | loss: nan - binary_acc: 0.4451 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 021 | loss: nan - binary_acc: 0.4451 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 022 | loss: nan - binary_acc: 0.4451 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 023 | loss: nan - binary_acc: 0.4451 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 024 | loss: nan - binary_acc: 0.4451 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 025 | loss: nan - binary_acc: 0.4451 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 026 | loss: nan - binary_acc: 0.4451 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 027 | loss: nan - binary_acc: 0.4451 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 028 | loss: nan - binary_acc: 0.4451 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 029 | loss: nan - binary_acc: 0.4451 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 030 | loss: nan - binary_acc: 0.4451 | val_loss: nan - val_binary_acc: 0.4228 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'prelu', 10, [0.45436105404132276]]\n",
      "AdaGrad\n",
      "prelu\n",
      "5\n",
      "---------------------------------\n",
      "Run id: AEMDX9\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.166s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| AdaGrad | epoch: 002 | loss: nan - binary_acc: 0.3538 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 003 | loss: nan - binary_acc: 0.4239 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 004 | loss: nan - binary_acc: 0.4356 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 005 | loss: nan - binary_acc: 0.4382 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 006 | loss: nan - binary_acc: 0.4390 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 007 | loss: nan - binary_acc: 0.4393 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 008 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 009 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 010 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 011 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 012 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 013 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 014 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 015 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 016 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 017 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 018 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 019 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 020 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 021 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 022 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 023 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 024 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 025 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 026 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| AdaGrad | epoch: 027 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 028 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 029 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| AdaGrad | epoch: 030 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'prelu', 5, [0.45436105404132276]]\n",
      "AdaGrad\n",
      "prelu\n",
      "35\n",
      "---------------------------------\n",
      "Run id: 403QG1\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.164s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 002 | loss: nan - binary_acc: 0.3955 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 003 | loss: nan - binary_acc: 0.4356 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaGrad | epoch: 004 | loss: nan - binary_acc: 0.4423 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 005 | loss: nan - binary_acc: 0.4438 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 006 | loss: nan - binary_acc: 0.4443 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaGrad | epoch: 007 | loss: nan - binary_acc: 0.4444 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaGrad | epoch: 008 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaGrad | epoch: 009 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaGrad | epoch: 010 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 011 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaGrad | epoch: 012 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 013 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaGrad | epoch: 014 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaGrad | epoch: 015 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaGrad | epoch: 016 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 017 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 018 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaGrad | epoch: 019 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaGrad | epoch: 020 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 021 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaGrad | epoch: 022 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaGrad | epoch: 023 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaGrad | epoch: 024 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 025 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 026 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| AdaGrad | epoch: 027 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaGrad | epoch: 028 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaGrad | epoch: 029 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| AdaGrad | epoch: 030 | loss: nan - binary_acc: 0.4445 | val_loss: nan - val_binary_acc: 0.4253 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'prelu', 35, [0.45436105404132276]]\n",
      "ProximalAdaGrad\n",
      "relu\n",
      "10\n",
      "---------------------------------\n",
      "Run id: FL3GBO\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.123s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.006s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.2933 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: nan - binary_acc: 0.3127 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: nan - binary_acc: 0.4082 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: nan - binary_acc: 0.4303 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: nan - binary_acc: 0.4366 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: nan - binary_acc: 0.4387 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: nan - binary_acc: 0.4395 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: nan - binary_acc: 0.4398 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: nan - binary_acc: 0.4399 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: nan - binary_acc: 0.4400 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: nan - binary_acc: 0.4400 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'relu', 10, [0.45436105404132276]]\n",
      "ProximalAdaGrad\n",
      "relu\n",
      "5\n",
      "---------------------------------\n",
      "Run id: M5DJOM\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.113s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: nan - binary_acc: 0.3932 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: nan - binary_acc: 0.4316 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: nan - binary_acc: 0.4379 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: nan - binary_acc: 0.4394 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: nan - binary_acc: 0.4398 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: nan - binary_acc: 0.4400 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: nan - binary_acc: 0.4400 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: nan - binary_acc: 0.4401 | val_loss: nan - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'relu', 5, [0.45436105404132276]]\n",
      "ProximalAdaGrad\n",
      "relu\n",
      "35\n",
      "---------------------------------\n",
      "Run id: FQF587\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.123s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: nan - binary_acc: 0.3299 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: nan - binary_acc: 0.4174 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: nan - binary_acc: 0.4320 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: nan - binary_acc: 0.4354 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: nan - binary_acc: 0.4364 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: nan - binary_acc: 0.4367 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: nan - binary_acc: 0.4368 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: nan - binary_acc: 0.4369 | val_loss: nan - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'relu', 35, [0.45436105404132276]]\n",
      "ProximalAdaGrad\n",
      "linear\n",
      "10\n",
      "---------------------------------\n",
      "Run id: N23ZSU\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.114s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.006s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.3242 | val_loss: 0.00000 - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.4138 | val_loss: 0.00000 - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.4288 | val_loss: 0.00000 - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.4322 | val_loss: 0.00000 - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.4332 | val_loss: 0.00000 - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.4335 | val_loss: 0.00000 - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.4336 | val_loss: 0.00000 - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.4337 | val_loss: 0.00000 - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.4337 | val_loss: 0.00000 - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.4337 | val_loss: 0.00000 - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.4337 | val_loss: 0.00000 - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.4337 | val_loss: 0.00000 - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.4337 | val_loss: 0.00000 - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.4337 | val_loss: 0.00000 - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.4337 | val_loss: 0.00000 - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.4337 | val_loss: 0.00000 - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.4337 | val_loss: 0.00000 - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.4337 | val_loss: 0.00000 - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.4337 | val_loss: 0.00000 - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.4337 | val_loss: 0.00000 - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.4337 | val_loss: 0.00000 - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.4337 | val_loss: 0.00000 - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.4337 | val_loss: 0.00000 - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.4337 | val_loss: 0.00000 - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.4337 | val_loss: 0.00000 - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.4337 | val_loss: 0.00000 - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.4337 | val_loss: 0.00000 - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.4337 | val_loss: 0.00000 - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.4337 | val_loss: 0.00000 - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'linear', 10, [0.45436105404132276]]\n",
      "ProximalAdaGrad\n",
      "linear\n",
      "5\n",
      "---------------------------------\n",
      "Run id: EUPG3X\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.121s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.2608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.006s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.3367 | val_loss: 0.00000 - val_binary_acc: 0.2987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.2843 | val_loss: 0.00000 - val_binary_acc: 0.2987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3103 | val_loss: 0.00000 - val_binary_acc: 0.2987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.3172 | val_loss: 0.00000 - val_binary_acc: 0.2987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3277 | val_loss: 0.00000 - val_binary_acc: 0.2987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.2987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3224 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.3196 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.3224 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.3231 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3232 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.3233 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3233 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3234 | val_loss: 0.00000 - val_binary_acc: 0.3241 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'linear', 5, [0.3002028369758482]]\n",
      "ProximalAdaGrad\n",
      "linear\n",
      "35\n",
      "---------------------------------\n",
      "Run id: B4CXK9\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.121s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.3287 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.2647 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3040 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.2687 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3304 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.2859 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3437 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.2947 | val_loss: 0.00000 - val_binary_acc: 0.2987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3379 | val_loss: 0.00000 - val_binary_acc: 0.2987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.2974 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3057 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.2839 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3091 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.2879 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3262 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.2987 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.2851 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.2765 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3101 | val_loss: 0.00000 - val_binary_acc: 0.2810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.2940 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3289 | val_loss: 0.00000 - val_binary_acc: 0.2861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.3067 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3246 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3101 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.2810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.3091 | val_loss: 0.00000 - val_binary_acc: 0.2785 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3241 | val_loss: 0.00000 - val_binary_acc: 0.2810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.3079 | val_loss: 0.00000 - val_binary_acc: 0.2861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3185 | val_loss: 0.00000 - val_binary_acc: 0.2810 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'linear', 35, [0.2920892521527428]]\n",
      "ProximalAdaGrad\n",
      "softmax\n",
      "10\n",
      "---------------------------------\n",
      "Run id: 8ZHNOU\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.147s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.2899 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.3163 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3207 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.3217 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3220 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3221 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'softmax', 10, [0.3002028369758482]]\n",
      "ProximalAdaGrad\n",
      "softmax\n",
      "5\n",
      "---------------------------------\n",
      "Run id: SCK0JX\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.130s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.2922 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.3188 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3232 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.3242 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3245 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.3246 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3246 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'softmax', 5, [0.3002028369758482]]\n",
      "ProximalAdaGrad\n",
      "softmax\n",
      "35\n",
      "---------------------------------\n",
      "Run id: NSR2TD\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.124s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.2951 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.3219 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3263 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.3274 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3277 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.013s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3278 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'softmax', 35, [0.3002028369758482]]\n",
      "ProximalAdaGrad\n",
      "sigmoid\n",
      "10\n",
      "---------------------------------\n",
      "Run id: X1VCXY\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.125s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3342 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.2888 | val_loss: 0.00000 - val_binary_acc: 0.3342 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.006s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.3150 | val_loss: 0.00000 - val_binary_acc: 0.3342 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.006s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3194 | val_loss: 0.00000 - val_binary_acc: 0.3342 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.3204 | val_loss: 0.00000 - val_binary_acc: 0.3342 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3207 | val_loss: 0.00000 - val_binary_acc: 0.3342 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.3208 | val_loss: 0.00000 - val_binary_acc: 0.3342 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3208 | val_loss: 0.00000 - val_binary_acc: 0.3342 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.3208 | val_loss: 0.00000 - val_binary_acc: 0.3342 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3209 | val_loss: 0.00000 - val_binary_acc: 0.3342 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.3209 | val_loss: 0.00000 - val_binary_acc: 0.3342 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3209 | val_loss: 0.00000 - val_binary_acc: 0.3342 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.3209 | val_loss: 0.00000 - val_binary_acc: 0.3342 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3209 | val_loss: 0.00000 - val_binary_acc: 0.3342 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.3209 | val_loss: 0.00000 - val_binary_acc: 0.3342 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3209 | val_loss: 0.00000 - val_binary_acc: 0.3342 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.3209 | val_loss: 0.00000 - val_binary_acc: 0.3342 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3209 | val_loss: 0.00000 - val_binary_acc: 0.3342 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.3209 | val_loss: 0.00000 - val_binary_acc: 0.3342 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3209 | val_loss: 0.00000 - val_binary_acc: 0.3342 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.3209 | val_loss: 0.00000 - val_binary_acc: 0.3342 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3209 | val_loss: 0.00000 - val_binary_acc: 0.3342 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.3209 | val_loss: 0.00000 - val_binary_acc: 0.3342 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3209 | val_loss: 0.00000 - val_binary_acc: 0.3342 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3209 | val_loss: 0.00000 - val_binary_acc: 0.3342 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3209 | val_loss: 0.00000 - val_binary_acc: 0.3342 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.3209 | val_loss: 0.00000 - val_binary_acc: 0.3342 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3209 | val_loss: 0.00000 - val_binary_acc: 0.3342 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.3209 | val_loss: 0.00000 - val_binary_acc: 0.3342 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3209 | val_loss: 0.00000 - val_binary_acc: 0.3342 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'sigmoid', 10, [0.3002028369758482]]\n",
      "ProximalAdaGrad\n",
      "sigmoid\n",
      "5\n",
      "---------------------------------\n",
      "Run id: XU3DHG\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.127s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.2893 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.3157 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3200 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.3210 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3213 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.3214 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'sigmoid', 5, [0.3002028369758482]]\n",
      "ProximalAdaGrad\n",
      "sigmoid\n",
      "35\n",
      "---------------------------------\n",
      "Run id: XI4LM3\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.140s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.2865 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.3125 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3169 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.3179 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3182 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.3183 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3183 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.3183 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3183 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.3183 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3183 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.3183 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3183 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.3183 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3183 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.3183 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3183 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.3183 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3183 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.3183 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3183 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.3183 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3183 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3183 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3183 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.014s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.3183 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3183 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.3183 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3183 | val_loss: 0.00000 - val_binary_acc: 0.3443 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'sigmoid', 35, [0.3002028369758482]]\n",
      "ProximalAdaGrad\n",
      "tanh\n",
      "10\n",
      "---------------------------------\n",
      "Run id: QMTOP5\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.126s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.006s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.3162 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.3185 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3188 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.3189 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3189 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'tanh', 10, [0.3002028369758482]]\n",
      "ProximalAdaGrad\n",
      "tanh\n",
      "5\n",
      "---------------------------------\n",
      "Run id: SFEYZM\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.125s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.006s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.3624 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.4804 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3631 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.3361 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3283 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.3258 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3248 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.3244 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3242 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.3241 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3241 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.3241 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3241 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.3240 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3240 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.3240 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.006s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3240 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.3240 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3240 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.3240 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3240 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.3240 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3240 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3240 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3240 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.3240 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3240 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.3240 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3240 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'tanh', 5, [0.3002028369758482]]\n",
      "ProximalAdaGrad\n",
      "tanh\n",
      "35\n",
      "---------------------------------\n",
      "Run id: 7U1QC9\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.123s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.3156 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.2768 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3351 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.2884 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.2746 | val_loss: 0.00000 - val_binary_acc: 0.2481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.2704 | val_loss: 0.00000 - val_binary_acc: 0.2506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3355 | val_loss: 0.00000 - val_binary_acc: 0.2430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.2996 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.2833 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.2758 | val_loss: 0.00000 - val_binary_acc: 0.2658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3158 | val_loss: 0.00000 - val_binary_acc: 0.2658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.2951 | val_loss: 0.00000 - val_binary_acc: 0.2506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3262 | val_loss: 0.00000 - val_binary_acc: 0.2557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.3003 | val_loss: 0.00000 - val_binary_acc: 0.2532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3187 | val_loss: 0.00000 - val_binary_acc: 0.2608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.2980 | val_loss: 0.00000 - val_binary_acc: 0.2658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.2862 | val_loss: 0.00000 - val_binary_acc: 0.2658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.2785 | val_loss: 0.00000 - val_binary_acc: 0.2684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3029 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.2910 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3009 | val_loss: 0.00000 - val_binary_acc: 0.2532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.2907 | val_loss: 0.00000 - val_binary_acc: 0.2506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3070 | val_loss: 0.00000 - val_binary_acc: 0.2506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.2942 | val_loss: 0.00000 - val_binary_acc: 0.2506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3044 | val_loss: 0.00000 - val_binary_acc: 0.2532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.2930 | val_loss: 0.00000 - val_binary_acc: 0.2506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3027 | val_loss: 0.00000 - val_binary_acc: 0.2506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.2920 | val_loss: 0.00000 - val_binary_acc: 0.2532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3060 | val_loss: 0.00000 - val_binary_acc: 0.2506 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'tanh', 35, [0.27180527534494536]]\n",
      "ProximalAdaGrad\n",
      "prelu\n",
      "10\n",
      "---------------------------------\n",
      "Run id: XBNSIM\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.204s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: nan - binary_acc: 0.2939 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: nan - binary_acc: 0.4197 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: nan - binary_acc: 0.4407 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: nan - binary_acc: 0.4455 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: nan - binary_acc: 0.4469 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: nan - binary_acc: 0.4474 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: nan - binary_acc: 0.4476 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: nan - binary_acc: 0.4476 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4127 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'prelu', 10, [0.45436105404132276]]\n",
      "ProximalAdaGrad\n",
      "prelu\n",
      "5\n",
      "---------------------------------\n",
      "Run id: KBHWKZ\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.172s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: nan - binary_acc: 0.4035 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: nan - binary_acc: 0.4402 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: nan - binary_acc: 0.4463 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: nan - binary_acc: 0.4477 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: nan - binary_acc: 0.4481 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: nan - binary_acc: 0.4482 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: nan - binary_acc: 0.4483 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: nan - binary_acc: 0.4483 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: nan - binary_acc: 0.4483 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: nan - binary_acc: 0.4483 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: nan - binary_acc: 0.4483 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: nan - binary_acc: 0.4483 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: nan - binary_acc: 0.4483 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: nan - binary_acc: 0.4483 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: nan - binary_acc: 0.4483 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: nan - binary_acc: 0.4483 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: nan - binary_acc: 0.4483 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: nan - binary_acc: 0.4483 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: nan - binary_acc: 0.4483 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: nan - binary_acc: 0.4483 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: nan - binary_acc: 0.4483 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: nan - binary_acc: 0.4483 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: nan - binary_acc: 0.4483 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: nan - binary_acc: 0.4483 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: nan - binary_acc: 0.4483 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: nan - binary_acc: 0.4483 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: nan - binary_acc: 0.4483 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: nan - binary_acc: 0.4483 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: nan - binary_acc: 0.4483 | val_loss: nan - val_binary_acc: 0.4101 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'prelu', 5, [0.45436105404132276]]\n",
      "ProximalAdaGrad\n",
      "prelu\n",
      "35\n",
      "---------------------------------\n",
      "Run id: 5CY91Z\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.296s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: nan - binary_acc: 0.3544 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: nan - binary_acc: 0.4235 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: nan - binary_acc: 0.4350 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: nan - binary_acc: 0.4376 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: nan - binary_acc: 0.4384 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: nan - binary_acc: 0.4386 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: nan - binary_acc: 0.4387 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32mnan\u001b[0m\u001b[0m | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: nan - binary_acc: 0.4388 | val_loss: nan - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'prelu', 35, [0.45436105404132276]]\n"
     ]
    }
   ],
   "source": [
    "#\"ProximalAdaGrad\",\"sgd\",'RMSProp','AdaGrad',\"ProximalAdaGrad\" \"momentum\",\"momentum\",'RMSProp' \" \"momentum\"\n",
    "optimizadores=[\"AdaDelta\",'RMSProp','AdaGrad',\"ProximalAdaGrad\"]\n",
    "#\n",
    "tf.reset_default_graph()\n",
    "activator=[  \"relu\", \"linear\" ,\"softmax\" ,'sigmoid','tanh','prelu']\n",
    "tamanio=[[10,10,1],[5,5],[35,35]]\n",
    "#t#amanio=[[64,64,30,10]]\n",
    "#sgd = tflearn.SGD(learning_rate=0.01,lr_decay=0.96 , decay_step=500)\n",
    "resultados=[]\n",
    "for o in optimizadores:\n",
    "    for a in activator:\n",
    "        for t in tamanio:\n",
    "            \n",
    "            print(o)\n",
    "            print(a)\n",
    "            print(str(t[0]))\n",
    "            tf.reset_default_graph()\n",
    "            net = tflearn.input_data(shape=[None, 6])\n",
    "            net = tflearn.fully_connected(net,t[0], activation=a,regularizer=\"L2\", weights_init='normal', weight_decay=0.001)\n",
    "            #net = tflearn.fully_connected(net,t[1], activation=a,regularizer=\"L2\", weights_init='normal', weight_decay=0.001)\n",
    "            net = tflearn.fully_connected(net,t[1], activation=a,regularizer=\"L2\", weights_init='normal', weight_decay=0.001)\n",
    "            net = tflearn.fully_connected(net,t[1], activation=a,regularizer=\"L2\", weights_init='normal', weight_decay=0.001)\n",
    "            net = tflearn.fully_connected(net,1, activation=a,regularizer=\"L2\", weights_init='normal', weight_decay=0.001)\n",
    "            net = tflearn.regression(net, optimizer=o,loss=\"categorical_crossentropy\",metric=\"accuracy\")\n",
    "            model = tflearn.DNN(net)\n",
    "            model.fit(entrenamiento, entrenamiento_lbl,show_metric=True,validation_set=0.2,n_epoch=30,batch_size=len(entrenamiento))\n",
    "            accu=model.evaluate(validacion, validacion_lbl)\n",
    "            \n",
    "            #print(accu)\n",
    "            config=[o,a,t[0],accu]\n",
    "            print(config)\n",
    "            resultados.append(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados=pd.DataFrame(resultados)\n",
    "a=resultados[3]\n",
    "accu=[i[0] for i in a]\n",
    "resultados[\"accu\"]=accu\n",
    "\n",
    "resultados=resultados.sort_values(by=\"accu\",ascending=False)\n",
    "resultados.to_csv(\"resultados_rna_ECI_c.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaDelta\n",
      "linear\n",
      "10\n",
      "---------------------------------\n",
      "Run id: KTU2NI\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.119s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.006s\n",
      "| AdaDelta | epoch: 002 | loss: 0.00000 - binary_acc: 0.3504 | val_loss: 0.00000 - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.008s\n",
      "| AdaDelta | epoch: 003 | loss: 0.00000 - binary_acc: 0.4279 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.008s\n",
      "| AdaDelta | epoch: 004 | loss: 0.00000 - binary_acc: 0.3842 | val_loss: 0.00000 - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.007s\n",
      "| AdaDelta | epoch: 005 | loss: 0.00000 - binary_acc: 0.4268 | val_loss: 0.00000 - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.008s\n",
      "| AdaDelta | epoch: 006 | loss: 0.00000 - binary_acc: 0.3934 | val_loss: 0.00000 - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.008s\n",
      "| AdaDelta | epoch: 007 | loss: 0.00000 - binary_acc: 0.4237 | val_loss: 0.00000 - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.008s\n",
      "| AdaDelta | epoch: 008 | loss: 0.00000 - binary_acc: 0.4126 | val_loss: 0.00000 - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.008s\n",
      "| AdaDelta | epoch: 009 | loss: 0.00000 - binary_acc: 0.4298 | val_loss: 0.00000 - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.009s\n",
      "| AdaDelta | epoch: 010 | loss: 0.00000 - binary_acc: 0.4026 | val_loss: 0.00000 - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.009s\n",
      "| AdaDelta | epoch: 011 | loss: 0.00000 - binary_acc: 0.4210 | val_loss: 0.00000 - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.010s\n",
      "| AdaDelta | epoch: 012 | loss: 0.00000 - binary_acc: 0.4142 | val_loss: 0.00000 - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.007s\n",
      "| AdaDelta | epoch: 013 | loss: 0.00000 - binary_acc: 0.4321 | val_loss: 0.00000 - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.009s\n",
      "| AdaDelta | epoch: 014 | loss: 0.00000 - binary_acc: 0.4252 | val_loss: 0.00000 - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.007s\n",
      "| AdaDelta | epoch: 015 | loss: 0.00000 - binary_acc: 0.4370 | val_loss: 0.00000 - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.007s\n",
      "| AdaDelta | epoch: 016 | loss: 0.00000 - binary_acc: 0.4450 | val_loss: 0.00000 - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.009s\n",
      "| AdaDelta | epoch: 017 | loss: 0.00000 - binary_acc: 0.4485 | val_loss: 0.00000 - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.009s\n",
      "| AdaDelta | epoch: 018 | loss: 0.00000 - binary_acc: 0.4320 | val_loss: 0.00000 - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.008s\n",
      "| AdaDelta | epoch: 019 | loss: 0.00000 - binary_acc: 0.4419 | val_loss: 0.00000 - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.009s\n",
      "| AdaDelta | epoch: 020 | loss: 0.00000 - binary_acc: 0.4352 | val_loss: 0.00000 - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.008s\n",
      "| AdaDelta | epoch: 021 | loss: 0.00000 - binary_acc: 0.4434 | val_loss: 0.00000 - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.008s\n",
      "| AdaDelta | epoch: 022 | loss: 0.00000 - binary_acc: 0.4317 | val_loss: 0.00000 - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.008s\n",
      "| AdaDelta | epoch: 023 | loss: 0.00000 - binary_acc: 0.4404 | val_loss: 0.00000 - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.008s\n",
      "| AdaDelta | epoch: 024 | loss: 0.00000 - binary_acc: 0.4364 | val_loss: 0.00000 - val_binary_acc: 0.4532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.008s\n",
      "| AdaDelta | epoch: 025 | loss: 0.00000 - binary_acc: 0.4429 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.009s\n",
      "| AdaDelta | epoch: 026 | loss: 0.00000 - binary_acc: 0.4392 | val_loss: 0.00000 - val_binary_acc: 0.4405 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.007s\n",
      "| AdaDelta | epoch: 027 | loss: 0.00000 - binary_acc: 0.4438 | val_loss: 0.00000 - val_binary_acc: 0.4380 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.009s\n",
      "| AdaDelta | epoch: 028 | loss: 0.00000 - binary_acc: 0.4405 | val_loss: 0.00000 - val_binary_acc: 0.4430 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.008s\n",
      "| AdaDelta | epoch: 029 | loss: 0.00000 - binary_acc: 0.4456 | val_loss: 0.00000 - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.008s\n",
      "| AdaDelta | epoch: 030 | loss: 0.00000 - binary_acc: 0.4401 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'linear', 10, [0.49087221022793537]]\n",
      "AdaDelta\n",
      "linear\n",
      "5\n",
      "---------------------------------\n",
      "Run id: Y79QGR\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.106s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.5139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.006s\n",
      "| AdaDelta | epoch: 002 | loss: 0.00000 - binary_acc: 0.3584 | val_loss: 0.00000 - val_binary_acc: 0.5190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.008s\n",
      "| AdaDelta | epoch: 003 | loss: 0.00000 - binary_acc: 0.4673 | val_loss: 0.00000 - val_binary_acc: 0.5190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.007s\n",
      "| AdaDelta | epoch: 004 | loss: 0.00000 - binary_acc: 0.4150 | val_loss: 0.00000 - val_binary_acc: 0.5165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.008s\n",
      "| AdaDelta | epoch: 005 | loss: 0.00000 - binary_acc: 0.4697 | val_loss: 0.00000 - val_binary_acc: 0.5241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.008s\n",
      "| AdaDelta | epoch: 006 | loss: 0.00000 - binary_acc: 0.4853 | val_loss: 0.00000 - val_binary_acc: 0.5139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.008s\n",
      "| AdaDelta | epoch: 007 | loss: 0.00000 - binary_acc: 0.4871 | val_loss: 0.00000 - val_binary_acc: 0.5241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.008s\n",
      "| AdaDelta | epoch: 008 | loss: 0.00000 - binary_acc: 0.4193 | val_loss: 0.00000 - val_binary_acc: 0.5114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.009s\n",
      "| AdaDelta | epoch: 009 | loss: 0.00000 - binary_acc: 0.4558 | val_loss: 0.00000 - val_binary_acc: 0.5190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.008s\n",
      "| AdaDelta | epoch: 010 | loss: 0.00000 - binary_acc: 0.4746 | val_loss: 0.00000 - val_binary_acc: 0.5165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.007s\n",
      "| AdaDelta | epoch: 011 | loss: 0.00000 - binary_acc: 0.4820 | val_loss: 0.00000 - val_binary_acc: 0.5215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.009s\n",
      "| AdaDelta | epoch: 012 | loss: 0.00000 - binary_acc: 0.4437 | val_loss: 0.00000 - val_binary_acc: 0.5215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.008s\n",
      "| AdaDelta | epoch: 013 | loss: 0.00000 - binary_acc: 0.4631 | val_loss: 0.00000 - val_binary_acc: 0.5190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.007s\n",
      "| AdaDelta | epoch: 014 | loss: 0.00000 - binary_acc: 0.4340 | val_loss: 0.00000 - val_binary_acc: 0.5190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.008s\n",
      "| AdaDelta | epoch: 015 | loss: 0.00000 - binary_acc: 0.4557 | val_loss: 0.00000 - val_binary_acc: 0.5190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.008s\n",
      "| AdaDelta | epoch: 016 | loss: 0.00000 - binary_acc: 0.4353 | val_loss: 0.00000 - val_binary_acc: 0.5165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.007s\n",
      "| AdaDelta | epoch: 017 | loss: 0.00000 - binary_acc: 0.4553 | val_loss: 0.00000 - val_binary_acc: 0.5215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.007s\n",
      "| AdaDelta | epoch: 018 | loss: 0.00000 - binary_acc: 0.4683 | val_loss: 0.00000 - val_binary_acc: 0.5165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.007s\n",
      "| AdaDelta | epoch: 019 | loss: 0.00000 - binary_acc: 0.4760 | val_loss: 0.00000 - val_binary_acc: 0.5165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.008s\n",
      "| AdaDelta | epoch: 020 | loss: 0.00000 - binary_acc: 0.4530 | val_loss: 0.00000 - val_binary_acc: 0.5165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.008s\n",
      "| AdaDelta | epoch: 021 | loss: 0.00000 - binary_acc: 0.4657 | val_loss: 0.00000 - val_binary_acc: 0.5139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.009s\n",
      "| AdaDelta | epoch: 022 | loss: 0.00000 - binary_acc: 0.4472 | val_loss: 0.00000 - val_binary_acc: 0.5165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.008s\n",
      "| AdaDelta | epoch: 023 | loss: 0.00000 - binary_acc: 0.4600 | val_loss: 0.00000 - val_binary_acc: 0.5165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.008s\n",
      "| AdaDelta | epoch: 024 | loss: 0.00000 - binary_acc: 0.4484 | val_loss: 0.00000 - val_binary_acc: 0.5190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.007s\n",
      "| AdaDelta | epoch: 025 | loss: 0.00000 - binary_acc: 0.4608 | val_loss: 0.00000 - val_binary_acc: 0.5139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.008s\n",
      "| AdaDelta | epoch: 026 | loss: 0.00000 - binary_acc: 0.4533 | val_loss: 0.00000 - val_binary_acc: 0.5139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.008s\n",
      "| AdaDelta | epoch: 027 | loss: 0.00000 - binary_acc: 0.4636 | val_loss: 0.00000 - val_binary_acc: 0.5139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.008s\n",
      "| AdaDelta | epoch: 028 | loss: 0.00000 - binary_acc: 0.4528 | val_loss: 0.00000 - val_binary_acc: 0.5165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.007s\n",
      "| AdaDelta | epoch: 029 | loss: 0.00000 - binary_acc: 0.4620 | val_loss: 0.00000 - val_binary_acc: 0.5165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.008s\n",
      "| AdaDelta | epoch: 030 | loss: 0.00000 - binary_acc: 0.4502 | val_loss: 0.00000 - val_binary_acc: 0.5215 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'linear', 5, [0.47870182368382963]]\n",
      "AdaDelta\n",
      "linear\n",
      "35\n",
      "---------------------------------\n",
      "Run id: UO386B\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.113s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.5291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.007s\n",
      "| AdaDelta | epoch: 002 | loss: 0.00000 - binary_acc: 0.3339 | val_loss: 0.00000 - val_binary_acc: 0.5316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.009s\n",
      "| AdaDelta | epoch: 003 | loss: 0.00000 - binary_acc: 0.4701 | val_loss: 0.00000 - val_binary_acc: 0.5316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.010s\n",
      "| AdaDelta | epoch: 004 | loss: 0.00000 - binary_acc: 0.4148 | val_loss: 0.00000 - val_binary_acc: 0.5316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.009s\n",
      "| AdaDelta | epoch: 005 | loss: 0.00000 - binary_acc: 0.4722 | val_loss: 0.00000 - val_binary_acc: 0.5316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.009s\n",
      "| AdaDelta | epoch: 006 | loss: 0.00000 - binary_acc: 0.4075 | val_loss: 0.00000 - val_binary_acc: 0.5316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.009s\n",
      "| AdaDelta | epoch: 007 | loss: 0.00000 - binary_acc: 0.4628 | val_loss: 0.00000 - val_binary_acc: 0.5291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.009s\n",
      "| AdaDelta | epoch: 008 | loss: 0.00000 - binary_acc: 0.4126 | val_loss: 0.00000 - val_binary_acc: 0.5316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.010s\n",
      "| AdaDelta | epoch: 009 | loss: 0.00000 - binary_acc: 0.4584 | val_loss: 0.00000 - val_binary_acc: 0.5291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.009s\n",
      "| AdaDelta | epoch: 010 | loss: 0.00000 - binary_acc: 0.4787 | val_loss: 0.00000 - val_binary_acc: 0.5316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.010s\n",
      "| AdaDelta | epoch: 011 | loss: 0.00000 - binary_acc: 0.4883 | val_loss: 0.00000 - val_binary_acc: 0.5291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.010s\n",
      "| AdaDelta | epoch: 012 | loss: 0.00000 - binary_acc: 0.4441 | val_loss: 0.00000 - val_binary_acc: 0.5316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.010s\n",
      "| AdaDelta | epoch: 013 | loss: 0.00000 - binary_acc: 0.4676 | val_loss: 0.00000 - val_binary_acc: 0.5342 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.009s\n",
      "| AdaDelta | epoch: 014 | loss: 0.00000 - binary_acc: 0.4333 | val_loss: 0.00000 - val_binary_acc: 0.5291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.008s\n",
      "| AdaDelta | epoch: 015 | loss: 0.00000 - binary_acc: 0.4580 | val_loss: 0.00000 - val_binary_acc: 0.5367 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.010s\n",
      "| AdaDelta | epoch: 016 | loss: 0.00000 - binary_acc: 0.4370 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.009s\n",
      "| AdaDelta | epoch: 017 | loss: 0.00000 - binary_acc: 0.4589 | val_loss: 0.00000 - val_binary_acc: 0.5418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.010s\n",
      "| AdaDelta | epoch: 018 | loss: 0.00000 - binary_acc: 0.4405 | val_loss: 0.00000 - val_binary_acc: 0.5443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.010s\n",
      "| AdaDelta | epoch: 019 | loss: 0.00000 - binary_acc: 0.4605 | val_loss: 0.00000 - val_binary_acc: 0.5443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.008s\n",
      "| AdaDelta | epoch: 020 | loss: 0.00000 - binary_acc: 0.4417 | val_loss: 0.00000 - val_binary_acc: 0.5443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.011s\n",
      "| AdaDelta | epoch: 021 | loss: 0.00000 - binary_acc: 0.4599 | val_loss: 0.00000 - val_binary_acc: 0.5443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.011s\n",
      "| AdaDelta | epoch: 022 | loss: 0.00000 - binary_acc: 0.4478 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.009s\n",
      "| AdaDelta | epoch: 023 | loss: 0.00000 - binary_acc: 0.4623 | val_loss: 0.00000 - val_binary_acc: 0.5443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.009s\n",
      "| AdaDelta | epoch: 024 | loss: 0.00000 - binary_acc: 0.4391 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.008s\n",
      "| AdaDelta | epoch: 025 | loss: 0.00000 - binary_acc: 0.4550 | val_loss: 0.00000 - val_binary_acc: 0.5443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.009s\n",
      "| AdaDelta | epoch: 026 | loss: 0.00000 - binary_acc: 0.4421 | val_loss: 0.00000 - val_binary_acc: 0.5392 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.007s\n",
      "| AdaDelta | epoch: 027 | loss: 0.00000 - binary_acc: 0.4564 | val_loss: 0.00000 - val_binary_acc: 0.5443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.008s\n",
      "| AdaDelta | epoch: 028 | loss: 0.00000 - binary_acc: 0.4451 | val_loss: 0.00000 - val_binary_acc: 0.5443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.009s\n",
      "| AdaDelta | epoch: 029 | loss: 0.00000 - binary_acc: 0.4580 | val_loss: 0.00000 - val_binary_acc: 0.5443 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.010s\n",
      "| AdaDelta | epoch: 030 | loss: 0.00000 - binary_acc: 0.4437 | val_loss: 0.00000 - val_binary_acc: 0.5443 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'linear', 35, [0.4929006112395629]]\n",
      "AdaDelta\n",
      "tanh\n",
      "10\n",
      "---------------------------------\n",
      "Run id: DYZFH1\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.128s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.5241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.008s\n",
      "| AdaDelta | epoch: 002 | loss: 0.00000 - binary_acc: 0.3498 | val_loss: 0.00000 - val_binary_acc: 0.5165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.008s\n",
      "| AdaDelta | epoch: 003 | loss: 0.00000 - binary_acc: 0.4621 | val_loss: 0.00000 - val_binary_acc: 0.5241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.007s\n",
      "| AdaDelta | epoch: 004 | loss: 0.00000 - binary_acc: 0.4061 | val_loss: 0.00000 - val_binary_acc: 0.5190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.008s\n",
      "| AdaDelta | epoch: 005 | loss: 0.00000 - binary_acc: 0.4625 | val_loss: 0.00000 - val_binary_acc: 0.5241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.009s\n",
      "| AdaDelta | epoch: 006 | loss: 0.00000 - binary_acc: 0.4228 | val_loss: 0.00000 - val_binary_acc: 0.5215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.009s\n",
      "| AdaDelta | epoch: 007 | loss: 0.00000 - binary_acc: 0.4621 | val_loss: 0.00000 - val_binary_acc: 0.5215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.009s\n",
      "| AdaDelta | epoch: 008 | loss: 0.00000 - binary_acc: 0.4782 | val_loss: 0.00000 - val_binary_acc: 0.5190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.008s\n",
      "| AdaDelta | epoch: 009 | loss: 0.00000 - binary_acc: 0.4839 | val_loss: 0.00000 - val_binary_acc: 0.5165 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.009s\n",
      "| AdaDelta | epoch: 010 | loss: 0.00000 - binary_acc: 0.4433 | val_loss: 0.00000 - val_binary_acc: 0.5215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.008s\n",
      "| AdaDelta | epoch: 011 | loss: 0.00000 - binary_acc: 0.4643 | val_loss: 0.00000 - val_binary_acc: 0.5291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.008s\n",
      "| AdaDelta | epoch: 012 | loss: 0.00000 - binary_acc: 0.4314 | val_loss: 0.00000 - val_binary_acc: 0.5190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.008s\n",
      "| AdaDelta | epoch: 013 | loss: 0.00000 - binary_acc: 0.4571 | val_loss: 0.00000 - val_binary_acc: 0.5241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.008s\n",
      "| AdaDelta | epoch: 014 | loss: 0.00000 - binary_acc: 0.4310 | val_loss: 0.00000 - val_binary_acc: 0.5215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.008s\n",
      "| AdaDelta | epoch: 015 | loss: 0.00000 - binary_acc: 0.4534 | val_loss: 0.00000 - val_binary_acc: 0.5215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.009s\n",
      "| AdaDelta | epoch: 016 | loss: 0.00000 - binary_acc: 0.4665 | val_loss: 0.00000 - val_binary_acc: 0.5215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.010s\n",
      "| AdaDelta | epoch: 017 | loss: 0.00000 - binary_acc: 0.4745 | val_loss: 0.00000 - val_binary_acc: 0.5241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.010s\n",
      "| AdaDelta | epoch: 018 | loss: 0.00000 - binary_acc: 0.4571 | val_loss: 0.00000 - val_binary_acc: 0.5215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.007s\n",
      "| AdaDelta | epoch: 019 | loss: 0.00000 - binary_acc: 0.4671 | val_loss: 0.00000 - val_binary_acc: 0.5266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.009s\n",
      "| AdaDelta | epoch: 020 | loss: 0.00000 - binary_acc: 0.4500 | val_loss: 0.00000 - val_binary_acc: 0.5215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.009s\n",
      "| AdaDelta | epoch: 021 | loss: 0.00000 - binary_acc: 0.4621 | val_loss: 0.00000 - val_binary_acc: 0.5215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.008s\n",
      "| AdaDelta | epoch: 022 | loss: 0.00000 - binary_acc: 0.4454 | val_loss: 0.00000 - val_binary_acc: 0.5215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.008s\n",
      "| AdaDelta | epoch: 023 | loss: 0.00000 - binary_acc: 0.4580 | val_loss: 0.00000 - val_binary_acc: 0.5215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.009s\n",
      "| AdaDelta | epoch: 024 | loss: 0.00000 - binary_acc: 0.4455 | val_loss: 0.00000 - val_binary_acc: 0.5215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.008s\n",
      "| AdaDelta | epoch: 025 | loss: 0.00000 - binary_acc: 0.4573 | val_loss: 0.00000 - val_binary_acc: 0.5291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.008s\n",
      "| AdaDelta | epoch: 026 | loss: 0.00000 - binary_acc: 0.4471 | val_loss: 0.00000 - val_binary_acc: 0.5215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.007s\n",
      "| AdaDelta | epoch: 027 | loss: 0.00000 - binary_acc: 0.4581 | val_loss: 0.00000 - val_binary_acc: 0.5241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.007s\n",
      "| AdaDelta | epoch: 028 | loss: 0.00000 - binary_acc: 0.4479 | val_loss: 0.00000 - val_binary_acc: 0.5139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.008s\n",
      "| AdaDelta | epoch: 029 | loss: 0.00000 - binary_acc: 0.4574 | val_loss: 0.00000 - val_binary_acc: 0.5241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.009s\n",
      "| AdaDelta | epoch: 030 | loss: 0.00000 - binary_acc: 0.4473 | val_loss: 0.00000 - val_binary_acc: 0.5165 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'tanh', 10, [0.4949290076569176]]\n",
      "AdaDelta\n",
      "tanh\n",
      "5\n",
      "---------------------------------\n",
      "Run id: 8LEL7G\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.136s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.4000 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.007s\n",
      "| AdaDelta | epoch: 002 | loss: 0.00000 - binary_acc: 0.3550 | val_loss: 0.00000 - val_binary_acc: 0.3747 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.008s\n",
      "| AdaDelta | epoch: 003 | loss: 0.00000 - binary_acc: 0.3898 | val_loss: 0.00000 - val_binary_acc: 0.3949 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.008s\n",
      "| AdaDelta | epoch: 004 | loss: 0.00000 - binary_acc: 0.3548 | val_loss: 0.00000 - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.007s\n",
      "| AdaDelta | epoch: 005 | loss: 0.00000 - binary_acc: 0.4090 | val_loss: 0.00000 - val_binary_acc: 0.3975 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.008s\n",
      "| AdaDelta | epoch: 006 | loss: 0.00000 - binary_acc: 0.4057 | val_loss: 0.00000 - val_binary_acc: 0.3975 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.008s\n",
      "| AdaDelta | epoch: 007 | loss: 0.00000 - binary_acc: 0.4130 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.008s\n",
      "| AdaDelta | epoch: 008 | loss: 0.00000 - binary_acc: 0.3815 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.008s\n",
      "| AdaDelta | epoch: 009 | loss: 0.00000 - binary_acc: 0.3722 | val_loss: 0.00000 - val_binary_acc: 0.3570 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.008s\n",
      "| AdaDelta | epoch: 010 | loss: 0.00000 - binary_acc: 0.3497 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.009s\n",
      "| AdaDelta | epoch: 011 | loss: 0.00000 - binary_acc: 0.3583 | val_loss: 0.00000 - val_binary_acc: 0.3367 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.009s\n",
      "| AdaDelta | epoch: 012 | loss: 0.00000 - binary_acc: 0.3432 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.008s\n",
      "| AdaDelta | epoch: 013 | loss: 0.00000 - binary_acc: 0.3409 | val_loss: 0.00000 - val_binary_acc: 0.3544 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.008s\n",
      "| AdaDelta | epoch: 014 | loss: 0.00000 - binary_acc: 0.3335 | val_loss: 0.00000 - val_binary_acc: 0.3949 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.008s\n",
      "| AdaDelta | epoch: 015 | loss: 0.00000 - binary_acc: 0.3417 | val_loss: 0.00000 - val_binary_acc: 0.3418 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.009s\n",
      "| AdaDelta | epoch: 016 | loss: 0.00000 - binary_acc: 0.3477 | val_loss: 0.00000 - val_binary_acc: 0.3367 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.010s\n",
      "| AdaDelta | epoch: 017 | loss: 0.00000 - binary_acc: 0.3485 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.010s\n",
      "| AdaDelta | epoch: 018 | loss: 0.00000 - binary_acc: 0.3427 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.009s\n",
      "| AdaDelta | epoch: 019 | loss: 0.00000 - binary_acc: 0.3375 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.007s\n",
      "| AdaDelta | epoch: 020 | loss: 0.00000 - binary_acc: 0.3328 | val_loss: 0.00000 - val_binary_acc: 0.3291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.007s\n",
      "| AdaDelta | epoch: 021 | loss: 0.00000 - binary_acc: 0.3297 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.009s\n",
      "| AdaDelta | epoch: 022 | loss: 0.00000 - binary_acc: 0.3287 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.009s\n",
      "| AdaDelta | epoch: 023 | loss: 0.00000 - binary_acc: 0.3270 | val_loss: 0.00000 - val_binary_acc: 0.3342 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.007s\n",
      "| AdaDelta | epoch: 024 | loss: 0.00000 - binary_acc: 0.3262 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.008s\n",
      "| AdaDelta | epoch: 025 | loss: 0.00000 - binary_acc: 0.3290 | val_loss: 0.00000 - val_binary_acc: 0.3367 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.010s\n",
      "| AdaDelta | epoch: 026 | loss: 0.00000 - binary_acc: 0.3276 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.009s\n",
      "| AdaDelta | epoch: 027 | loss: 0.00000 - binary_acc: 0.3304 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.008s\n",
      "| AdaDelta | epoch: 028 | loss: 0.00000 - binary_acc: 0.3291 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.008s\n",
      "| AdaDelta | epoch: 029 | loss: 0.00000 - binary_acc: 0.3276 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.009s\n",
      "| AdaDelta | epoch: 030 | loss: 0.00000 - binary_acc: 0.3269 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'tanh', 5, [0.3002028369758482]]\n",
      "AdaDelta\n",
      "tanh\n",
      "35\n",
      "---------------------------------\n",
      "Run id: RUEP3H\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.124s\n",
      "| AdaDelta | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.006s\n",
      "| AdaDelta | epoch: 002 | loss: 0.00000 - binary_acc: 0.3390 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.008s\n",
      "| AdaDelta | epoch: 003 | loss: 0.00000 - binary_acc: 0.2920 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.010s\n",
      "| AdaDelta | epoch: 004 | loss: 0.00000 - binary_acc: 0.3512 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.010s\n",
      "| AdaDelta | epoch: 005 | loss: 0.00000 - binary_acc: 0.3030 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.012s\n",
      "| AdaDelta | epoch: 006 | loss: 0.00000 - binary_acc: 0.3491 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.010s\n",
      "| AdaDelta | epoch: 007 | loss: 0.00000 - binary_acc: 0.3082 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.010s\n",
      "| AdaDelta | epoch: 008 | loss: 0.00000 - binary_acc: 0.3428 | val_loss: 0.00000 - val_binary_acc: 0.2785 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.009s\n",
      "| AdaDelta | epoch: 009 | loss: 0.00000 - binary_acc: 0.3090 | val_loss: 0.00000 - val_binary_acc: 0.2785 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.010s\n",
      "| AdaDelta | epoch: 010 | loss: 0.00000 - binary_acc: 0.2937 | val_loss: 0.00000 - val_binary_acc: 0.2759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.010s\n",
      "| AdaDelta | epoch: 011 | loss: 0.00000 - binary_acc: 0.2867 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.009s\n",
      "| AdaDelta | epoch: 012 | loss: 0.00000 - binary_acc: 0.3229 | val_loss: 0.00000 - val_binary_acc: 0.2785 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.012s\n",
      "| AdaDelta | epoch: 013 | loss: 0.00000 - binary_acc: 0.3041 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.011s\n",
      "| AdaDelta | epoch: 014 | loss: 0.00000 - binary_acc: 0.3320 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.009s\n",
      "| AdaDelta | epoch: 015 | loss: 0.00000 - binary_acc: 0.3112 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.011s\n",
      "| AdaDelta | epoch: 016 | loss: 0.00000 - binary_acc: 0.3346 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.010s\n",
      "| AdaDelta | epoch: 017 | loss: 0.00000 - binary_acc: 0.3146 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.010s\n",
      "| AdaDelta | epoch: 018 | loss: 0.00000 - binary_acc: 0.3181 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.012s\n",
      "| AdaDelta | epoch: 019 | loss: 0.00000 - binary_acc: 0.3053 | val_loss: 0.00000 - val_binary_acc: 0.2785 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.012s\n",
      "| AdaDelta | epoch: 020 | loss: 0.00000 - binary_acc: 0.3176 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.010s\n",
      "| AdaDelta | epoch: 021 | loss: 0.00000 - binary_acc: 0.3056 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.011s\n",
      "| AdaDelta | epoch: 022 | loss: 0.00000 - binary_acc: 0.3136 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.010s\n",
      "| AdaDelta | epoch: 023 | loss: 0.00000 - binary_acc: 0.3027 | val_loss: 0.00000 - val_binary_acc: 0.2759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.010s\n",
      "| AdaDelta | epoch: 024 | loss: 0.00000 - binary_acc: 0.3113 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.010s\n",
      "| AdaDelta | epoch: 025 | loss: 0.00000 - binary_acc: 0.3022 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.012s\n",
      "| AdaDelta | epoch: 026 | loss: 0.00000 - binary_acc: 0.3190 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.012s\n",
      "| AdaDelta | epoch: 027 | loss: 0.00000 - binary_acc: 0.3079 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.012s\n",
      "| AdaDelta | epoch: 028 | loss: 0.00000 - binary_acc: 0.3156 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.009s\n",
      "| AdaDelta | epoch: 029 | loss: 0.00000 - binary_acc: 0.3061 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.009s\n",
      "| AdaDelta | epoch: 030 | loss: 0.00000 - binary_acc: 0.3204 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "['AdaDelta', 'tanh', 35, [0.2657200837957448]]\n",
      "RMSProp\n",
      "linear\n",
      "10\n",
      "---------------------------------\n",
      "Run id: YAMKWQ\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.119s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.4835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.007s\n",
      "| RMSProp | epoch: 002 | loss: 0.00000 - binary_acc: 0.3527 | val_loss: 0.00000 - val_binary_acc: 0.4835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.008s\n",
      "| RMSProp | epoch: 003 | loss: 0.00000 - binary_acc: 0.4766 | val_loss: 0.00000 - val_binary_acc: 0.4886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.008s\n",
      "| RMSProp | epoch: 004 | loss: 0.00000 - binary_acc: 0.4211 | val_loss: 0.00000 - val_binary_acc: 0.4709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.080s\n",
      "| RMSProp | epoch: 005 | loss: 0.00000 - binary_acc: 0.4782 | val_loss: 0.00000 - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.012s\n",
      "| RMSProp | epoch: 006 | loss: 0.00000 - binary_acc: 0.4932 | val_loss: 0.00000 - val_binary_acc: 0.4709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.009s\n",
      "| RMSProp | epoch: 007 | loss: 0.00000 - binary_acc: 0.4975 | val_loss: 0.00000 - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.008s\n",
      "| RMSProp | epoch: 008 | loss: 0.00000 - binary_acc: 0.4737 | val_loss: 0.00000 - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.008s\n",
      "| RMSProp | epoch: 009 | loss: 0.00000 - binary_acc: 0.4912 | val_loss: 0.00000 - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.010s\n",
      "| RMSProp | epoch: 010 | loss: 0.00000 - binary_acc: 0.4533 | val_loss: 0.00000 - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.008s\n",
      "| RMSProp | epoch: 011 | loss: 0.00000 - binary_acc: 0.4813 | val_loss: 0.00000 - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.008s\n",
      "| RMSProp | epoch: 012 | loss: 0.00000 - binary_acc: 0.4370 | val_loss: 0.00000 - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.009s\n",
      "| RMSProp | epoch: 013 | loss: 0.00000 - binary_acc: 0.4693 | val_loss: 0.00000 - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.008s\n",
      "| RMSProp | epoch: 014 | loss: 0.00000 - binary_acc: 0.4452 | val_loss: 0.00000 - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.008s\n",
      "| RMSProp | epoch: 015 | loss: 0.00000 - binary_acc: 0.4725 | val_loss: 0.00000 - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.008s\n",
      "| RMSProp | epoch: 016 | loss: 0.00000 - binary_acc: 0.4384 | val_loss: 0.00000 - val_binary_acc: 0.4709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.005s\n",
      "| RMSProp | epoch: 017 | loss: 0.00000 - binary_acc: 0.4651 | val_loss: 0.00000 - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.008s\n",
      "| RMSProp | epoch: 018 | loss: 0.00000 - binary_acc: 0.4380 | val_loss: 0.00000 - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.007s\n",
      "| RMSProp | epoch: 019 | loss: 0.00000 - binary_acc: 0.4628 | val_loss: 0.00000 - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.009s\n",
      "| RMSProp | epoch: 020 | loss: 0.00000 - binary_acc: 0.4386 | val_loss: 0.00000 - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.008s\n",
      "| RMSProp | epoch: 021 | loss: 0.00000 - binary_acc: 0.4615 | val_loss: 0.00000 - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.008s\n",
      "| RMSProp | epoch: 022 | loss: 0.00000 - binary_acc: 0.4438 | val_loss: 0.00000 - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.008s\n",
      "| RMSProp | epoch: 023 | loss: 0.00000 - binary_acc: 0.4643 | val_loss: 0.00000 - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.009s\n",
      "| RMSProp | epoch: 024 | loss: 0.00000 - binary_acc: 0.4398 | val_loss: 0.00000 - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.007s\n",
      "| RMSProp | epoch: 025 | loss: 0.00000 - binary_acc: 0.4605 | val_loss: 0.00000 - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.009s\n",
      "| RMSProp | epoch: 026 | loss: 0.00000 - binary_acc: 0.4463 | val_loss: 0.00000 - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.008s\n",
      "| RMSProp | epoch: 027 | loss: 0.00000 - binary_acc: 0.4636 | val_loss: 0.00000 - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.008s\n",
      "| RMSProp | epoch: 028 | loss: 0.00000 - binary_acc: 0.4543 | val_loss: 0.00000 - val_binary_acc: 0.4684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.008s\n",
      "| RMSProp | epoch: 029 | loss: 0.00000 - binary_acc: 0.4678 | val_loss: 0.00000 - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.007s\n",
      "| RMSProp | epoch: 030 | loss: 0.00000 - binary_acc: 0.4482 | val_loss: 0.00000 - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'linear', 10, [0.4746450331462566]]\n",
      "RMSProp\n",
      "linear\n",
      "5\n",
      "---------------------------------\n",
      "Run id: DP5HZ1\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.123s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.007s\n",
      "| RMSProp | epoch: 002 | loss: 0.00000 - binary_acc: 0.3470 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.009s\n",
      "| RMSProp | epoch: 003 | loss: 0.00000 - binary_acc: 0.2851 | val_loss: 0.00000 - val_binary_acc: 0.3013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.008s\n",
      "| RMSProp | epoch: 004 | loss: 0.00000 - binary_acc: 0.2934 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.055s\n",
      "| RMSProp | epoch: 005 | loss: 0.00000 - binary_acc: 0.2940 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.011s\n",
      "| RMSProp | epoch: 006 | loss: 0.00000 - binary_acc: 0.3867 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.007s\n",
      "| RMSProp | epoch: 007 | loss: 0.00000 - binary_acc: 0.4176 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.008s\n",
      "| RMSProp | epoch: 008 | loss: 0.00000 - binary_acc: 0.4292 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.006s\n",
      "| RMSProp | epoch: 009 | loss: 0.00000 - binary_acc: 0.4339 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.008s\n",
      "| RMSProp | epoch: 010 | loss: 0.00000 - binary_acc: 0.4361 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.008s\n",
      "| RMSProp | epoch: 011 | loss: 0.00000 - binary_acc: 0.4371 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.008s\n",
      "| RMSProp | epoch: 012 | loss: 0.00000 - binary_acc: 0.4376 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.010s\n",
      "| RMSProp | epoch: 013 | loss: 0.00000 - binary_acc: 0.4378 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.008s\n",
      "| RMSProp | epoch: 014 | loss: 0.00000 - binary_acc: 0.4380 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.007s\n",
      "| RMSProp | epoch: 015 | loss: 0.00000 - binary_acc: 0.4380 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.009s\n",
      "| RMSProp | epoch: 016 | loss: 0.00000 - binary_acc: 0.4381 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.008s\n",
      "| RMSProp | epoch: 017 | loss: 0.00000 - binary_acc: 0.4381 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.009s\n",
      "| RMSProp | epoch: 018 | loss: 0.00000 - binary_acc: 0.4381 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.008s\n",
      "| RMSProp | epoch: 019 | loss: 0.00000 - binary_acc: 0.4382 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.008s\n",
      "| RMSProp | epoch: 020 | loss: 0.00000 - binary_acc: 0.4382 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.008s\n",
      "| RMSProp | epoch: 021 | loss: 0.00000 - binary_acc: 0.4382 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.009s\n",
      "| RMSProp | epoch: 022 | loss: 0.00000 - binary_acc: 0.4382 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.009s\n",
      "| RMSProp | epoch: 023 | loss: 0.00000 - binary_acc: 0.4382 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.009s\n",
      "| RMSProp | epoch: 024 | loss: 0.00000 - binary_acc: 0.4382 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.008s\n",
      "| RMSProp | epoch: 025 | loss: 0.00000 - binary_acc: 0.4382 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.010s\n",
      "| RMSProp | epoch: 026 | loss: 0.00000 - binary_acc: 0.4382 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.012s\n",
      "| RMSProp | epoch: 027 | loss: 0.00000 - binary_acc: 0.4382 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.008s\n",
      "| RMSProp | epoch: 028 | loss: 0.00000 - binary_acc: 0.4382 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.009s\n",
      "| RMSProp | epoch: 029 | loss: 0.00000 - binary_acc: 0.4382 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.009s\n",
      "| RMSProp | epoch: 030 | loss: 0.00000 - binary_acc: 0.4382 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'linear', 5, [0.45436105404132276]]\n",
      "RMSProp\n",
      "linear\n",
      "35\n",
      "---------------------------------\n",
      "Run id: OD8C4W\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.184s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.5241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.009s\n",
      "| RMSProp | epoch: 002 | loss: 0.00000 - binary_acc: 0.3807 | val_loss: 0.00000 - val_binary_acc: 0.5241 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.009s\n",
      "| RMSProp | epoch: 003 | loss: 0.00000 - binary_acc: 0.4754 | val_loss: 0.00000 - val_binary_acc: 0.4835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.008s\n",
      "| RMSProp | epoch: 004 | loss: 0.00000 - binary_acc: 0.3909 | val_loss: 0.00000 - val_binary_acc: 0.5038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.010s\n",
      "| RMSProp | epoch: 005 | loss: 0.00000 - binary_acc: 0.4697 | val_loss: 0.00000 - val_binary_acc: 0.5291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.009s\n",
      "| RMSProp | epoch: 006 | loss: 0.00000 - binary_acc: 0.4144 | val_loss: 0.00000 - val_binary_acc: 0.5266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.009s\n",
      "| RMSProp | epoch: 007 | loss: 0.00000 - binary_acc: 0.4614 | val_loss: 0.00000 - val_binary_acc: 0.5316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.009s\n",
      "| RMSProp | epoch: 008 | loss: 0.00000 - binary_acc: 0.4826 | val_loss: 0.00000 - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.009s\n",
      "| RMSProp | epoch: 009 | loss: 0.00000 - binary_acc: 0.4497 | val_loss: 0.00000 - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.009s\n",
      "| RMSProp | epoch: 010 | loss: 0.00000 - binary_acc: 0.4557 | val_loss: 0.00000 - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.009s\n",
      "| RMSProp | epoch: 011 | loss: 0.00000 - binary_acc: 0.4594 | val_loss: 0.00000 - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.009s\n",
      "| RMSProp | epoch: 012 | loss: 0.00000 - binary_acc: 0.4467 | val_loss: 0.00000 - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.009s\n",
      "| RMSProp | epoch: 013 | loss: 0.00000 - binary_acc: 0.4550 | val_loss: 0.00000 - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.009s\n",
      "| RMSProp | epoch: 014 | loss: 0.00000 - binary_acc: 0.4479 | val_loss: 0.00000 - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.010s\n",
      "| RMSProp | epoch: 015 | loss: 0.00000 - binary_acc: 0.4533 | val_loss: 0.00000 - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.009s\n",
      "| RMSProp | epoch: 016 | loss: 0.00000 - binary_acc: 0.4564 | val_loss: 0.00000 - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.009s\n",
      "| RMSProp | epoch: 017 | loss: 0.00000 - binary_acc: 0.4487 | val_loss: 0.00000 - val_binary_acc: 0.4456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.009s\n",
      "| RMSProp | epoch: 018 | loss: 0.00000 - binary_acc: 0.4479 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.009s\n",
      "| RMSProp | epoch: 019 | loss: 0.00000 - binary_acc: 0.4521 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.009s\n",
      "| RMSProp | epoch: 020 | loss: 0.00000 - binary_acc: 0.4496 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.010s\n",
      "| RMSProp | epoch: 021 | loss: 0.00000 - binary_acc: 0.4539 | val_loss: 0.00000 - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.009s\n",
      "| RMSProp | epoch: 022 | loss: 0.00000 - binary_acc: 0.4536 | val_loss: 0.00000 - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.008s\n",
      "| RMSProp | epoch: 023 | loss: 0.00000 - binary_acc: 0.4585 | val_loss: 0.00000 - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.010s\n",
      "| RMSProp | epoch: 024 | loss: 0.00000 - binary_acc: 0.4519 | val_loss: 0.00000 - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.008s\n",
      "| RMSProp | epoch: 025 | loss: 0.00000 - binary_acc: 0.4589 | val_loss: 0.00000 - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.009s\n",
      "| RMSProp | epoch: 026 | loss: 0.00000 - binary_acc: 0.4515 | val_loss: 0.00000 - val_binary_acc: 0.4506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.009s\n",
      "| RMSProp | epoch: 027 | loss: 0.00000 - binary_acc: 0.4581 | val_loss: 0.00000 - val_binary_acc: 0.4177 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.009s\n",
      "| RMSProp | epoch: 028 | loss: 0.00000 - binary_acc: 0.4526 | val_loss: 0.00000 - val_binary_acc: 0.4177 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.009s\n",
      "| RMSProp | epoch: 029 | loss: 0.00000 - binary_acc: 0.4526 | val_loss: 0.00000 - val_binary_acc: 0.4177 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.010s\n",
      "| RMSProp | epoch: 030 | loss: 0.00000 - binary_acc: 0.4494 | val_loss: 0.00000 - val_binary_acc: 0.4203 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'linear', 35, [0.4746450331462566]]\n",
      "RMSProp\n",
      "tanh\n",
      "10\n",
      "---------------------------------\n",
      "Run id: NNDXWZ\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.195s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.4810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.007s\n",
      "| RMSProp | epoch: 002 | loss: 0.00000 - binary_acc: 0.3464 | val_loss: 0.00000 - val_binary_acc: 0.4810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.009s\n",
      "| RMSProp | epoch: 003 | loss: 0.00000 - binary_acc: 0.4630 | val_loss: 0.00000 - val_binary_acc: 0.4861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.009s\n",
      "| RMSProp | epoch: 004 | loss: 0.00000 - binary_acc: 0.4824 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.008s\n",
      "| RMSProp | epoch: 005 | loss: 0.00000 - binary_acc: 0.4904 | val_loss: 0.00000 - val_binary_acc: 0.4987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.008s\n",
      "| RMSProp | epoch: 006 | loss: 0.00000 - binary_acc: 0.4059 | val_loss: 0.00000 - val_binary_acc: 0.5038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.009s\n",
      "| RMSProp | epoch: 007 | loss: 0.00000 - binary_acc: 0.4614 | val_loss: 0.00000 - val_binary_acc: 0.5063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.008s\n",
      "| RMSProp | epoch: 008 | loss: 0.00000 - binary_acc: 0.4844 | val_loss: 0.00000 - val_binary_acc: 0.5114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.008s\n",
      "| RMSProp | epoch: 009 | loss: 0.00000 - binary_acc: 0.4955 | val_loss: 0.00000 - val_binary_acc: 0.4810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.008s\n",
      "| RMSProp | epoch: 010 | loss: 0.00000 - binary_acc: 0.4510 | val_loss: 0.00000 - val_binary_acc: 0.4861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.007s\n",
      "| RMSProp | epoch: 011 | loss: 0.00000 - binary_acc: 0.4689 | val_loss: 0.00000 - val_binary_acc: 0.4785 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.008s\n",
      "| RMSProp | epoch: 012 | loss: 0.00000 - binary_acc: 0.4485 | val_loss: 0.00000 - val_binary_acc: 0.4481 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.009s\n",
      "| RMSProp | epoch: 013 | loss: 0.00000 - binary_acc: 0.4569 | val_loss: 0.00000 - val_binary_acc: 0.5114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.011s\n",
      "| RMSProp | epoch: 014 | loss: 0.00000 - binary_acc: 0.4119 | val_loss: 0.00000 - val_binary_acc: 0.4987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.008s\n",
      "| RMSProp | epoch: 015 | loss: 0.00000 - binary_acc: 0.4480 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.009s\n",
      "| RMSProp | epoch: 016 | loss: 0.00000 - binary_acc: 0.4205 | val_loss: 0.00000 - val_binary_acc: 0.4937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.009s\n",
      "| RMSProp | epoch: 017 | loss: 0.00000 - binary_acc: 0.4497 | val_loss: 0.00000 - val_binary_acc: 0.4785 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.008s\n",
      "| RMSProp | epoch: 018 | loss: 0.00000 - binary_acc: 0.4299 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.009s\n",
      "| RMSProp | epoch: 019 | loss: 0.00000 - binary_acc: 0.4523 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.009s\n",
      "| RMSProp | epoch: 020 | loss: 0.00000 - binary_acc: 0.4343 | val_loss: 0.00000 - val_binary_acc: 0.4987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.009s\n",
      "| RMSProp | epoch: 021 | loss: 0.00000 - binary_acc: 0.4560 | val_loss: 0.00000 - val_binary_acc: 0.4785 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.008s\n",
      "| RMSProp | epoch: 022 | loss: 0.00000 - binary_acc: 0.4339 | val_loss: 0.00000 - val_binary_acc: 0.4785 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.009s\n",
      "| RMSProp | epoch: 023 | loss: 0.00000 - binary_acc: 0.4510 | val_loss: 0.00000 - val_binary_acc: 0.4835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.009s\n",
      "| RMSProp | epoch: 024 | loss: 0.00000 - binary_acc: 0.4422 | val_loss: 0.00000 - val_binary_acc: 0.4810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.008s\n",
      "| RMSProp | epoch: 025 | loss: 0.00000 - binary_acc: 0.4499 | val_loss: 0.00000 - val_binary_acc: 0.4861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.008s\n",
      "| RMSProp | epoch: 026 | loss: 0.00000 - binary_acc: 0.4419 | val_loss: 0.00000 - val_binary_acc: 0.4835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.008s\n",
      "| RMSProp | epoch: 027 | loss: 0.00000 - binary_acc: 0.4499 | val_loss: 0.00000 - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.007s\n",
      "| RMSProp | epoch: 028 | loss: 0.00000 - binary_acc: 0.4473 | val_loss: 0.00000 - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.009s\n",
      "| RMSProp | epoch: 029 | loss: 0.00000 - binary_acc: 0.4506 | val_loss: 0.00000 - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.008s\n",
      "| RMSProp | epoch: 030 | loss: 0.00000 - binary_acc: 0.4444 | val_loss: 0.00000 - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'tanh', 10, [0.47667343186074773]]\n",
      "RMSProp\n",
      "tanh\n",
      "5\n",
      "---------------------------------\n",
      "Run id: B3CYED\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.165s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.008s\n",
      "| RMSProp | epoch: 002 | loss: 0.00000 - binary_acc: 0.2260 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.007s\n",
      "| RMSProp | epoch: 003 | loss: 0.00000 - binary_acc: 0.3202 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.007s\n",
      "| RMSProp | epoch: 004 | loss: 0.00000 - binary_acc: 0.3488 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.008s\n",
      "| RMSProp | epoch: 005 | loss: 0.00000 - binary_acc: 0.3308 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.008s\n",
      "| RMSProp | epoch: 006 | loss: 0.00000 - binary_acc: 0.3256 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.007s\n",
      "| RMSProp | epoch: 007 | loss: 0.00000 - binary_acc: 0.3239 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.008s\n",
      "| RMSProp | epoch: 008 | loss: 0.00000 - binary_acc: 0.3233 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.008s\n",
      "| RMSProp | epoch: 009 | loss: 0.00000 - binary_acc: 0.3230 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.008s\n",
      "| RMSProp | epoch: 010 | loss: 0.00000 - binary_acc: 0.3229 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.008s\n",
      "| RMSProp | epoch: 011 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.007s\n",
      "| RMSProp | epoch: 012 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.008s\n",
      "| RMSProp | epoch: 013 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.008s\n",
      "| RMSProp | epoch: 014 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.008s\n",
      "| RMSProp | epoch: 015 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.009s\n",
      "| RMSProp | epoch: 016 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.007s\n",
      "| RMSProp | epoch: 017 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.008s\n",
      "| RMSProp | epoch: 018 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.008s\n",
      "| RMSProp | epoch: 019 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.008s\n",
      "| RMSProp | epoch: 020 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.008s\n",
      "| RMSProp | epoch: 021 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.008s\n",
      "| RMSProp | epoch: 022 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.008s\n",
      "| RMSProp | epoch: 023 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.008s\n",
      "| RMSProp | epoch: 024 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.008s\n",
      "| RMSProp | epoch: 025 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.008s\n",
      "| RMSProp | epoch: 026 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.008s\n",
      "| RMSProp | epoch: 027 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.007s\n",
      "| RMSProp | epoch: 028 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.006s\n",
      "| RMSProp | epoch: 029 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.009s\n",
      "| RMSProp | epoch: 030 | loss: 0.00000 - binary_acc: 0.3228 | val_loss: 0.00000 - val_binary_acc: 0.3266 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'tanh', 5, [0.3002028369758482]]\n",
      "RMSProp\n",
      "tanh\n",
      "35\n",
      "---------------------------------\n",
      "Run id: RHHILO\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.149s\n",
      "| RMSProp | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.009s\n",
      "| RMSProp | epoch: 002 | loss: 0.00000 - binary_acc: 0.3886 | val_loss: 0.00000 - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.010s\n",
      "| RMSProp | epoch: 003 | loss: 0.00000 - binary_acc: 0.4857 | val_loss: 0.00000 - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.012s\n",
      "| RMSProp | epoch: 004 | loss: 0.00000 - binary_acc: 0.4115 | val_loss: 0.00000 - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.011s\n",
      "| RMSProp | epoch: 005 | loss: 0.00000 - binary_acc: 0.4778 | val_loss: 0.00000 - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.010s\n",
      "| RMSProp | epoch: 006 | loss: 0.00000 - binary_acc: 0.4275 | val_loss: 0.00000 - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.010s\n",
      "| RMSProp | epoch: 007 | loss: 0.00000 - binary_acc: 0.4754 | val_loss: 0.00000 - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.010s\n",
      "| RMSProp | epoch: 008 | loss: 0.00000 - binary_acc: 0.4473 | val_loss: 0.00000 - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.010s\n",
      "| RMSProp | epoch: 009 | loss: 0.00000 - binary_acc: 0.4787 | val_loss: 0.00000 - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.012s\n",
      "| RMSProp | epoch: 010 | loss: 0.00000 - binary_acc: 0.4439 | val_loss: 0.00000 - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.010s\n",
      "| RMSProp | epoch: 011 | loss: 0.00000 - binary_acc: 0.4736 | val_loss: 0.00000 - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.010s\n",
      "| RMSProp | epoch: 012 | loss: 0.00000 - binary_acc: 0.4388 | val_loss: 0.00000 - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.011s\n",
      "| RMSProp | epoch: 013 | loss: 0.00000 - binary_acc: 0.4679 | val_loss: 0.00000 - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.010s\n",
      "| RMSProp | epoch: 014 | loss: 0.00000 - binary_acc: 0.4573 | val_loss: 0.00000 - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.009s\n",
      "| RMSProp | epoch: 015 | loss: 0.00000 - binary_acc: 0.4769 | val_loss: 0.00000 - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.009s\n",
      "| RMSProp | epoch: 016 | loss: 0.00000 - binary_acc: 0.4452 | val_loss: 0.00000 - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.010s\n",
      "| RMSProp | epoch: 017 | loss: 0.00000 - binary_acc: 0.4676 | val_loss: 0.00000 - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.010s\n",
      "| RMSProp | epoch: 018 | loss: 0.00000 - binary_acc: 0.4519 | val_loss: 0.00000 - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.008s\n",
      "| RMSProp | epoch: 019 | loss: 0.00000 - binary_acc: 0.4704 | val_loss: 0.00000 - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.011s\n",
      "| RMSProp | epoch: 020 | loss: 0.00000 - binary_acc: 0.4474 | val_loss: 0.00000 - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.009s\n",
      "| RMSProp | epoch: 021 | loss: 0.00000 - binary_acc: 0.4658 | val_loss: 0.00000 - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.008s\n",
      "| RMSProp | epoch: 022 | loss: 0.00000 - binary_acc: 0.4430 | val_loss: 0.00000 - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.009s\n",
      "| RMSProp | epoch: 023 | loss: 0.00000 - binary_acc: 0.4617 | val_loss: 0.00000 - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.010s\n",
      "| RMSProp | epoch: 024 | loss: 0.00000 - binary_acc: 0.4490 | val_loss: 0.00000 - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.009s\n",
      "| RMSProp | epoch: 025 | loss: 0.00000 - binary_acc: 0.4647 | val_loss: 0.00000 - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.009s\n",
      "| RMSProp | epoch: 026 | loss: 0.00000 - binary_acc: 0.4471 | val_loss: 0.00000 - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.009s\n",
      "| RMSProp | epoch: 027 | loss: 0.00000 - binary_acc: 0.4624 | val_loss: 0.00000 - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.009s\n",
      "| RMSProp | epoch: 028 | loss: 0.00000 - binary_acc: 0.4521 | val_loss: 0.00000 - val_binary_acc: 0.4557 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.009s\n",
      "| RMSProp | epoch: 029 | loss: 0.00000 - binary_acc: 0.4654 | val_loss: 0.00000 - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.009s\n",
      "| RMSProp | epoch: 030 | loss: 0.00000 - binary_acc: 0.4753 | val_loss: 0.00000 - val_binary_acc: 0.4582 -- iter: 1577/1577\n",
      "--\n",
      "['RMSProp', 'tanh', 35, [0.4847870152330302]]\n",
      "AdaGrad\n",
      "linear\n",
      "10\n",
      "---------------------------------\n",
      "Run id: ARQJYC\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.122s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.2861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.006s\n",
      "| AdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.2408 | val_loss: 0.00000 - val_binary_acc: 0.2785 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.008s\n",
      "| AdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.2627 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.008s\n",
      "| AdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3306 | val_loss: 0.00000 - val_binary_acc: 0.2810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.008s\n",
      "| AdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.2931 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.009s\n",
      "| AdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.2755 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.009s\n",
      "| AdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.3050 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.008s\n",
      "| AdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3161 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.008s\n",
      "| AdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.3206 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.008s\n",
      "| AdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3226 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.007s\n",
      "| AdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.3236 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.007s\n",
      "| AdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3241 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.009s\n",
      "| AdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.3243 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.008s\n",
      "| AdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3245 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.009s\n",
      "| AdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.3245 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.008s\n",
      "| AdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3246 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.008s\n",
      "| AdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.3246 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.009s\n",
      "| AdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3246 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.008s\n",
      "| AdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.3246 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.008s\n",
      "| AdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.008s\n",
      "| AdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.008s\n",
      "| AdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.008s\n",
      "| AdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.008s\n",
      "| AdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.009s\n",
      "| AdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.008s\n",
      "| AdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.008s\n",
      "| AdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.008s\n",
      "| AdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.007s\n",
      "| AdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.007s\n",
      "| AdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3247 | val_loss: 0.00000 - val_binary_acc: 0.3190 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'linear', 10, [0.3002028369758482]]\n",
      "AdaGrad\n",
      "linear\n",
      "5\n",
      "---------------------------------\n",
      "Run id: EET8HJ\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.160s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3215 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.006s\n",
      "| AdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.3207 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.008s\n",
      "| AdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.3136 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.008s\n",
      "| AdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3238 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.008s\n",
      "| AdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.3222 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.008s\n",
      "| AdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3217 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.007s\n",
      "| AdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.3216 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.008s\n",
      "| AdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.008s\n",
      "| AdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.007s\n",
      "| AdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.011s\n",
      "| AdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.007s\n",
      "| AdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.006s\n",
      "| AdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.008s\n",
      "| AdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.008s\n",
      "| AdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.008s\n",
      "| AdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.008s\n",
      "| AdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.008s\n",
      "| AdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.008s\n",
      "| AdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.007s\n",
      "| AdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.006s\n",
      "| AdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.006s\n",
      "| AdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.006s\n",
      "| AdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.006s\n",
      "| AdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.008s\n",
      "| AdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.009s\n",
      "| AdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.009s\n",
      "| AdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.008s\n",
      "| AdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.008s\n",
      "| AdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.008s\n",
      "| AdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3215 | val_loss: 0.00000 - val_binary_acc: 0.3316 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'linear', 5, [0.3002028369758482]]\n",
      "AdaGrad\n",
      "linear\n",
      "35\n",
      "---------------------------------\n",
      "Run id: E8F3I0\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.130s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.2759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.007s\n",
      "| AdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.3578 | val_loss: 0.00000 - val_binary_acc: 0.2759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.009s\n",
      "| AdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.2809 | val_loss: 0.00000 - val_binary_acc: 0.2759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.011s\n",
      "| AdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.2714 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.010s\n",
      "| AdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.2692 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.011s\n",
      "| AdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3346 | val_loss: 0.00000 - val_binary_acc: 0.2759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.009s\n",
      "| AdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.2944 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.010s\n",
      "| AdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3464 | val_loss: 0.00000 - val_binary_acc: 0.2506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.010s\n",
      "| AdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.3043 | val_loss: 0.00000 - val_binary_acc: 0.2506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.010s\n",
      "| AdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3361 | val_loss: 0.00000 - val_binary_acc: 0.2506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.011s\n",
      "| AdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.3024 | val_loss: 0.00000 - val_binary_acc: 0.2506 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.010s\n",
      "| AdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3253 | val_loss: 0.00000 - val_binary_acc: 0.2532 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.010s\n",
      "| AdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.3000 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.010s\n",
      "| AdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3363 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.009s\n",
      "| AdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.3082 | val_loss: 0.00000 - val_binary_acc: 0.2810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.009s\n",
      "| AdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3236 | val_loss: 0.00000 - val_binary_acc: 0.2886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.008s\n",
      "| AdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.3007 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.009s\n",
      "| AdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3202 | val_loss: 0.00000 - val_binary_acc: 0.2886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.009s\n",
      "| AdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.3010 | val_loss: 0.00000 - val_binary_acc: 0.2886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.009s\n",
      "| AdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3163 | val_loss: 0.00000 - val_binary_acc: 0.2810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.009s\n",
      "| AdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.2994 | val_loss: 0.00000 - val_binary_acc: 0.2785 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.010s\n",
      "| AdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3139 | val_loss: 0.00000 - val_binary_acc: 0.2759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.008s\n",
      "| AdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.2975 | val_loss: 0.00000 - val_binary_acc: 0.2759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.010s\n",
      "| AdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3171 | val_loss: 0.00000 - val_binary_acc: 0.2759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.009s\n",
      "| AdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3031 | val_loss: 0.00000 - val_binary_acc: 0.2759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.010s\n",
      "| AdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3189 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.008s\n",
      "| AdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.3047 | val_loss: 0.00000 - val_binary_acc: 0.2810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.010s\n",
      "| AdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3178 | val_loss: 0.00000 - val_binary_acc: 0.2759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.009s\n",
      "| AdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.3043 | val_loss: 0.00000 - val_binary_acc: 0.2759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.009s\n",
      "| AdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3128 | val_loss: 0.00000 - val_binary_acc: 0.2911 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'linear', 35, [0.259634886805958]]\n",
      "AdaGrad\n",
      "tanh\n",
      "10\n",
      "---------------------------------\n",
      "Run id: OJ03TL\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.117s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.5089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.007s\n",
      "| AdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.3498 | val_loss: 0.00000 - val_binary_acc: 0.5063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.010s\n",
      "| AdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.4724 | val_loss: 0.00000 - val_binary_acc: 0.5089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.007s\n",
      "| AdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.4106 | val_loss: 0.00000 - val_binary_acc: 0.4937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.008s\n",
      "| AdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.4710 | val_loss: 0.00000 - val_binary_acc: 0.4785 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.009s\n",
      "| AdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.4821 | val_loss: 0.00000 - val_binary_acc: 0.4810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.010s\n",
      "| AdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.4881 | val_loss: 0.00000 - val_binary_acc: 0.4734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.008s\n",
      "| AdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.4914 | val_loss: 0.00000 - val_binary_acc: 0.4937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.008s\n",
      "| AdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.4901 | val_loss: 0.00000 - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.009s\n",
      "| AdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.4901 | val_loss: 0.00000 - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.009s\n",
      "| AdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.4616 | val_loss: 0.00000 - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.008s\n",
      "| AdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.4613 | val_loss: 0.00000 - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.008s\n",
      "| AdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.4612 | val_loss: 0.00000 - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.009s\n",
      "| AdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.4601 | val_loss: 0.00000 - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.009s\n",
      "| AdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.4599 | val_loss: 0.00000 - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.008s\n",
      "| AdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.4468 | val_loss: 0.00000 - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.009s\n",
      "| AdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.4512 | val_loss: 0.00000 - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.008s\n",
      "| AdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.4518 | val_loss: 0.00000 - val_binary_acc: 0.4633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.009s\n",
      "| AdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.4550 | val_loss: 0.00000 - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.008s\n",
      "| AdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.4517 | val_loss: 0.00000 - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.009s\n",
      "| AdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.4552 | val_loss: 0.00000 - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.011s\n",
      "| AdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.4514 | val_loss: 0.00000 - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.008s\n",
      "| AdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.4547 | val_loss: 0.00000 - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.008s\n",
      "| AdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.4495 | val_loss: 0.00000 - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.009s\n",
      "| AdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.4530 | val_loss: 0.00000 - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.009s\n",
      "| AdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.4513 | val_loss: 0.00000 - val_binary_acc: 0.4608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.008s\n",
      "| AdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.4543 | val_loss: 0.00000 - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.010s\n",
      "| AdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.4502 | val_loss: 0.00000 - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.008s\n",
      "| AdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.4530 | val_loss: 0.00000 - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.009s\n",
      "| AdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.4496 | val_loss: 0.00000 - val_binary_acc: 0.4658 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'tanh', 10, [0.47870182942667067]]\n",
      "AdaGrad\n",
      "tanh\n",
      "5\n",
      "---------------------------------\n",
      "Run id: KX6DSS\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.148s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.008s\n",
      "| AdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.4423 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.007s\n",
      "| AdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.3512 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.008s\n",
      "| AdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3361 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.007s\n",
      "| AdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.3326 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.008s\n",
      "| AdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.007s\n",
      "| AdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.3312 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.009s\n",
      "| AdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3311 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.010s\n",
      "| AdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.3311 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.008s\n",
      "| AdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.008s\n",
      "| AdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.008s\n",
      "| AdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.008s\n",
      "| AdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.008s\n",
      "| AdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.008s\n",
      "| AdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.008s\n",
      "| AdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.009s\n",
      "| AdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.009s\n",
      "| AdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.008s\n",
      "| AdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.009s\n",
      "| AdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.008s\n",
      "| AdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.009s\n",
      "| AdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.008s\n",
      "| AdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.009s\n",
      "| AdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.008s\n",
      "| AdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.009s\n",
      "| AdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.009s\n",
      "| AdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.008s\n",
      "| AdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.008s\n",
      "| AdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.007s\n",
      "| AdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3310 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'tanh', 5, [0.3002028369758482]]\n",
      "AdaGrad\n",
      "tanh\n",
      "35\n",
      "---------------------------------\n",
      "Run id: PJUQ74\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.137s\n",
      "| AdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.5038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.007s\n",
      "| AdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.3601 | val_loss: 0.00000 - val_binary_acc: 0.5063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.009s\n",
      "| AdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.4707 | val_loss: 0.00000 - val_binary_acc: 0.5038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.009s\n",
      "| AdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.4263 | val_loss: 0.00000 - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.009s\n",
      "| AdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.4745 | val_loss: 0.00000 - val_binary_acc: 0.4987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.010s\n",
      "| AdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.4324 | val_loss: 0.00000 - val_binary_acc: 0.5038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.010s\n",
      "| AdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.4693 | val_loss: 0.00000 - val_binary_acc: 0.4987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.010s\n",
      "| AdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.4393 | val_loss: 0.00000 - val_binary_acc: 0.5013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.010s\n",
      "| AdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.4686 | val_loss: 0.00000 - val_binary_acc: 0.4962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.010s\n",
      "| AdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.4534 | val_loss: 0.00000 - val_binary_acc: 0.5013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.009s\n",
      "| AdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.4717 | val_loss: 0.00000 - val_binary_acc: 0.5038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.009s\n",
      "| AdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.4364 | val_loss: 0.00000 - val_binary_acc: 0.5013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.010s\n",
      "| AdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.4624 | val_loss: 0.00000 - val_binary_acc: 0.5038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.011s\n",
      "| AdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.4400 | val_loss: 0.00000 - val_binary_acc: 0.3646 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.010s\n",
      "| AdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.4624 | val_loss: 0.00000 - val_binary_acc: 0.3646 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.010s\n",
      "| AdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.4310 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.009s\n",
      "| AdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.3989 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.009s\n",
      "| AdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3745 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.010s\n",
      "| AdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.3602 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.009s\n",
      "| AdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3502 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.010s\n",
      "| AdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.3444 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.010s\n",
      "| AdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3402 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.010s\n",
      "| AdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.3377 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.010s\n",
      "| AdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3357 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.010s\n",
      "| AdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3346 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.012s\n",
      "| AdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3333 | val_loss: 0.00000 - val_binary_acc: 0.3114 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.009s\n",
      "| AdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.3329 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.010s\n",
      "| AdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3316 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.009s\n",
      "| AdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.3315 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.011s\n",
      "| AdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3309 | val_loss: 0.00000 - val_binary_acc: 0.3089 -- iter: 1577/1577\n",
      "--\n",
      "['AdaGrad', 'tanh', 35, [0.3002028369758482]]\n",
      "ProximalAdaGrad\n",
      "linear\n",
      "10\n",
      "---------------------------------\n",
      "Run id: 3TWU1G\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.120s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.2810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.006s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.3264 | val_loss: 0.00000 - val_binary_acc: 0.2886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.2793 | val_loss: 0.00000 - val_binary_acc: 0.2937 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.2715 | val_loss: 0.00000 - val_binary_acc: 0.2886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.3000 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3199 | val_loss: 0.00000 - val_binary_acc: 0.2886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.2996 | val_loss: 0.00000 - val_binary_acc: 0.2886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3194 | val_loss: 0.00000 - val_binary_acc: 0.2886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.2987 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3171 | val_loss: 0.00000 - val_binary_acc: 0.2861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.3026 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3180 | val_loss: 0.00000 - val_binary_acc: 0.2861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.3040 | val_loss: 0.00000 - val_binary_acc: 0.2886 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3143 | val_loss: 0.00000 - val_binary_acc: 0.3519 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.2967 | val_loss: 0.00000 - val_binary_acc: 0.3519 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3034 | val_loss: 0.00000 - val_binary_acc: 0.3519 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.3063 | val_loss: 0.00000 - val_binary_acc: 0.3494 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3107 | val_loss: 0.00000 - val_binary_acc: 0.3519 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.3111 | val_loss: 0.00000 - val_binary_acc: 0.3519 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3112 | val_loss: 0.00000 - val_binary_acc: 0.3519 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.3114 | val_loss: 0.00000 - val_binary_acc: 0.3519 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3139 | val_loss: 0.00000 - val_binary_acc: 0.3519 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.3131 | val_loss: 0.00000 - val_binary_acc: 0.3519 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3150 | val_loss: 0.00000 - val_binary_acc: 0.3519 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3140 | val_loss: 0.00000 - val_binary_acc: 0.3519 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3150 | val_loss: 0.00000 - val_binary_acc: 0.3519 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.3139 | val_loss: 0.00000 - val_binary_acc: 0.3519 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3131 | val_loss: 0.00000 - val_binary_acc: 0.3519 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.3127 | val_loss: 0.00000 - val_binary_acc: 0.3519 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3136 | val_loss: 0.00000 - val_binary_acc: 0.3519 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'linear', 10, [0.2778904680427141]]\n",
      "ProximalAdaGrad\n",
      "linear\n",
      "5\n",
      "---------------------------------\n",
      "Run id: DF9ELJ\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.119s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.3350 | val_loss: 0.00000 - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.4241 | val_loss: 0.00000 - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.4389 | val_loss: 0.00000 - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.4424 | val_loss: 0.00000 - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.4433 | val_loss: 0.00000 - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.4437 | val_loss: 0.00000 - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.4438 | val_loss: 0.00000 - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.4438 | val_loss: 0.00000 - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.4439 | val_loss: 0.00000 - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.4439 | val_loss: 0.00000 - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.006s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.4439 | val_loss: 0.00000 - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.4439 | val_loss: 0.00000 - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.4439 | val_loss: 0.00000 - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.4439 | val_loss: 0.00000 - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.4439 | val_loss: 0.00000 - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.006s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.4439 | val_loss: 0.00000 - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.4439 | val_loss: 0.00000 - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.4439 | val_loss: 0.00000 - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.4439 | val_loss: 0.00000 - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.4439 | val_loss: 0.00000 - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.4439 | val_loss: 0.00000 - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.4439 | val_loss: 0.00000 - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.4439 | val_loss: 0.00000 - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.4439 | val_loss: 0.00000 - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.4439 | val_loss: 0.00000 - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.4439 | val_loss: 0.00000 - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.4439 | val_loss: 0.00000 - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.4439 | val_loss: 0.00000 - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.4439 | val_loss: 0.00000 - val_binary_acc: 0.4278 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'linear', 5, [0.45436105404132276]]\n",
      "ProximalAdaGrad\n",
      "linear\n",
      "35\n",
      "---------------------------------\n",
      "Run id: PMGTUN\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.653s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.3321 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.2658 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3223 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.2730 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3396 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.2861 | val_loss: 0.00000 - val_binary_acc: 0.2861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3189 | val_loss: 0.00000 - val_binary_acc: 0.2861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.2860 | val_loss: 0.00000 - val_binary_acc: 0.2861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.2711 | val_loss: 0.00000 - val_binary_acc: 0.2861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.2911 | val_loss: 0.00000 - val_binary_acc: 0.2861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3396 | val_loss: 0.00000 - val_binary_acc: 0.2861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.3038 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.2846 | val_loss: 0.00000 - val_binary_acc: 0.2861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.012s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.2737 | val_loss: 0.00000 - val_binary_acc: 0.2861 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.2671 | val_loss: 0.00000 - val_binary_acc: 0.2810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.2634 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.2833 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.2745 | val_loss: 0.00000 - val_binary_acc: 0.2810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3049 | val_loss: 0.00000 - val_binary_acc: 0.2810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.2900 | val_loss: 0.00000 - val_binary_acc: 0.2810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3156 | val_loss: 0.00000 - val_binary_acc: 0.2810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.014s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.2985 | val_loss: 0.00000 - val_binary_acc: 0.2810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3303 | val_loss: 0.00000 - val_binary_acc: 0.2810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3103 | val_loss: 0.00000 - val_binary_acc: 0.2810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3233 | val_loss: 0.00000 - val_binary_acc: 0.2810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.3062 | val_loss: 0.00000 - val_binary_acc: 0.2810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3191 | val_loss: 0.00000 - val_binary_acc: 0.2810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.3041 | val_loss: 0.00000 - val_binary_acc: 0.2810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3172 | val_loss: 0.00000 - val_binary_acc: 0.2810 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'linear', 35, [0.27383367176230006]]\n",
      "ProximalAdaGrad\n",
      "tanh\n",
      "10\n",
      "---------------------------------\n",
      "Run id: B9GD77\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.118s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.006s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.3419 | val_loss: 0.00000 - val_binary_acc: 0.2785 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.2780 | val_loss: 0.00000 - val_binary_acc: 0.2759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.2711 | val_loss: 0.00000 - val_binary_acc: 0.2785 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.2669 | val_loss: 0.00000 - val_binary_acc: 0.2456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3363 | val_loss: 0.00000 - val_binary_acc: 0.2608 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.2951 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3181 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.2874 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3349 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.2997 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3332 | val_loss: 0.00000 - val_binary_acc: 0.2810 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.3159 | val_loss: 0.00000 - val_binary_acc: 0.2759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3499 | val_loss: 0.00000 - val_binary_acc: 0.2658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.3147 | val_loss: 0.00000 - val_binary_acc: 0.2759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.2942 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.2814 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3142 | val_loss: 0.00000 - val_binary_acc: 0.2785 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.2976 | val_loss: 0.00000 - val_binary_acc: 0.2785 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3222 | val_loss: 0.00000 - val_binary_acc: 0.2759 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.013s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.3035 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3207 | val_loss: 0.00000 - val_binary_acc: 0.2633 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.3040 | val_loss: 0.00000 - val_binary_acc: 0.2734 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3209 | val_loss: 0.00000 - val_binary_acc: 0.2709 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3055 | val_loss: 0.00000 - val_binary_acc: 0.2684 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3267 | val_loss: 0.00000 - val_binary_acc: 0.2456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.3108 | val_loss: 0.00000 - val_binary_acc: 0.2456 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3240 | val_loss: 0.00000 - val_binary_acc: 0.2658 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.3102 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3293 | val_loss: 0.00000 - val_binary_acc: 0.2835 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'tanh', 10, [0.2920892521527428]]\n",
      "ProximalAdaGrad\n",
      "tanh\n",
      "5\n",
      "---------------------------------\n",
      "Run id: IUIY8F\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.154s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.5013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.3493 | val_loss: 0.00000 - val_binary_acc: 0.5089 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.4355 | val_loss: 0.00000 - val_binary_acc: 0.5013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.4180 | val_loss: 0.00000 - val_binary_acc: 0.4987 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.4438 | val_loss: 0.00000 - val_binary_acc: 0.5063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.294s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.4324 | val_loss: 0.00000 - val_binary_acc: 0.5013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.014s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.4553 | val_loss: 0.00000 - val_binary_acc: 0.5013 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.4674 | val_loss: 0.00000 - val_binary_acc: 0.5038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.4607 | val_loss: 0.00000 - val_binary_acc: 0.4911 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.4615 | val_loss: 0.00000 - val_binary_acc: 0.5291 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.4462 | val_loss: 0.00000 - val_binary_acc: 0.4076 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.4263 | val_loss: 0.00000 - val_binary_acc: 0.4329 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.4306 | val_loss: 0.00000 - val_binary_acc: 0.5139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.4023 | val_loss: 0.00000 - val_binary_acc: 0.5190 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.4384 | val_loss: 0.00000 - val_binary_acc: 0.5038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.4222 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.4489 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.4079 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.3821 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3654 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.3546 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3473 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.3424 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3390 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.007s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3367 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3350 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.3338 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3329 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.3323 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3319 | val_loss: 0.00000 - val_binary_acc: 0.2962 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'tanh', 5, [0.3002028369758482]]\n",
      "ProximalAdaGrad\n",
      "tanh\n",
      "35\n",
      "---------------------------------\n",
      "Run id: GZYA6P\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 1577\n",
      "Validation samples: 395\n",
      "--\n",
      "Training Step: 1  | time: 1.154s\n",
      "| ProximalAdaGrad | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 | val_loss: 0.00000 - val_binary_acc: 0.3063 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 2  | time: 1.008s\n",
      "| ProximalAdaGrad | epoch: 002 | loss: 0.00000 - binary_acc: 0.3430 | val_loss: 0.00000 - val_binary_acc: 0.3038 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 3  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 003 | loss: 0.00000 - binary_acc: 0.3010 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 4  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 004 | loss: 0.00000 - binary_acc: 0.3554 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 5  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 005 | loss: 0.00000 - binary_acc: 0.3350 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 6  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 006 | loss: 0.00000 - binary_acc: 0.3292 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 7  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 007 | loss: 0.00000 - binary_acc: 0.3272 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 8  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 008 | loss: 0.00000 - binary_acc: 0.3265 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 9  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 009 | loss: 0.00000 - binary_acc: 0.3262 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 10  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 010 | loss: 0.00000 - binary_acc: 0.3261 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 11  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 011 | loss: 0.00000 - binary_acc: 0.3260 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 12  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 012 | loss: 0.00000 - binary_acc: 0.3260 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 13  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 013 | loss: 0.00000 - binary_acc: 0.3260 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 14  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 014 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 15  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 015 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 16  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 016 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 17  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 017 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 18  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 018 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 19  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 019 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 20  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 020 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 21  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 021 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 22  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 022 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 23  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 023 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 24  | time: 1.011s\n",
      "| ProximalAdaGrad | epoch: 024 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 25  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 025 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 26  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 026 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 27  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 027 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 28  | time: 1.009s\n",
      "| ProximalAdaGrad | epoch: 028 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 29  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 029 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "Training Step: 30  | time: 1.010s\n",
      "| ProximalAdaGrad | epoch: 030 | loss: 0.00000 - binary_acc: 0.3259 | val_loss: 0.00000 - val_binary_acc: 0.3139 -- iter: 1577/1577\n",
      "--\n",
      "['ProximalAdaGrad', 'tanh', 35, [0.3002028369758482]]\n"
     ]
    }
   ],
   "source": [
    "#\"ProximalAdaGrad\",\"sgd\",'RMSProp','AdaGrad',\"ProximalAdaGrad\" \"momentum\",\"momentum\",'RMSProp' \" \"momentum\"\n",
    "optimizadores=[\"AdaDelta\",'RMSProp','AdaGrad',\"ProximalAdaGrad\"]\n",
    "#\n",
    "tf.reset_default_graph()\n",
    "activator=[  \"linear\" ,'tanh']\n",
    "tamanio=[[10,30,1],[5,15,5],[35,70,35]]\n",
    "#t#amanio=[[64,64,30,10]]\n",
    "#sgd = tflearn.SGD(learning_rate=0.01,lr_decay=0.96 , decay_step=500)\n",
    "resultados=[]\n",
    "for o in optimizadores:\n",
    "    for a in activator:\n",
    "        for t in tamanio:\n",
    "            \n",
    "            print(o)\n",
    "            print(a)\n",
    "            print(str(t[0]))\n",
    "            tf.reset_default_graph()\n",
    "            net = tflearn.input_data(shape=[None, 6])\n",
    "            net = tflearn.fully_connected(net,t[0], activation=a,regularizer=\"L2\", weights_init='normal', weight_decay=0.001)\n",
    "            #net = tflearn.fully_connected(net,t[1], activation=a,regularizer=\"L2\", weights_init='normal', weight_decay=0.001)\n",
    "            net = tflearn.fully_connected(net,t[1], activation=a,regularizer=\"L2\", weights_init='normal', weight_decay=0.001)\n",
    "            net = tflearn.fully_connected(net,t[0], activation=a,regularizer=\"L2\", weights_init='normal', weight_decay=0.001)\n",
    "            net = tflearn.fully_connected(net,1, activation=a,regularizer=\"L2\", weights_init='normal', weight_decay=0.001)\n",
    "            net = tflearn.regression(net, optimizer=o,loss=\"categorical_crossentropy\",metric=\"accuracy\")\n",
    "            model = tflearn.DNN(net)\n",
    "            model.fit(entrenamiento, entrenamiento_lbl,show_metric=True,validation_set=0.2,n_epoch=30,batch_size=len(entrenamiento))\n",
    "            accu=model.evaluate(validacion, validacion_lbl)\n",
    "            \n",
    "            #print(accu)\n",
    "            config=[o,a,t[0],accu]\n",
    "            print(config)\n",
    "            resultados.append(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados=pd.DataFrame(resultados)\n",
    "a=resultados[3]\n",
    "accu=[i[0] for i in a]\n",
    "resultados[\"accu\"]=accu\n",
    "\n",
    "resultados=resultados.sort_values(by=\"accu\",ascending=False)\n",
    "resultados.to_csv(\"resultados_rna_ECI_d.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
